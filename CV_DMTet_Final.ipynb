{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "70enHQEVM3HX",
        "vC8xIFcMNaXk",
        "8W1zYXghPPVh",
        "LxiYFjl6PT2C",
        "R-D0gGzDS3-7",
        "scLBY-eAaBUf",
        "hIZbLWiqaL5d",
        "dJxc2UTSacjd",
        "p34jmk1eTUFf",
        "qKcm_vY-TV8S"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aydin-ab/CV_DMTet/blob/main/CV_DMTet_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ],
      "metadata": {
        "id": "70enHQEVM3HX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bx6A6pHmM017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d96e1d-4ff9-45e6-a774-aa13333634ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |██████████████▌                 | 834.1 MB 478 kB/s eta 0:34:56tcmalloc: large alloc 1147494400 bytes == 0x38fa2000 @  0x7f75b8ffe615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |██████████████████▍             | 1055.7 MB 1.2 MB/s eta 0:11:08tcmalloc: large alloc 1434370048 bytes == 0x7d5f8000 @  0x7f75b8ffe615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |███████████████████████▎        | 1336.2 MB 1.2 MB/s eta 0:07:08tcmalloc: large alloc 1792966656 bytes == 0x242a000 @  0x7f75b8ffe615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████████████▌  | 1691.1 MB 1.1 MB/s eta 0:02:12tcmalloc: large alloc 2241208320 bytes == 0x6d212000 @  0x7f75b8ffe615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 1837.7 MB 125.3 MB/s eta 0:00:01tcmalloc: large alloc 1837744128 bytes == 0xf2b74000 @  0x7f75b8ffd1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2297184256 bytes == 0x160410000 @  0x7f75b8ffe615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 1837.7 MB 10 kB/s \n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 96.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 23.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1+cu113 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/'MyDrive'/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH"
      ],
      "metadata": {
        "id": "kv10BnuQNUjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8799d7b-0b68-480a-8669-b35e32268a7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "!pip install Cython==0.29.20  --quiet\n",
        "!pip install usd-core --quiet"
      ],
      "metadata": {
        "id": "02dA9jboNWj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c569d6e0-8141-4cae-a413-29e907409d1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 0.29.32\n",
            "Uninstalling Cython-0.29.32:\n",
            "  Successfully uninstalled Cython-0.29.32\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 24.7 MB 7.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "# !echo Checking if $SETUP_CHECK exists\n",
        "# !if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "!python setup.py develop\n",
        "!python -c \"import kaolin; print(kaolin.__version__)\""
      ],
      "metadata": {
        "id": "wbKOjtJyNYGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a84ee8-d327-4dc9-eba7-9ae98b6ffd34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: IGNORE_TORCH_VER=1\n",
            "env: KAOLIN_INSTALL_EXPERIMENTAL=1\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling kaolin/cython/ops/mesh/triangle_hash.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "Compiling kaolin/cython/ops/conversions/mise.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "[1/2] Cythonizing kaolin/cython/ops/conversions/mise.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/conversions/mise.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "[2/2] Cythonizing kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running develop\n",
            "running egg_info\n",
            "writing kaolin.egg-info/PKG-INFO\n",
            "writing dependency_links to kaolin.egg-info/dependency_links.txt\n",
            "writing requirements to kaolin.egg-info/requires.txt\n",
            "writing top-level names to kaolin.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:411: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'kaolin.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:813: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.3). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'kaolin.ops.mesh.triangle_hash' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/mesh/triangle_hash.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=triangle_hash -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:656\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_f_6kaolin_3ops_4mesh_13triangle_hash_12TriangleHash_query(__pyx_obj_6kaolin_3ops_4mesh_13triangle_hash_TriangleHash*, __Pyx_memviewslice, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2880:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2889:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so\n",
            "building 'kaolin.ops.conversions.mise' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/conversions/mise.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mise -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6kaolin_3ops_11conversions_4mise_4MISE_8get_points(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3476:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_10 = 0; \u001b[01;35m\u001b[K__pyx_t_10 < __pyx_t_9\u001b[m\u001b[K; __pyx_t_10+=1) {\n",
            "                        \u001b[01;35m\u001b[K~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid __pyx_f_6kaolin_3ops_11conversions_4mise_4MISE_subdivide_voxels(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3703:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3712:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3744:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3753:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K At global scope:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:15782:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyObject* __pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D(__pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " static PyObject* \u001b[01;35m\u001b[K__pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D\u001b[m\u001b[K(struct __pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D s) {\n",
            "                  \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/_C.so -> kaolin\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so -> kaolin/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so -> kaolin/ops/conversions\n",
            "Creating /usr/local/lib/python3.8/dist-packages/kaolin.egg-link (link to .)\n",
            "Adding kaolin 0.12.0 to easy-install.pth file\n",
            "Installing kaolin-dash3d script to /usr/local/bin\n",
            "\n",
            "Installed /content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Processing dependencies for kaolin==0.12.0\n",
            "Searching for usd-core<22.8\n",
            "Reading https://pypi.org/simple/usd-core/\n",
            "Downloading https://files.pythonhosted.org/packages/04/16/cc0b37b1f3eb68b3bdd3e4e2e31d297c8ac3bf8e4569d009eb3a5457424e/usd_core-22.5.post1-cp38-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=25f89f8637a671a8f883ded91e209844f0fe55f3f948310eddef92112418ffcc\n",
            "Best match: usd-core 22.5.post1\n",
            "Processing usd_core-22.5.post1-cp38-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing usd_core-22.5.post1-cp38-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding usd-core 22.5.post1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "Searching for flask==2.0.3\n",
            "Reading https://pypi.org/simple/flask/\n",
            "Downloading https://files.pythonhosted.org/packages/cd/77/59df23681f4fd19b7cbbb5e92484d46ad587554f5d490f33ef907e456132/Flask-2.0.3-py3-none-any.whl#sha256=59da8a3170004800a2837844bfa84d49b022550616070f7cb1a659682b2e7c9f\n",
            "Best match: Flask 2.0.3\n",
            "Processing Flask-2.0.3-py3-none-any.whl\n",
            "Installing Flask-2.0.3-py3-none-any.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding Flask 2.0.3 to easy-install.pth file\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/Flask-2.0.3-py3.8.egg\n",
            "Searching for tornado==6.1\n",
            "Reading https://pypi.org/simple/tornado/\n",
            "Downloading https://files.pythonhosted.org/packages/7a/4a/4fafa6f032f9e202ce5bc1becacef5588a34fd0f0539fdcc705fa2b5ca4a/tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl#sha256=d14d30e7f46a0476efb0deb5b61343b1526f73ebb5ed84f23dc794bdb88f9d9f\n",
            "Best match: tornado 6.1\n",
            "Processing tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl\n",
            "Installing tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding tornado 6.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg\n",
            "Searching for Pillow>=8.0.0\n",
            "Reading https://pypi.org/simple/Pillow/\n",
            "Downloading https://files.pythonhosted.org/packages/be/3e/a757fd2fdd5814aa0e9e1e838f79d33e0098e10a2e3afb7acdcb72278290/Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=03150abd92771742d4a8cd6f2fa6246d847dcd2e332a18d0c15cc75bf6703040\n",
            "Best match: Pillow 9.3.0\n",
            "Processing Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding Pillow 9.3.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Searching for scipy<=1.7.2,>=1.2.0\n",
            "Reading https://pypi.org/simple/scipy/\n",
            "Downloading https://files.pythonhosted.org/packages/ac/9a/6bcb3f8dcf4f2eae2a74c295afb51676295f69e1ee0a35b96ef9926a33a2/scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=4d175ba93e00d8eef8f7cd70d4d88a9106a86800c82ea03cf2268c36d6545483\n",
            "Best match: scipy 1.7.2\n",
            "Processing scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding scipy 1.7.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "Searching for itsdangerous>=2.0\n",
            "Reading https://pypi.org/simple/itsdangerous/\n",
            "Downloading https://files.pythonhosted.org/packages/68/5f/447e04e828f47465eeab35b5d408b7ebaaaee207f48b7136c5a7267a30ae/itsdangerous-2.1.2-py3-none-any.whl#sha256=2c2349112351b88699d8d4b6b075022c0808887cb7ad10069318a8b0bc88db44\n",
            "Best match: itsdangerous 2.1.2\n",
            "Processing itsdangerous-2.1.2-py3-none-any.whl\n",
            "Installing itsdangerous-2.1.2-py3-none-any.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding itsdangerous 2.1.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/itsdangerous-2.1.2-py3.8.egg\n",
            "Searching for Werkzeug>=2.0\n",
            "Reading https://pypi.org/simple/Werkzeug/\n",
            "Downloading https://files.pythonhosted.org/packages/c8/27/be6ddbcf60115305205de79c29004a0c6bc53cec814f733467b1bb89386d/Werkzeug-2.2.2-py3-none-any.whl#sha256=f979ab81f58d7318e064e99c4506445d60135ac5cd2e177a2de0089bfd4c9bd5\n",
            "Best match: Werkzeug 2.2.2\n",
            "Processing Werkzeug-2.2.2-py3-none-any.whl\n",
            "Installing Werkzeug-2.2.2-py3-none-any.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding Werkzeug 2.2.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/Werkzeug-2.2.2-py3.8.egg\n",
            "Searching for Jinja2>=3.0\n",
            "Reading https://pypi.org/simple/Jinja2/\n",
            "Downloading https://files.pythonhosted.org/packages/bc/c3/f068337a370801f372f2f8f6bad74a5c140f6fda3d9de154052708dd3c65/Jinja2-3.1.2-py3-none-any.whl#sha256=6088930bfe239f0e6710546ab9c19c9ef35e29792895fed6e6e31a023a182a61\n",
            "Best match: Jinja2 3.1.2\n",
            "Processing Jinja2-3.1.2-py3-none-any.whl\n",
            "Installing Jinja2-3.1.2-py3-none-any.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/Jinja2-3.1.2-py3.8.egg\n",
            "Searching for MarkupSafe>=2.1.1\n",
            "Reading https://pypi.org/simple/MarkupSafe/\n",
            "Downloading https://files.pythonhosted.org/packages/fd/f4/524d2e8f5a3727cf309c2b7df7c732038375322df1376c9e9ef3aa92fcaf/MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=4b9fe39a2ccc108a4accc2676e77da025ce383c108593d65cc909add5c3bd601\n",
            "Best match: MarkupSafe 2.1.1\n",
            "Processing MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.8/dist-packages\n",
            "Adding MarkupSafe 2.1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.8/dist-packages/MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for kaolin==0.12.0\n",
            "0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "vC8xIFcMNaXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "    import pytorch3d\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from pytorch3d.datasets import (\n",
        "    ShapeNetCore,\n",
        "    collate_batched_meshes\n",
        ")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/pvcnn')\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/models')\n",
        "\n",
        "torch.manual_seed(3407)\n",
        "torch.cuda.manual_seed(3407)"
      ],
      "metadata": {
        "id": "2uriKv2LNd9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9685ae4-dd44-4588-f9f6-61fb15e88195"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221213.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221213-py3-none-any.whl size=61498 sha256=fb9048cabc71c137c1d866e0f9869a7f45ed3360e62904761de0f2ae50eded9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/6d/5c/4fd3efe9b62aeae1e7e68204b54487df288e58e28f3d13fa1e\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=ff8924063ddb553fbe330b8b2c3d9704007600b925f5550a960f167a1fd8c6b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: portalocker, yacs, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221213 iopath-0.1.10 portalocker-2.6.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/pytorch3d-0.7.1-cp38-cp38-linux_x86_64.whl (47.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: iopath in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.5.post20221213)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (7.1.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (2.6.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ],
      "metadata": {
        "id": "CjeE5azrOEmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "bDyBXwZ7OHwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8428ff54-7373-4631-b319-82c683f73875"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ],
      "metadata": {
        "id": "-JNY_k5EOg7F"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import by pytorch3d\n",
        "\n",
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "# SYNSETS_IDS = ['02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02843684', '02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "SYNSETS_IDS = ['02747177']\n",
        "# shapenet_dataset = ShapeNetCore(SHAPENET_PATH, synsets=SYNSETS_IDS, version=2)\n",
        "# shapenet_loader = DataLoader(shapenet_dataset, batch_size=3, collate_fn=collate_batched_meshes)"
      ],
      "metadata": {
        "id": "FAflurFdOjih"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import by kaolin\n",
        "\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ],
      "metadata": {
        "id": "OwZ8rPkKOnS9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model visualization"
      ],
      "metadata": {
        "id": "8W1zYXghPPVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model = shapenet_train[0] # change the index here for different models\n",
        "sample_verts = sample_model['mesh'][0]\n",
        "sample_faces = sample_model['mesh'][1]\n",
        "\n",
        "center = (sample_verts.max(0)[0] + sample_verts.min(0)[0]) / 2\n",
        "max_l = (sample_verts.max(0)[0] - sample_verts.min(0)[0]).max()\n",
        "sample_verts = ((sample_verts - center) / max_l)\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[sample_verts.cpu()],\n",
        "    faces_list=[sample_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "lLuZr7eIPN9p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ],
      "metadata": {
        "id": "LxiYFjl6PT2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "    vertices=sample_verts.unsqueeze(0).to(device),\n",
        "    faces=sample_faces.to(device),\n",
        "    resolution=64\n",
        ")"
      ],
      "metadata": {
        "id": "OtlWB0DbPXws"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "wt_verts, wt_faces = wt_verts[0], wt_faces[0]"
      ],
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "timelapse.add_mesh_batch(\n",
        "    category='watertight_test',\n",
        "    vertices_list=[wt_verts.cpu()],\n",
        "    faces_list=[wt_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ],
      "metadata": {
        "id": "R-D0gGzDS3-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load('/content/drive/MyDrive/CV_DMTet/kaolin/examples/samples/128_verts.npz')['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load('/content/drive/MyDrive/CV_DMTet/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)"
      ],
      "metadata": {
        "id": "LyIoND6-SxAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed660438-b627-4eaa-eba2-2e28367b7096"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ca8a73dbab11>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  tets = torch.tensor(([np.load('/content/drive/MyDrive/CV_DMTet/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDF Model & GCN Model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ],
      "metadata": {
        "id": "scLBY-eAaBUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "        self.multires = config['multires']\n",
        "\n",
        "        self.embed_fn = None\n",
        "        # if self.multires > 0:\n",
        "        #     embed_fn, input_ch = get_embedder(self.multires)\n",
        "        #     self.embed_fn = embed_fn\n",
        "        #     self.input_dim = input_ch\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.embed_fn is not None:\n",
        "            x = self.embed_fn(x)\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return sdf predicted + f_v feature vector\n",
        "\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 3,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim"
      ],
      "metadata": {
        "id": "Sukbj2BeajMN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        deform = torch.tanh(deform)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature"
      ],
      "metadata": {
        "id": "J3MYPa9jacRy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Surface refinement utils"
      ],
      "metadata": {
        "id": "hIZbLWiqaL5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if thresh = 0, return all surface tetrahedrons\n",
        "# if thresh > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "def extract_tet(tets, sdf, thresh, non_surf=False):\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  if thresh == 0:\n",
        "    mask = sdf[tets] > 0\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (sdf[tets] >= -thresh) & (sdf[tets] <= thresh)\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    if thresh == 0:\n",
        "      non_surf_tets = tets[~((t > 0) & (t < 4))]\n",
        "    else:\n",
        "      non_surf_tets = tets[t < 4]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n",
        "def get_pred_sdfs(model, tets_verts, gt_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    F_vol = F.interpolate(gt_verts[None, None, None,:, :], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "    pred_sdfs, f_vs = model(F_vol)\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  d,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  d[s==True] *= -1\n",
        "\n",
        "  return d.squeeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instanciate Models"
      ],
      "metadata": {
        "id": "dJxc2UTSacjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 6, # Coordinates of the grid's vertices #previously 3\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "lr = 1e-4\n",
        "laplacian_weight = 0.1\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128\n",
        "epoch = 3000\n",
        "iterations = 200\n",
        "eval = 50"
      ],
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "sdf_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "print(sdf_model)\n",
        "print('\\n\\n')\n",
        "summary(sdf_model, input_size= (tets_verts.shape[0], 6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igdsZnpiTD9P",
        "outputId": "ce5a346a-b2ee-41cd-b11e-e23ea3f92370"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=6, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1          [-1, 277410, 256]           1,792\n",
            "            Linear-2          [-1, 277410, 256]          65,792\n",
            "            Linear-3          [-1, 277410, 128]          32,896\n",
            "            Linear-4           [-1, 277410, 64]           8,256\n",
            "            Linear-5            [-1, 277410, 1]              65\n",
            "================================================================\n",
            "Total params: 108,801\n",
            "Trainable params: 108,801\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 6.35\n",
            "Forward/backward pass size (MB): 1492.11\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 1498.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}"
      ],
      "metadata": {
        "id": "9ZYDVvaVTDUN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)"
      ],
      "metadata": {
        "id": "adK5p9SETGWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Up Optimizer"
      ],
      "metadata": {
        "id": "p34jmk1eTUFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "\n",
        "params = list(sdf_model.named_parameters()) + list(refine_model.named_parameters())\n",
        "\n",
        "refine_vars = [p for _, p in params]\n",
        "refine_optimizer = torch.optim.Adam(refine_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(refine_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "WxQnq3ZRTKTO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "qKcm_vY-TV8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d.loss import(\n",
        "    chamfer_distance\n",
        ")\n",
        "\n",
        "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
        "    term = torch.zeros_like(mesh_verts)\n",
        "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
        "\n",
        "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
        "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
        "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    pm = pytorch3d.structures.Meshes([mesh_verts], [mesh_faces])\n",
        "    gm = pytorch3d.structures.Meshes([gt_verts], [gt_faces])\n",
        "  \n",
        "    if mesh_verts.shape[0] > 0:\n",
        "      # pred_points, pred_n= pytorch3d.ops.sample_points_from_meshes(pm, num_samples=100000, return_normals=True)\n",
        "      # gt_points, gt_n = pytorch3d.ops.sample_points_from_meshes(gm, num_samples=100000, return_normals=True)\n",
        "      # print(pred_points.shape, pred_n.shape)\n",
        "      # c = pytorch3d.loss.chamfer_distance(pred_points, gt_points, x_normals=pred_n, y_normals=gt_n)\n",
        "\n",
        "      pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 100000)[0][0]\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 100000)[0][0]\n",
        "      # pred_points,gt_points = pc[0], pc[1]\n",
        "      # print(c[0]*500)\n",
        "      chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), squared=False).mean()\n",
        "    else:\n",
        "      chamfer = 0\n",
        "\n",
        "\n",
        "    #chamfer, p_norms = pytorch3d.loss.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), point_reduction='sum')\n",
        "    # norm = torch.sum(1-torch.abs(p_norms))\n",
        "    # norm = pytorch3d.loss.mesh_normal_consistency(m)\n",
        "    if it > iterations//2:\n",
        "      lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
        "      return 500*chamfer + lap * laplacian_weight #+ 1e-6*norm\n",
        "    return 500*chamfer #+ 1e-6*norm "
      ],
      "metadata": {
        "id": "MTGuIR9PS6Im"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train with IDW KDtree"
      ],
      "metadata": {
        "id": "kQNxZ88uTjtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree as KDTree\n",
        "    # http://docs.scipy.org/doc/scipy/reference/spatial.html\n",
        "\n",
        "__date__ = \"2010-11-09 Nov\"  # weights, doc\n",
        "\n",
        "#...............................................................................\n",
        "class Invdisttree:\n",
        "    \"\"\" inverse-distance-weighted interpolation using KDTree:\n",
        "invdisttree = Invdisttree( X, z )  -- data points, values\n",
        "interpol = invdisttree( q, nnear=3, eps=0, p=1, weights=None, stat=0 )\n",
        "    interpolates z from the 3 points nearest each query point q;\n",
        "    For example, interpol[ a query point q ]\n",
        "    finds the 3 data points nearest q, at distances d1 d2 d3\n",
        "    and returns the IDW average of the values z1 z2 z3\n",
        "        (z1/d1 + z2/d2 + z3/d3)\n",
        "        / (1/d1 + 1/d2 + 1/d3)\n",
        "        = .55 z1 + .27 z2 + .18 z3  for distances 1 2 3\n",
        "\n",
        "    q may be one point, or a batch of points.\n",
        "    eps: approximate nearest, dist <= (1 + eps) * true nearest\n",
        "    p: use 1 / distance**p\n",
        "    weights: optional multipliers for 1 / distance**p, of the same shape as q\n",
        "    stat: accumulate wsum, wn for average weights\n",
        "\n",
        "How many nearest neighbors should one take ?\n",
        "a) start with 8 11 14 .. 28 in 2d 3d 4d .. 10d; see Wendel's formula\n",
        "b) make 3 runs with nnear= e.g. 6 8 10, and look at the results --\n",
        "    |interpol 6 - interpol 8| etc., or |f - interpol*| if you have f(q).\n",
        "    I find that runtimes don't increase much at all with nnear -- ymmv.\n",
        "\n",
        "p=1, p=2 ?\n",
        "    p=2 weights nearer points more, farther points less.\n",
        "    In 2d, the circles around query points have areas ~ distance**2,\n",
        "    so p=2 is inverse-area weighting. For example,\n",
        "        (z1/area1 + z2/area2 + z3/area3)\n",
        "        / (1/area1 + 1/area2 + 1/area3)\n",
        "        = .74 z1 + .18 z2 + .08 z3  for distances 1 2 3\n",
        "    Similarly, in 3d, p=3 is inverse-volume weighting.\n",
        "\n",
        "Scaling:\n",
        "    if different X coordinates measure different things, Euclidean distance\n",
        "    can be way off.  For example, if X0 is in the range 0 to 1\n",
        "    but X1 0 to 1000, the X1 distances will swamp X0;\n",
        "    rescale the data, i.e. make X0.std() ~= X1.std() .\n",
        "\n",
        "A nice property of IDW is that it's scale-free around query points:\n",
        "if I have values z1 z2 z3 from 3 points at distances d1 d2 d3,\n",
        "the IDW average\n",
        "    (z1/d1 + z2/d2 + z3/d3)\n",
        "    / (1/d1 + 1/d2 + 1/d3)\n",
        "is the same for distances 1 2 3, or 10 20 30 -- only the ratios matter.\n",
        "In contrast, the commonly-used Gaussian kernel exp( - (distance/h)**2 )\n",
        "is exceedingly sensitive to distance and to h.\n",
        "\n",
        "    \"\"\"\n",
        "# anykernel( dj / av dj ) is also scale-free\n",
        "# error analysis, |f(x) - idw(x)| ? todo: regular grid, nnear ndim+1, 2*ndim\n",
        "\n",
        "    def __init__( self, X, z, leafsize=10, stat=0 ):\n",
        "        assert len(X) == len(z), \"len(X) %d != len(z) %d\" % (len(X), len(z))\n",
        "        self.tree = KDTree( X, leafsize=leafsize )  # build the tree\n",
        "        self.z = z\n",
        "        self.stat = stat\n",
        "        self.wn = 0\n",
        "        self.wsum = None;\n",
        "\n",
        "    def __call__( self, q, nnear=6, eps=0, p=1, weights=None ):\n",
        "            # nnear nearest neighbours of each query point --\n",
        "        q = np.asarray(q)\n",
        "        qdim = q.ndim\n",
        "        if qdim == 1:\n",
        "            q = np.array([q])\n",
        "        if self.wsum is None:\n",
        "            self.wsum = np.zeros(nnear)\n",
        "\n",
        "        self.distances, self.ix = self.tree.query( q, k=nnear, eps=eps )\n",
        "        interpol = np.zeros( (len(self.distances),) + np.shape(self.z[0]) )\n",
        "        jinterpol = 0\n",
        "        for dist, ix in zip( self.distances, self.ix ):\n",
        "            if nnear == 1:\n",
        "                wz = self.z[ix]\n",
        "            elif dist[0] < 1e-10:\n",
        "                wz = self.z[ix[0]]\n",
        "            else:  # weight z s by 1/dist --\n",
        "                w = 1 / dist**p\n",
        "                if weights is not None:\n",
        "                    w *= weights[ix]  # >= 0\n",
        "                w /= np.sum(w)\n",
        "                wz = np.dot( w, self.z[ix] )\n",
        "                if self.stat:\n",
        "                    self.wn += 1\n",
        "                    self.wsum += w\n",
        "            interpol[jinterpol] = wz\n",
        "            jinterpol += 1\n",
        "        return interpol if qdim > 1  else interpol[0]"
      ],
      "metadata": {
        "id": "zdUDMWT8Uvoy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def test_train_widw(iterations, sdf_model, gcn_model, wt_v, wt_f, gt_pts, idw, optimizer, scheduler, epoch):\n",
        "  gcn_model.train()\n",
        "  sdf_model.train()\n",
        "  avg_loss = 0\n",
        "\n",
        "  for i in range(iterations):\n",
        "\n",
        "    gt_model = shapenet_train[i] # change the index here for different models\n",
        "\n",
        "    gt_verts = gt_model['mesh'][0]\n",
        "    gt_faces = gt_model['mesh'][1]\n",
        "\n",
        "    gt_verts = ((gt_verts - ((gt_verts.max(0)[0] + gt_verts.min(0)[0]) / 2)) / ((gt_verts.max(0)[0] - gt_verts.min(0)[0]).max()))* 0.8\n",
        "\n",
        "    gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "\n",
        "    if epoch == 0:\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 7000)[0][0]\n",
        "\n",
        "      invdisttree = Invdisttree(gt_verts.cpu().numpy(), np.ones(gt_verts.shape))\n",
        "\n",
        "      wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "        vertices=gt_verts.unsqueeze(0),\n",
        "        faces=gt_faces,\n",
        "        resolution=64\n",
        "      )\n",
        "\n",
        "      wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "      wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "      center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "      max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "      wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "\n",
        "      wt_v.append(wt_verts)\n",
        "      wt_f.append(wt_faces)\n",
        "      gt_pts.append(gt_points)\n",
        "      idw.append(invdisttree)\n",
        "\n",
        "    else:\n",
        "      gt_points = gt_pts[i]\n",
        "      wt_verts, wt_faces = wt_v[i], wt_f[i]\n",
        "      idw_tree = idw[i]\n",
        "\n",
        "    inp = tets_verts.cpu().numpy()\n",
        "    F_vol = invdisttree(inp, nnear=11) #volumetric input\n",
        "    F_vol = torch.tensor(F_vol).to(device).float()\n",
        "    F_vol = torch.cat((tets_verts, F_vol.to(device)), dim=1)\n",
        "\n",
        "    pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "    \"\"\"\n",
        "    Surface Refinement\n",
        "    \"\"\"\n",
        "\n",
        "    surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0.008)\n",
        "    surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "    surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "    surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "    surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "    surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = pred_sdfs.clone()\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    update_tets_verts = tets_verts.clone()\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    update_tets_f = f_vs.clone()\n",
        "    update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "    if epoch < 500:\n",
        "      gt_sdfs = get_gt_sdfs(wt_verts.unsqueeze(0), wt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "      sdf_loss = F.mse_loss(update_sdfs, gt_sdfs, reduction='mean')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      sdf_loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      avg_loss += sdf_loss.item()\n",
        "\n",
        "      if epoch == 0 and i == 0:\n",
        "        print('========== Start pretraining ==========')\n",
        "      \n",
        "      if i == (iterations - 1) and epoch % 100 == 0:\n",
        "        print ('Epoch {} - loss: {}'.format(epoch, avg_loss/iterations))\n",
        "\n",
        "      continue\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "    mask = ((s_sdfs >= -0.3) & (s_sdfs <= 0.3)).squeeze(1)\n",
        "    p = update_sdfs[mask]\n",
        "    g = s_sdfs[mask]\n",
        "\n",
        "    sdf_loss = F.mse_loss(p, g, reduction='mean') \n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='mean')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, i)\n",
        "\n",
        "    g_loss = r_loss + deform_loss + 0.4*sdf_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    avg_loss += g_loss.item()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch == 500 and i == 0:\n",
        "        print('========== Start Refinement ==========')\n",
        "\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      # print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(i, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      print ('Epoch {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(epoch, avg_loss/iterations, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      print('# surface tets: {}'.format(surf_tets_verts.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=epoch+1,\n",
        "          category='final_train_res',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )\n"
      ],
      "metadata": {
        "id": "wl9eXDVuPumO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wt_v = []\n",
        "wt_f = []\n",
        "gt_pts = []\n",
        "idw = []\n",
        "\n",
        "for i in range(3):\n",
        "  test_train_widw(iterations, sdf_model, refine_model, wt_v, wt_f, gt_pts, idw, refine_optimizer, refine_scheduler, i)"
      ],
      "metadata": {
        "id": "3ouGLkJKVzEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train with Trilinear"
      ],
      "metadata": {
        "id": "-T4voeQCXQqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_wtri(iterations, sdf_model, gcn_model, wt_v, wt_f, gt_pts, optimizer, scheduler, epoch):\n",
        "  gcn_model.train()\n",
        "  sdf_model.train()\n",
        "  avg_loss = 0\n",
        "\n",
        "  for i in range(iterations):\n",
        "\n",
        "    gt_model = shapenet_train[10] # change the index here for different models\n",
        "\n",
        "    gt_verts = gt_model['mesh'][0]\n",
        "    gt_faces = gt_model['mesh'][1]\n",
        "\n",
        "    gt_verts = ((gt_verts - ((gt_verts.max(0)[0] + gt_verts.min(0)[0]) / 2)) / ((gt_verts.max(0)[0] - gt_verts.min(0)[0]).max()))* 0.8\n",
        "\n",
        "    gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "    if epoch == 0:\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 7000)[0][0]\n",
        "\n",
        "      wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "        vertices=gt_verts.unsqueeze(0),\n",
        "        faces=gt_faces,\n",
        "        resolution=64\n",
        "      )\n",
        "\n",
        "      wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "      wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "      center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "      max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "      wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "\n",
        "      wt_v.append(wt_verts)\n",
        "      wt_f.append(wt_faces)\n",
        "      gt_pts.append(gt_points)\n",
        "\n",
        "    else:\n",
        "      gt_points = gt_pts\n",
        "      wt_verts, wt_faces = wt_v, wt_f\n",
        "\n",
        "    F_vol = F.interpolate(gt_points[None, None, None, :,:], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "\n",
        "    pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "    \"\"\"\n",
        "    Surface Refinement\n",
        "    \"\"\"\n",
        "\n",
        "    surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0.008)\n",
        "    surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "    surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "    surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "    surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "    surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = pred_sdfs.clone()\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    update_tets_verts = tets_verts.clone()\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    update_tets_f = f_vs.clone()\n",
        "    update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "    if epoch < 500:\n",
        "      gt_sdfs = get_gt_sdfs(wt_verts.unsqueeze(0), wt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "      sdf_loss = F.mse_loss(update_sdfs, gt_sdfs, reduction='mean')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      sdf_loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      avg_loss += sdf_loss.item()\n",
        "\n",
        "      if epoch == 0 and i == 0:\n",
        "        print('========== Start pretraining ==========')\n",
        "      \n",
        "      if i == (iterations - 1) and epoch % 100 == 0:\n",
        "        print ('Epoch {} - loss: {}'.format(epoch, avg_loss/iterations))\n",
        "\n",
        "      continue\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "    mask = ((s_sdfs >= -0.3) & (s_sdfs <= 0.3)).squeeze(1)\n",
        "    p = update_sdfs[mask]\n",
        "    g = s_sdfs[mask]\n",
        "\n",
        "    sdf_loss = F.mse_loss(p, g, reduction='mean') \n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='mean')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, i)\n",
        "\n",
        "    g_loss = r_loss + deform_loss + 0.4*sdf_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    avg_loss += g_loss.item()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch == 500 and i == 0:\n",
        "        print('========== Start Refinement ==========')\n",
        "\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      # print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(i, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      print ('Epoch {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(epoch, avg_loss/iterations, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      print('# surface tets: {}'.format(surf_tets_verts.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=epoch+1,\n",
        "          category='final_train_res',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )\n",
        "    "
      ],
      "metadata": {
        "id": "0Nju6vB7_GBx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wt_v = []\n",
        "wt_f = [] \n",
        "gt_pts = []\n",
        "\n",
        "for i in range(epoch):\n",
        "  test_train_wtri(iterations, sdf_model, refine_model, wt_v, wt_f, gt_pts, refine_optimizer, refine_scheduler, i)"
      ],
      "metadata": {
        "id": "BT4Tf7O_a4ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "DYrQM22TT8ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_loss(mesh_verts, mesh_faces, gt_verts, gt_faces):\n",
        "  pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 50000)[0][0]\n",
        "  gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 50000)[0][0]\n",
        "\n",
        "  chamfer = 100*pytorch3d.loss.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), norm=1)[0]\n",
        "  chamferL2 = 100*kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), squared=False).mean()\n",
        "  fscore = 100*kaolin.metrics.pointcloud.f_score(gt_points.unsqueeze(0), pred_points.unsqueeze(0)).mean()\n",
        "  return chamfer, chamferL2, fscore"
      ],
      "metadata": {
        "id": "s7g_tRPeTHGT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_eval(sdf_model, gcn_model, id):\n",
        "  sdf_model.eval()\n",
        "  gcn_model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    gt_model = shapenet_test[id] # change the index here for different models\n",
        "\n",
        "    gt_verts = gt_model['mesh'][0]\n",
        "    gt_faces = gt_model['mesh'][1]\n",
        "\n",
        "    gt_verts = ((gt_verts - ((gt_verts.max(0)[0] + gt_verts.min(0)[0]) / 2)) / ((gt_verts.max(0)[0] - gt_verts.min(0)[0]).max()))* 0.8\n",
        "\n",
        "    gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "    gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 7000)[0][0]\n",
        "\n",
        "    F_vol = F.interpolate(gt_points[None, None, None, :,:], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "\n",
        "    pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "    \"\"\"\n",
        "    Surface Refinement\n",
        "    \"\"\"\n",
        "\n",
        "    surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0)\n",
        "    surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "    surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "    surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "    surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "    surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = pred_sdfs.clone()\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    update_tets_verts = tets_verts.clone()\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    update_tets_f = f_vs.clone()\n",
        "    update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    timelapse.add_mesh_batch(\n",
        "          category='gt',\n",
        "          vertices_list=[gt_verts.cpu()],\n",
        "          faces_list=[gt_faces.cpu()]\n",
        "    )\n",
        "\n",
        "    timelapse.add_pointcloud_batch(\n",
        "        category='input',\n",
        "        pointcloud_list = [gt_points.cpu()]\n",
        "    )\n",
        "\n",
        "    timelapse.add_mesh_batch(\n",
        "        category='eval_res',\n",
        "        vertices_list=[mesh_verts.cpu()],\n",
        "        faces_list=[mesh_faces.cpu()]\n",
        "    )\n",
        "\n",
        "    chamfer, chamferL2, fscore = eval_loss(mesh_verts, mesh_faces, gt_verts, gt_faces)\n",
        "    \n",
        "    print('Chamfer loss for model {} is: chamferL1: {}, chamferL2: {}, f-score: {}'.format(id, chamfer, chamferL2, fscore))"
      ],
      "metadata": {
        "id": "cXxoOyd7SlAm"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(eval):\n",
        "  test_eval(sdf_model, refine_model, i)"
      ],
      "metadata": {
        "id": "TfC7guf5XFLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "1H7RCV62USts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2IGctyaa9n7vRBd8qq7pzd0bNKh_2pDFmKRk5Af1QDq295xZ4\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "id": "p68GrPqkUU07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad69efba-b607-452a-a34b-326b829f4b0d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 3.0 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 194 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 256 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 266 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 276 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 296 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 317 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 327 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 337 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 348 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 368 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 389 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 399 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 409 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 419 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 440 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 460 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 471 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 481 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 491 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 501 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 512 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 522 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 532 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 542 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 552 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 563 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 573 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 583 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 593 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 604 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 614 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 624 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 634 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 645 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 655 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 665 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 675 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 686 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 696 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 706 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 716 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 727 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 737 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 747 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 757 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 761 kB 6.2 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ],
      "metadata": {
        "id": "rWJ2SS1EUYjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fac94e-deda-481c-9d08-f1559db2cd0d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking URL: NgrokTunnel: \"http://287c-34-125-135-181.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_model = shapenet_train[18]\n",
        "v_verts = v_model['mesh'][0].to(device)\n",
        "v_faces = v_model['mesh'][1].to(device)\n",
        "\n",
        "gt_verts = v_verts\n",
        "\n",
        "gt_verts = ((gt_verts - ((gt_verts.max(0)[0] + gt_verts.min(0)[0]) / 2)) / ((gt_verts.max(0)[0] - gt_verts.min(0)[0]).max()))* 0.8\n",
        "\n",
        "gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), v_faces, 7000)[0][0]\n",
        "\n",
        "wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "        vertices=gt_verts.unsqueeze(0),\n",
        "        faces=v_faces,\n",
        "        resolution=64\n",
        "    )\n",
        "\n",
        "wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "      category='gt',\n",
        "      vertices_list=[v_verts.cpu()],\n",
        "      faces_list=[v_faces.cpu()]\n",
        ")\n",
        "\n",
        "timelapse.add_pointcloud_batch(\n",
        "    category='input',\n",
        "    pointcloud_list = [gt_points.cpu()]\n",
        ")\n"
      ],
      "metadata": {
        "id": "dW2JHgF_bnFd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ],
      "metadata": {
        "id": "9RZLd8x7UrUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748f1fce-0698-47a9-899d-a24e6ec8b679"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash3D server starting. Go to: http://localhost:80\n",
            "2022-12-16 04:59:36,116|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 04:59:57,941|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 04:59:59,359|    INFO| tornado.access| 200 GET / (127.0.0.1) 1460.24ms\n",
            "2022-12-16 04:59:59,833|    INFO| tornado.access| 200 GET /static/thirdparty.css (127.0.0.1) 300.04ms\n",
            "2022-12-16 05:00:00,415|    INFO| tornado.access| 200 GET /static/thirdparty.js (127.0.0.1) 581.65ms\n",
            "2022-12-16 05:00:00,813|    INFO| tornado.access| 200 GET /static/core-min.js (127.0.0.1) 979.16ms\n",
            "2022-12-16 05:00:01,474|    INFO| tornado.access| 200 GET /static/green_plastic.frag (127.0.0.1) 402.84ms\n",
            "2022-12-16 05:00:01,475|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 0.56ms\n",
            "2022-12-16 05:00:01,516|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 05:00:01,825|    INFO| tornado.access| 200 GET /static/favicon.ico (127.0.0.1) 306.61ms\n",
            "2022-12-16 05:00:05,500|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.61ms\n",
            "2022-12-16 05:00:05,714|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.68ms\n",
            "2022-12-16 05:00:05,803|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.40ms\n",
            "2022-12-16 05:00:05,894|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.35ms\n",
            "2022-12-16 05:00:07,948|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 05:00:07,951|    INFO| tornado.access| 200 GET / (127.0.0.1) 44.96ms\n",
            "2022-12-16 05:00:08,050|    INFO|kaolin.experimental.dash3d.util| Socket closed.\n",
            "2022-12-16 05:00:08,687|    INFO| tornado.access| 200 GET /static/style.css (127.0.0.1) 628.89ms\n",
            "2022-12-16 05:00:08,690|    INFO| tornado.access| 304 GET /static/thirdparty.css (127.0.0.1) 2.83ms\n",
            "2022-12-16 05:00:08,692|    INFO| tornado.access| 304 GET /static/core-min.js (127.0.0.1) 4.34ms\n",
            "2022-12-16 05:00:08,694|    INFO| tornado.access| 304 GET /static/thirdparty.js (127.0.0.1) 6.02ms\n",
            "2022-12-16 05:00:08,812|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.29ms\n",
            "2022-12-16 05:00:08,837|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 0.38ms\n",
            "2022-12-16 05:00:08,875|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 05:00:08,901|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.08ms\n",
            "2022-12-16 05:00:08,906|    INFO| tornado.access| 304 GET /static/favicon.ico (127.0.0.1) 1.83ms\n",
            "2022-12-16 05:00:11,875|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 3.15ms\n",
            "2022-12-16 05:00:12,086|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.52ms\n",
            "2022-12-16 05:00:12,175|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.72ms\n",
            "2022-12-16 05:00:13,720|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:16,554|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:16,560|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:17,853|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:18,723|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:18,728|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:39,652|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:40,366|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:40,372|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:41,255|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:41,273|    INFO|kaolin.experimental.dash3d.util| Snap time 2901.0 too close to current_time 2901.0; no geometry parsed\n",
            "2022-12-16 05:00:41,280|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:41,285|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:43,546|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:43,812|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:43,818|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-16 05:00:45,275|    INFO|kaolin.experimental.dash3d.util| Socket closed.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaolin-dash3d\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/kaolin-dash3d\", line 6, in <module>\n",
            "    run_main()\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/run.py\", line 97, in run_main\n",
            "    IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg/tornado/platform/asyncio.py\", line 199, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1823, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaolin-dash3d\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}