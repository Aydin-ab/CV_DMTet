{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U-ItNJXfPQPA",
        "pKhngPBlPbTs",
        "4LTFQbA5awlr",
        "2nNEgqpiVtWS",
        "vO_9h4CvJsGJ",
        "NXJG7i2wbHC7",
        "scLBY-eAaBUf",
        "CdT4ryFGTP1M",
        "W_Dh9gJiTWEq",
        "gf6lBBcPTcwd"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aydin-ab/CV_DMTet/blob/main/DMTet_Tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ],
      "metadata": {
        "id": "1Af_jBwcMwG8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x7VxtwyMthl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06349545-4fa7-4621-999f-daa3d0a7d5ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/'MyDrive'/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "!pip install Cython==0.29.20  --quiet\n",
        "!pip install usd-core --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomq21yA4wP8",
        "outputId": "6a909dc1-e6a3-4200-919f-7ec7249ffa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 0.29.20\n",
            "Uninstalling Cython-0.29.20:\n",
            "  Successfully uninstalled Cython-0.29.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "# !echo Checking if $SETUP_CHECK exists\n",
        "# !if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "!python setup.py develop\n",
        "!python -c \"import kaolin; print(kaolin.__version__)\""
      ],
      "metadata": {
        "id": "w2gnrsxeoc_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fc569d-6177-4e7a-e2a4-72fb3b54226b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: IGNORE_TORCH_VER=1\n",
            "env: KAOLIN_INSTALL_EXPERIMENTAL=1\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n",
            "setup.py:36: UserWarning: Kaolin is compatible with PyTorch >=1.6.0, <=1.13.0, but found version 1.13.0+cu116. Continuing with the installed version as IGNORE_TORCH_VER is set.\n",
            "  warnings.warn(\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling kaolin/cython/ops/mesh/triangle_hash.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "Compiling kaolin/cython/ops/conversions/mise.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "[1/2] Cythonizing kaolin/cython/ops/conversions/mise.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/conversions/mise.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "[2/2] Cythonizing kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running develop\n",
            "running egg_info\n",
            "writing kaolin.egg-info/PKG-INFO\n",
            "writing dependency_links to kaolin.egg-info/dependency_links.txt\n",
            "writing requirements to kaolin.egg-info/requires.txt\n",
            "writing top-level names to kaolin.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'kaolin.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'kaolin.ops.mesh.triangle_hash' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/mesh/triangle_hash.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=triangle_hash -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:656\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_f_6kaolin_3ops_4mesh_13triangle_hash_12TriangleHash_query(__pyx_obj_6kaolin_3ops_4mesh_13triangle_hash_TriangleHash*, __Pyx_memviewslice, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2880:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2889:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so\n",
            "building 'kaolin.ops.conversions.mise' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/conversions/mise.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mise -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6kaolin_3ops_11conversions_4mise_4MISE_8get_points(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3476:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_10 = 0; \u001b[01;35m\u001b[K__pyx_t_10 < __pyx_t_9\u001b[m\u001b[K; __pyx_t_10+=1) {\n",
            "                        \u001b[01;35m\u001b[K~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid __pyx_f_6kaolin_3ops_11conversions_4mise_4MISE_subdivide_voxels(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3703:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3712:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3744:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3753:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K At global scope:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:15782:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyObject* __pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D(__pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " static PyObject* \u001b[01;35m\u001b[K__pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D\u001b[m\u001b[K(struct __pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D s) {\n",
            "                  \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/_C.so -> kaolin\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so -> kaolin/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so -> kaolin/ops/conversions\n",
            "Creating /usr/local/lib/python3.8/dist-packages/kaolin.egg-link (link to .)\n",
            "kaolin 0.12.0 is already the active version in easy-install.pth\n",
            "Installing kaolin-dash3d script to /usr/local/bin\n",
            "\n",
            "Installed /content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Processing dependencies for kaolin==0.12.0\n",
            "Searching for usd-core==22.5.post1\n",
            "Best match: usd-core 22.5.post1\n",
            "Processing usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "usd-core 22.5.post1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "Searching for Flask==2.0.3\n",
            "Best match: Flask 2.0.3\n",
            "Processing Flask-2.0.3-py3.8.egg\n",
            "Flask 2.0.3 is already the active version in easy-install.pth\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Flask-2.0.3-py3.8.egg\n",
            "Searching for tornado==6.1\n",
            "Best match: tornado 6.1\n",
            "Processing tornado-6.1-py3.8-linux-x86_64.egg\n",
            "tornado 6.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Pillow==9.3.0\n",
            "Best match: Pillow 9.3.0\n",
            "Processing Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Pillow 9.3.0 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Searching for scipy==1.7.2\n",
            "Best match: scipy 1.7.2\n",
            "Processing scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "scipy 1.7.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "Searching for itsdangerous==2.1.2\n",
            "Best match: itsdangerous 2.1.2\n",
            "Processing itsdangerous-2.1.2-py3.8.egg\n",
            "itsdangerous 2.1.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/itsdangerous-2.1.2-py3.8.egg\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Werkzeug==2.2.2\n",
            "Best match: Werkzeug 2.2.2\n",
            "Processing Werkzeug-2.2.2-py3.8.egg\n",
            "Werkzeug 2.2.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Werkzeug-2.2.2-py3.8.egg\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Processing Jinja2-3.1.2-py3.8.egg\n",
            "Jinja2 3.1.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Jinja2-3.1.2-py3.8.egg\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for MarkupSafe==2.1.1\n",
            "Best match: MarkupSafe 2.1.1\n",
            "Processing MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "MarkupSafe 2.1.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "Finished processing dependencies for kaolin==0.12.0\n",
            "0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "U-ItNJXfPQPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')"
      ],
      "metadata": {
        "id": "xI6uNv5JPP0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ],
      "metadata": {
        "id": "pKhngPBlPbTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch3d"
      ],
      "metadata": {
        "id": "LWdkJJr1y_wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('/content/drive/MyDrive/CV_DMTet/shapenet.pvcnn.c1.pth.tar')\n",
        "state_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G126GQfpf1nB",
        "outputId": "37bcd83e-81a8-4124-87a5-8bbb0fa6ca09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['model'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/kaolin/examples/')\n",
        "sys.path.append('/content/drive/MyDrive/kaolin/examples/tutorial')"
      ],
      "metadata": {
        "id": "yMSLuRoDPfkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "aTCgE2WCPiAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25911613-aced-4849-99a9-d00d0332c47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the point cloud to be reconstructed\n",
        "pcd_path = \"/content/drive/MyDrive/kaolin/examples/samples/bear_pointcloud.usd\"\n",
        "# path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ],
      "metadata": {
        "id": "i3zs2M-kOA1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ],
      "metadata": {
        "id": "R-D0gGzDS3-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load('/content/drive/MyDrive/kaolin/examples/samples/128_verts.npz')['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load('/content/drive/MyDrive/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyIoND6-SxAD",
        "outputId": "a5874262-46d7-4258-a480-c66a643ef217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-6909fe0ff698>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  tets = torch.tensor(([np.load('/content/drive/MyDrive/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading from ShapeNet"
      ],
      "metadata": {
        "id": "4LTFQbA5awlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "SYNSETS_IDS = ['02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02843684', '02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ],
      "metadata": {
        "id": "fxK5Qw4xay7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model = shapenet_train[2000] # change the index here for different models\n",
        "sample_verts = sample_model['mesh'][0]\n",
        "sample_faces = sample_model['mesh'][1]\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[sample_verts.cpu()],\n",
        "    faces_list=[sample_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "uhzpP8kua2Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert model to watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ],
      "metadata": {
        "id": "NXJG7i2wbHC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "    vertices=sample_verts.unsqueeze(0).to(device),\n",
        "    faces=sample_faces.to(device),\n",
        "    resolution=64\n",
        ")"
      ],
      "metadata": {
        "id": "e93m-kdBHD7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "wt_verts, wt_faces = wt_verts[0], wt_faces[0]"
      ],
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wt_verts = kaolin.metrics.trianglemesh.uniform_laplacian_smoothing(wt_verts[0].unsqueeze(0), wt_faces[0])\n",
        "# sample_verts, sample_faces = wt_verts[0], wt_faces[0]"
      ],
      "metadata": {
        "id": "SeRiCeTULDEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "wt_verts = ((wt_verts - center) / max_l)* 0.9\n",
        "timelapse.add_mesh_batch(\n",
        "    category='watertight_test',\n",
        "    vertices_list=[wt_verts.cpu()],\n",
        "    faces_list=[wt_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDF model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ],
      "metadata": {
        "id": "scLBY-eAaBUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "lr = 0.01\n",
        "laplacian_weight = 0.1\n",
        "iterations = 2000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ],
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "        self.multires = config['multires']\n",
        "\n",
        "        self.embed_fn = None\n",
        "        # if self.multires > 0:\n",
        "        #     embed_fn, input_ch = get_embedder(self.multires)\n",
        "        #     self.embed_fn = embed_fn\n",
        "        #     self.input_dim = input_ch\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.embed_fn is not None:\n",
        "            x = self.embed_fn(x)\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return sdf predicted + f_v feature vector\n",
        "\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 3,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim"
      ],
      "metadata": {
        "id": "cS9kStkdKQlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "print(sdf_model)\n",
        "print('\\n\\n')\n",
        "summary(sdf_model, input_size= tets_verts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLOS3kFWrd4n",
        "outputId": "80224ea2-98f9-4e94-d495-322f2a3d4ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1          [-1, 277410, 256]           1,024\n",
            "            Linear-2          [-1, 277410, 256]          65,792\n",
            "            Linear-3          [-1, 277410, 128]          32,896\n",
            "            Linear-4           [-1, 277410, 64]           8,256\n",
            "            Linear-5            [-1, 277410, 1]              65\n",
            "================================================================\n",
            "Total params: 108,033\n",
            "Trainable params: 108,033\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.17\n",
            "Forward/backward pass size (MB): 1492.11\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 1495.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Little Test:"
      ],
      "metadata": {
        "id": "k3RhnpiEL35m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sdfs, f_vs = sdf_model(tets_verts)\n",
        "\n",
        "print(f'Input grid shape is : {tets_verts.shape}')\n",
        "print(f'Output shape of the predicted SDFs should be {tets_verts.shape[0], 1} and it actually is {tuple(pred_sdfs.shape)}')\n",
        "print(f'Output shape of the feature vectors f_vs should be {tets_verts.shape[0], 64} and it actually is {tuple(f_vs.shape)}')\n",
        "print(pred_sdfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqcbsCj7L5eO",
        "outputId": "12c4f841-515b-4f86-ca81-40cc9d2bd10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid shape is : torch.Size([277410, 3])\n",
            "Output shape of the predicted SDFs should be (277410, 1) and it actually is (277410, 1)\n",
            "Output shape of the feature vectors f_vs should be (277410, 64) and it actually is (277410, 64)\n",
            "tensor([[0.1024],\n",
            "        [0.1021],\n",
            "        [0.1022],\n",
            "        ...,\n",
            "        [0.1006],\n",
            "        [0.1006],\n",
            "        [0.1006]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Optimizer"
      ],
      "metadata": {
        "id": "W_Dh9gJiTWEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "rENv3tMyTSdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "gf6lBBcPTcwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# takes in a module and applies the specified weight initialization\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "        values taken from a normal distribution.'''\n",
        "\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        y = m.in_features\n",
        "    # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
        "    # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "cDjptlAn_Biz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_model.apply(weights_init_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qoVPBuJ_EaA",
        "outputId": "c50d24fd-79f9-42e9-d786-0e12e1b0be65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hiddens): ModuleList(\n",
              "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
              "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sdf_train(iterations, model, optimizer, scheduler):\n",
        "  model.train()\n",
        "  gt_verts = wt_verts.to(device)\n",
        "  gt_faces = wt_faces.to(device)\n",
        "\n",
        "  f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "  gt_sdfs, idx, t = point_to_mesh_distance(tets_verts.unsqueeze(0), f)\n",
        "\n",
        "  sign = kaolin.ops.mesh.check_sign(gt_verts.unsqueeze(0).to(device), gt_faces.to(device), tets_verts.unsqueeze(0))\n",
        "  gt_sdfs[sign==False] *= -1\n",
        "\n",
        "  for it in range(iterations):\n",
        "      pred_sdfs, f_vs = model(tets_verts)\n",
        "      \n",
        "      loss = F.mse_loss(pred_sdfs, gt_sdfs.squeeze(0).unsqueeze(1), reduction='sum')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n"
      ],
      "metadata": {
        "id": "oSbqopQVh3yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~12 min. Speed up?\n",
        "sdf_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler)"
      ],
      "metadata": {
        "id": "MOLR1SY1IoFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354942d6-b473-4d97-9261-9064580e2482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 - loss: 0.011151010170578957\n",
            "Iteration 100 - loss: 5.3956679039401934e-05\n",
            "Iteration 200 - loss: 3.137449675705284e-05\n",
            "Iteration 300 - loss: 2.4316572307725437e-05\n",
            "Iteration 400 - loss: 1.9445456928224303e-05\n",
            "Iteration 500 - loss: 1.7838116036728024e-05\n",
            "Iteration 600 - loss: 1.8048469428322278e-05\n",
            "Iteration 700 - loss: 1.5522813555435278e-05\n",
            "Iteration 800 - loss: 1.5283503671525978e-05\n",
            "Iteration 900 - loss: 1.4500064025924075e-05\n",
            "Iteration 1000 - loss: 1.572274231875781e-05\n",
            "Iteration 1100 - loss: 1.3757760825683363e-05\n",
            "Iteration 1200 - loss: 1.3320885045686737e-05\n",
            "Iteration 1300 - loss: 1.3232168385002296e-05\n",
            "Iteration 1400 - loss: 1.2258676179044414e-05\n",
            "Iteration 1500 - loss: 1.1962479220528621e-05\n",
            "Iteration 1600 - loss: 1.1679520866891835e-05\n",
            "Iteration 1700 - loss: 1.1446755706856493e-05\n",
            "Iteration 1800 - loss: 1.1237471881031524e-05\n",
            "Iteration 1900 - loss: 1.1052374247810803e-05\n",
            "Iteration 1999 - loss: 1.2083042747690342e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Surface refinement utils"
      ],
      "metadata": {
        "id": "hIZbLWiqaL5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if thresh = 0, return all surface tetrahedrons\n",
        "# if thresh > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "def extract_tet(tets, sdf, thresh, non_surf=False):\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  if thresh == 0:\n",
        "    mask = sdf[tets] > 0\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (sdf[tets] >= -thresh) & (sdf[tets] <= thresh)\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    non_surf_tets = tets[t == 0]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n",
        "def get_pred_sdfs(model, tets_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pred_sdfs, f_vs = model(tets_verts)\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  d,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  d[s==True] *= -1\n",
        "\n",
        "  return d.squeeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check quality of sdf prediction"
      ],
      "metadata": {
        "id": "cfm6rGQnb3CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = get_gt_sdfs(wt_verts.unsqueeze(0).to(device), wt_faces.to(device), tets_verts.unsqueeze(0))"
      ],
      "metadata": {
        "id": "ICl3ftwOb_YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(d[d > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqID6g79ccNN",
        "outputId": "2070bce6-1350-4b39-bd66-3199f0f23ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1024, 0.1021, 0.1022,  ..., 0.1006, 0.1006, 0.1006], device='cuda:0')\n",
            "tensor([0.2277, 0.2311, 0.2158,  ..., 0.2419, 0.2374, 0.2313], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, d, 0)\n",
        "surf_tets_verts = tets_verts[surf_tets_verts_idx]\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "            category='tet_surface',\n",
        "            vertices_list=[surf_tets_verts.cpu()],\n",
        "            faces_list=[surf_tets_faces.cpu()]\n",
        "        )"
      ],
      "metadata": {
        "id": "6nAc-DFKb5rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Surface refinement model"
      ],
      "metadata": {
        "id": "NrEgkw5TksFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature\n"
      ],
      "metadata": {
        "id": "z9uLf6MBUn49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    m = pytorch3d.structures.Meshes([mesh_verts, gt_verts], [mesh_faces, gt_faces])\n",
        "  \n",
        "    # pc = pytorch3d.ops.sample_points_from_meshes(m, num_samples=50000)\n",
        "    pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 50000)[0][0]\n",
        "    gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 50000)[0][0]\n",
        "\n",
        "    # pred_points,gt_points = pc[0], pc[1]\n",
        "    chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0)).mean()\n",
        "    \n",
        "    norm = pytorch3d.loss.mesh_normal_consistency(m)\n",
        "    if it > iterations//2:\n",
        "      lap = pytorch3d.loss.mesh_laplacian_smoothing(m)\n",
        "      return 500*chamfer + lap * laplacian_weight + 1e-6*norm # + sdf_loss + deform_loss\n",
        "    return 500*chamfer + 1e-6*norm #+ sdf_loss + deform_loss"
      ],
      "metadata": {
        "id": "U5GGfOyM3NRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train GCN Model for Surface Refinement"
      ],
      "metadata": {
        "id": "Zzjoso_kziVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}\n",
        "\n",
        "# Same set of Hyperparam is applied\n",
        "lr = 1e-4\n",
        "laplacian_weight = 0.1\n",
        "gcn_iterations = 5000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ],
      "metadata": {
        "id": "6QO7CuxCzohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def gcn_pretrain(iterations, gcn_model, optimizer, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdf, thresh)\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = pred_sdf[surf_tets_verts_idx].detach()\n",
        "  surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "  \n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  # f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "\n",
        "  for it in tqdm(range(iterations)):\n",
        "    verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(verts_f, surf_tets_edges)\n",
        "\n",
        "    update_verts = surf_tets_verts + torch.tanh(deform) / grid_res\n",
        "    update_sdfs = surf_sdfs + sdf\n",
        "\n",
        "    gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_verts.unsqueeze(0))\n",
        "\n",
        "    sdf_loss = F.mse_loss(update_sdfs, gt_sdfs, reduction='mean')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    sdf_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "\n",
        "    if it == iterations-1:\n",
        "      print('Iteration {} - loss: {}'.format(iterations, sdf_loss))\n"
      ],
      "metadata": {
        "id": "QJ4L--ys4rh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Identify surface Tetrahedral\n",
        "input: f = [v, s, F_vol, f_64]\n",
        "output: f = [delta v, delta s, f_64]\n",
        "\n",
        "update v = v + delta v, s = s + delta s\n",
        "generate new meshes by marching tet from v and s; calculate loss\n",
        "\n",
        "loss = chamfer + sdf_loss + deform_loss\n",
        "\"\"\"\n",
        "from pytorch3d import loss\n",
        "\n",
        "def gcn_train(iterations, gcn_model, optimizer, scheduler, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Firstly, based on predicted sdf value, extract out all surface tetrahedrons\n",
        "  i.e. 1-3 vertices of tetrahedrons are with different sdf signs\n",
        "  return value: \n",
        "  --> surf_tets_idx: origin index of vertices as in tet grid\n",
        "  --> surf_tets_faces: reindexed faces list start from 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces, non_surf_idx, non_surf_tets = extract_tet(tets, pred_sdf, thresh, True)\n",
        "  surf_tets_edges = get_edges(surf_tets_faces).to(device)\n",
        "\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  # obtain per vertex features: \n",
        "  # sdf, position, feature vector\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = pred_sdf[surf_tets_verts_idx].detach()\n",
        "  surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "  non_surf_verts = torch.clone(tets_verts[non_surf_idx])\n",
        "\n",
        "  # calculate ground truth sdf value over all vertices in tet mesh\n",
        "\n",
        "  # gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces).to(device)\n",
        "  # gt_sdfs, _, _ = point_to_mesh_distance(tets_verts.unsqueeze(0), gt_f)\n",
        "  # gt_sdfs = gt_sdfs.squeeze(0).unsqueeze(1)\n",
        "\n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "  \n",
        "  gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "  for it in range(iterations):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Secondly, predict with a 2-layer GCN followed by 2-layer MLP\n",
        "    output:\n",
        "    --> [delta v, delta s, new f_s] \\in R^68\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    us = sdf.detach()\n",
        "    update_sdfs = torch.clone(pred_sdf)\n",
        "    update_sdfs[surf_tets_verts_idx] += us\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    vd = torch.tanh(deform).detach()\n",
        "    update_tets_verts = torch.clone(tets_verts)\n",
        "    update_tets_verts[surf_tets_verts_idx] += vd / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    vfvs = fv.detach()\n",
        "    update_tets_f = torch.clone(tets_verts_features)\n",
        "    update_tets_f[surf_tets_verts_idx] += vfvs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    # Calculate SDF non_surface tetrahedron in newly generated mesh\n",
        "\n",
        "    p_sdfs = get_gt_sdfs(mesh_verts.unsqueeze(0), mesh_faces, non_surf_verts.unsqueeze(0))\n",
        "\n",
        "    # Get ground truth SDF value of non_surface tetrahedron vertices and truncate at +- 0.3 to focus on surface\n",
        "\n",
        "    ns_g = gt_sdfs[non_surf_idx]\n",
        "    mask = (ns_g >= -0.3) & (ns_g <= 0.3)\n",
        "    p = p_sdfs[mask]\n",
        "    g = ns_g[mask]\n",
        "\n",
        "    # Also calculate surface sdf loss\n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts[surf_tets_verts_idx].unsqueeze(0), gt_f)\n",
        "\n",
        "    sdf_loss = F.mse_loss(sdf, s_sdfs - surf_sdfs, reduction='sum') #+F.mse_loss(p, g, reduction='sum') +\n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(deform, torch.zeros(deform.shape).to(device), reduction='sum')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it)\n",
        "\n",
        "    loss = r_loss + 0.4*sdf_loss + deform_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if (it) % save_every == 0 or it == (iterations - 1): \n",
        "      print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=it+1,\n",
        "          category='extracted_mesh',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )"
      ],
      "metadata": {
        "id": "5pn7Q89vgch9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d import loss\n",
        "\n",
        "def gcn_train_wsubdiv(iterations, gcn_model, optimizer, scheduler, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Firstly, based on predicted sdf value, extract out all surface tetrahedrons\n",
        "  i.e. 1-3 vertices of tetrahedrons are with different sdf signs\n",
        "  return value: \n",
        "  --> surf_tets_idx: origin index of vertices as in tet grid\n",
        "  --> surf_tets_faces: reindexed faces list start from 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Get surface and non-surface tetrahedron indices\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces, non_surf_idx, non_surf_tets = extract_tet(tets, pred_sdf, thresh, True)\n",
        "\n",
        "  # Use surface faces to obtain edge list\n",
        "\n",
        "  surf_tets_edges = get_edges(surf_tets_faces).to(device)\n",
        "\n",
        "\n",
        "  # Use surface indices obtain per vertex features: \n",
        "\n",
        "  # Surface vertices positions:\n",
        "\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  # Surface per vertex feature vector:\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "\n",
        "  # Surface per vertex predicted sdf value:\n",
        "\n",
        "  surf_sdfs = torch.clone(pred_sdf[surf_tets_verts_idx])\n",
        "\n",
        "  # Cat all features together as the input into model\n",
        "\n",
        "  surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "  # Obtain non_surface vertices position\n",
        "\n",
        "  non_surf_verts = torch.clone(tets_verts[non_surf_idx])\n",
        "\n",
        "  # Calculate ground truth sdf value over all vertices in tet mesh\n",
        "\n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "\n",
        "  gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "  for it in range(100):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Secondly, predict with a 2-layer GCN followed by 2-layer MLP\n",
        "    output:\n",
        "    --> [delta v, delta s, new f_s] \\in R^68\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    us = sdf.detach()\n",
        "    update_sdfs = torch.clone(pred_sdf)\n",
        "    update_sdfs[surf_tets_verts_idx] += us\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    vd = torch.tanh(deform).detach()\n",
        "    update_tets_verts = torch.clone(tets_verts)\n",
        "    update_tets_verts[surf_tets_verts_idx] += vd / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    vfvs = fv.detach()\n",
        "    update_tets_f = torch.clone(tets_verts_features)\n",
        "    update_tets_f[surf_tets_verts_idx] += vfvs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Volume subdivision:\n",
        "    Re-identify surface tets based on updated sdf value and subdivide identified surface tets\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract surface tetrahedrons based on updated sdf value\n",
        "\n",
        "    d_surf_tets_verts_idx, d_surf_tets_faces = extract_tet(tets, update_sdfs, thresh)\n",
        "    if d_surf_tets_faces.shape[0] == 0:\n",
        "      d_surf_tets_verts_idx, d_surf_tets_faces = surf_tets_verts_idx, surf_tets_faces\n",
        "\n",
        "    # Use new surface indices to get new surface vertices positions\n",
        "\n",
        "    d_surf_tets_verts = torch.clone(update_tets_verts[d_surf_tets_verts_idx])\n",
        "\n",
        "    # Use new surface indices to get new surface per vertex sdf and features\n",
        "\n",
        "    d_surf_tets_verts_features = torch.clone(update_tets_f[d_surf_tets_verts_idx])\n",
        "    d_surf_sdfs = torch.clone(update_sdfs[d_surf_tets_verts_idx])\n",
        "\n",
        "    # Cat new surface per vertex features together for subdivide\n",
        "\n",
        "    d_surf_verts_f = torch.cat((d_surf_sdfs, d_surf_tets_verts_features), dim=1)\n",
        "\n",
        "    # Perform subdivide, returns subdivided surface tetrahedron \n",
        "\n",
        "    d_tets_verts, d_tets_faces, d_tets_fvs = kaolin.ops.mesh.subdivide_tetmesh(d_surf_tets_verts.unsqueeze(0), d_surf_tets_faces, d_surf_verts_f.unsqueeze(0))\n",
        "    d_tets_verts, d_tets_fvs = d_tets_verts[0], d_tets_fvs[0]\n",
        "    d_tets_sdfs = d_tets_fvs[:, 0]\n",
        "\n",
        "\n",
        "    # Get surface edges from tetrahedron faces\n",
        "\n",
        "    d_tets_edges = get_edges(d_tets_faces).to(device)\n",
        "\n",
        "    # Cat to obtain feature input into GCN\n",
        "\n",
        "    d_tets_fvs = torch.cat((d_tets_verts, d_tets_fvs), dim=1)\n",
        "\n",
        "    d_sdf, d_deform, d_fv = gcn_model(d_tets_fvs, d_tets_edges)\n",
        "\n",
        "    # Updated sdf\n",
        "\n",
        "    d_update_sdfs = d_tets_sdfs.unsqueeze(1).detach() + d_sdf #since we need this to back propagate\n",
        "\n",
        "\n",
        "    # Update vertices positions\n",
        "\n",
        "    d_vd = torch.tanh(d_deform).detach()\n",
        "    d_update_tets_verts = d_tets_verts + d_vd / grid_res\n",
        "\n",
        "    # Update vertices features\n",
        "\n",
        "    d_vfvs = d_fv.detach()\n",
        "    d_update_tets_f = d_tets_fvs[:, 4:] + d_vfvs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(d_update_tets_verts.unsqueeze(0), d_tets_faces, d_update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    print(mesh_verts.shape, mesh_faces.shape)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    # Calculate SDF non_surface tetrahedron in newly generated mesh\n",
        "\n",
        "    p_sdfs = get_gt_sdfs(mesh_verts.unsqueeze(0), mesh_faces, non_surf_verts.unsqueeze(0))\n",
        "\n",
        "    # Get ground truth SDF value of non_surface tetrahedron vertices and truncate at +- 0.3 to focus on surface\n",
        "\n",
        "    ns_g = gt_sdfs[non_surf_idx]\n",
        "    mask = (ns_g >= -0.3) & (ns_g <= 0.3)\n",
        "    p = p_sdfs[mask]\n",
        "    g = ns_g[mask]\n",
        "\n",
        "    # Also calculate surface sdf loss\n",
        "\n",
        "    # s_sdfs, _, _ = point_to_mesh_distance(update_tets_verts[surf_tets_verts_idx].unsqueeze(0), gt_f)\n",
        "    # s_sign = kaolin.ops.mesh.check_sign(gt_verts.unsqueeze(0), gt_faces, update_tets_verts[surf_tets_verts_idx].unsqueeze(0))\n",
        "    # s_sdfs[s_sign==False] *= -1\n",
        "\n",
        "    # s_sdfs = s_sdfs.squeeze(0).unsqueeze(1)\n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, d_update_tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "    sdf_loss = F.mse_loss(p, g, reduction='sum') + F.mse_loss(d_update_sdfs, s_sdfs, reduction='sum')\n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(d_deform, torch.zeros(d_deform.shape).to(device), reduction='sum')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it)\n",
        "    \n",
        "    loss = r_loss + deform_loss + 0.4*sdf_loss \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    # print('Iteration {} - loss: {}'.format(it, loss))\n",
        "\n",
        "    if (it) % save_every == 0 or it == (iterations - 1): \n",
        "      print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=it+1,\n",
        "          category='extracted_mesh',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )"
      ],
      "metadata": {
        "id": "Oicuzl0WSHRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)\n",
        "\n",
        "pre_vars = [p for _, p in refine_model.named_parameters()]\n",
        "pre_optimizer = torch.optim.Adam(pre_vars, lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm5aud4mz6ZJ",
        "outputId": "02f985d6-4255-4375-a50e-6bf4871f74b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN_Res(\n",
            "  (gcn_res): ModuleList(\n",
            "    (0): GBottleneck(\n",
            "      (blocks): Sequential(\n",
            "        (0): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "        (1): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "      )\n",
            "      (conv1): GraphConv(68 -> 128, directed=False)\n",
            "    )\n",
            "  )\n",
            "  (sdf_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
            "  )\n",
            "  (deform_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=3, bias=False)\n",
            "  )\n",
            "  (feature_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=64, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sdfs, f_vs = get_pred_sdfs(sdf_model, tets_verts)\n",
        "print(extract_tet(tets, d, 0.001)[0].shape)\n",
        "print(sample_faces.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iADZ6VnsBTCJ",
        "outputId": "d2ed7759-8007-4296-b036-0219c86ca829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([24004])\n",
            "torch.Size([20212, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_pretrain(500, refine_model, pre_optimizer, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hlf1luSRwZ3",
        "outputId": "3dbc03c9-4f78-41ad-a8c0-56688167cadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:54<00:00,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 500 - loss: 0.011778036132454872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refine_vars = [p for _, p in refine_model.named_parameters()]\n",
        "refine_optimizer = torch.optim.Adam(pre_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(pre_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "i7ylyiYXI08J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_train(gcn_iterations, refine_model, refine_optimizer, refine_scheduler, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqEaSvssI8it",
        "outputId": "5173be30-f18b-49da-87a7-51fcf7f567ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 - loss: 58331108.0, # of mesh vertices: 45972, # of mesh faces: 92280\n",
            "Iteration 100 - loss: 5686.1953125, # of mesh vertices: 32120, # of mesh faces: 64288\n",
            "Iteration 200 - loss: 2095.136962890625, # of mesh vertices: 37072, # of mesh faces: 74232\n",
            "Iteration 300 - loss: 1226.7706298828125, # of mesh vertices: 40104, # of mesh faces: 80344\n",
            "Iteration 400 - loss: 826.2510986328125, # of mesh vertices: 41646, # of mesh faces: 83456\n",
            "Iteration 500 - loss: 606.0220336914062, # of mesh vertices: 42756, # of mesh faces: 85712\n",
            "Iteration 600 - loss: 483.702392578125, # of mesh vertices: 43730, # of mesh faces: 87688\n",
            "Iteration 700 - loss: 403.935546875, # of mesh vertices: 43978, # of mesh faces: 88204\n",
            "Iteration 800 - loss: 345.98272705078125, # of mesh vertices: 44520, # of mesh faces: 89300\n",
            "Iteration 900 - loss: 304.2041320800781, # of mesh vertices: 45170, # of mesh faces: 90652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_gcn = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "t_v = [p for _, p in test_gcn.named_parameters()]\n",
        "t_op = torch.optim.Adam(t_v, lr=lr)\n",
        "t_sch = torch.optim.lr_scheduler.LambdaLR(t_op, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "jhShD27xy42k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_pretrain(700, test_gcn, t_op, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-RPwOOP0bNH",
        "outputId": "86e00b6c-b780-440e-9c98-5af151429bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 700/700 [01:21<00:00,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 700 - loss: 0.006069199647754431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_train_wsubdiv(gcn_iterations, test_gcn, t_op, t_sch, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0)"
      ],
      "metadata": {
        "id": "WsUxitzdzEja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "to-dos: volume subdivision\n",
        "\n",
        "identify T_surf's neighbors: i.e. share a same edge\n",
        "\n",
        "subdivide T_surf to perform another surface refinement\n",
        "unsubdivded tet, i.e. not surface's neighbor, is dropped to save memory and computation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#neightbor if share an edge\n",
        "#identify edge based on surf_faces and adj matrix\n",
        "\n",
        "\"\"\"\n",
        "convert face_lists = [v1, v2, v3, v4] --> \n",
        "[\n",
        "  [v1, v2, v3, E, o1],\n",
        "  [v2, v3, v4, E, o2],\n",
        "  [v1, v2, v4, E, o3],\n",
        "  [v1, v3, v4, E, o4]\n",
        "]\n",
        "\n",
        "by torch combinations, E = tet index, o_i = face_i index\n",
        "\"\"\"\n",
        "def convert_face_lists(tets):\n",
        "  face_idx = torch.tensor([1,2,3,4])\n",
        "  tet_face_list = []\n",
        "  for idx, tet in enumerate(tets):\n",
        "    tet_idx = torch.full(4, idx)\n",
        "    tet_faces = torch.combinations(tet, r=3)\n",
        "    tet_faces = torch.cat((tet_faces, tet_idx, face_idx), dim=1)\n",
        "    tet_face_list.append(tet_faces)\n",
        "\n",
        "  tet_face_list = torch.stack(tet_face_list, dim=0)\n",
        "\n",
        "  def compare(face_1, face_2):\n",
        "    o1 = face_1[0]-face_2[0]\n",
        "    o2 = face_1[1]-face_2[1]\n",
        "    o3 = face_1[2]-face_2[2]\n",
        "\n",
        "    if o1 <= 0 or (o1 == 0 and o2 < 0) or (o1 == 0 and o2 == 0 and o3 < 0):\n",
        "      return -1\n",
        "    elif o1 == 0 and o2 == 0 and o3 == 0:\n",
        "      return 0\n",
        "    else: \n",
        "      return 1\n",
        "\n",
        "  sorted(tet_face_list, cmp=compare)\n",
        "  return tet_face_list\n",
        "\n",
        "def get_neighbor(surf_tet_verts, surf_tets, tet_verts, tets):\n",
        "  tet_face_list = convert_face_lists(tets)\n",
        "  \n",
        "\n",
        "surf_idx, surf = extract_tet(tets, pred_sdfs, 0.003)\n",
        "\n",
        "print(surf_idx)"
      ],
      "metadata": {
        "id": "tx0o-m2bukdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacb6685-4589-498e-a34b-7db665a76ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 83308,  83316,  83318,  ..., 216949, 216951, 216959], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_faces(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=3)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])"
      ],
      "metadata": {
        "id": "Too6Yu0KxrRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = get_faces(tets)\n",
        "b = get_faces(tets[surf_idx])\n",
        "\n",
        "for f in b:\n",
        "  mask = a == f\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_e-1rPxP3Ru9",
        "outputId": "791a3d67-bca0-42a2-e07f-f982f0ecc41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-6e04c434f11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msurf_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_faces' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "1H7RCV62USts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Hzzzh94FgOXssVkSP5Yffz8uYg_By2RMDZLTPx1aXakhYfH\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "id": "p68GrPqkUU07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ],
      "metadata": {
        "id": "rWJ2SS1EUYjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb82427a-de3c-4c7a-a962-73872f89ad48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking URL: NgrokTunnel: \"http://40b6-34-124-135-125.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ],
      "metadata": {
        "id": "9RZLd8x7UrUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e10245-7cbc-4845-d850-e1f5d7674c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash3D server starting. Go to: http://localhost:80\n",
            "2022-12-08 19:14:38,232|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-08 19:14:38,236|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-08 19:14:41,667|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-08 19:14:41,673|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-08 19:14:41,694|    INFO| tornado.access| 200 GET / (127.0.0.1) 40.24ms\n",
            "2022-12-08 19:14:42,142|    INFO| tornado.access| 200 GET /static/thirdparty.css (127.0.0.1) 3.64ms\n",
            "2022-12-08 19:14:42,145|    INFO| tornado.access| 200 GET /static/style.css (127.0.0.1) 2.07ms\n",
            "2022-12-08 19:14:42,174|    INFO| tornado.access| 200 GET /static/thirdparty.js (127.0.0.1) 5.18ms\n",
            "2022-12-08 19:14:42,179|    INFO| tornado.access| 200 GET /static/core-min.js (127.0.0.1) 9.98ms\n",
            "2022-12-08 19:14:43,887|    INFO| tornado.access| 200 GET /static/green_plastic.frag (127.0.0.1) 3.15ms\n",
            "2022-12-08 19:14:43,911|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 1.74ms\n",
            "2022-12-08 19:14:43,922|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-08 19:14:43,928|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-08 19:14:44,011|    INFO| tornado.access| 200 GET /static/favicon.ico (127.0.0.1) 3.29ms\n",
            "2022-12-08 19:14:44,142|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.76ms\n",
            "2022-12-08 19:14:45,431|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 3.18ms\n",
            "2022-12-08 19:14:49,027|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:14:49,031|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:14:56,581|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:14:56,586|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:14:59,677|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:14:59,682|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:15:03,402|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-08 19:15:03,407|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1823, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaolin-dash3d\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/kaolin-dash3d\", line 6, in <module>\n",
            "    run_main()\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/run.py\", line 97, in run_main\n",
            "    IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg/tornado/platform/asyncio.py\", line 199, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 578, in run_forever\n",
            "    sys.set_asyncgen_hooks(*old_agen_hooks)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prev Code"
      ],
      "metadata": {
        "id": "W6lqIYyxq_sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# # MLP + Positional Encoding\n",
        "# class Decoder(torch.nn.Module):\n",
        "#     def __init__(self, input_dims = 3, internal_dims = 128, output_dims = 4, hidden = 5, multires = 2):\n",
        "#         super().__init__()\n",
        "#         self.embed_fn = None\n",
        "#         if multires > 0:\n",
        "#             embed_fn, input_ch = get_embedder(multires)\n",
        "#             self.embed_fn = embed_fn\n",
        "#             input_dims = input_ch\n",
        "\n",
        "#         # net = (torch.nn.Linear(input_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "#         # for i in range(hidden-1):\n",
        "#         #     net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "#         # net = net + (torch.nn.Linear(internal_dims, output_dims, bias=False),)\n",
        "#         # self.net = torch.nn.Sequential(*net)\n",
        "\n",
        "#         self.net = torch.nn.Sequential(\n",
        "#             torch.nn.Linear(input_dims, 256, bias=False),\n",
        "#             torch.nn.ReLU(),\n",
        "#             torch.nn.Linear(256, 256, bias=False),\n",
        "#             torch.nn.ReLU(),\n",
        "#             torch.nn.Linear(256, 128, bias=False),\n",
        "#             torch.nn.ReLU(),\n",
        "#             torch.nn.Linear(128, 64, bias=False),\n",
        "#             torch.nn.ReLU(),\n",
        "#             torch.nn.Linear(64, output_dims, bias=False),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, p):\n",
        "#         if self.embed_fn is not None:\n",
        "#             p = self.embed_fn(p)\n",
        "#         print(p.shape)\n",
        "#         out = self.net(p)\n",
        "#         return out\n",
        "\n",
        "#     def pre_train_sphere(self, iter):\n",
        "#         print (\"Initialize SDF to sphere\")\n",
        "#         loss_fn = torch.nn.MSELoss()\n",
        "#         optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "\n",
        "#         for i in tqdm(range(iter)):\n",
        "#             p = torch.rand((1024,3), device='cuda') - 0.5\n",
        "#             ref_value  = torch.sqrt((p**2).sum(-1)) - 0.3\n",
        "#             output = self(p)\n",
        "#             loss = loss_fn(output[...,0], ref_value)\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#         print(\"Pre-trained MLP\", loss.item())\n",
        "\n",
        "\n",
        "# # Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "# class Embedder:\n",
        "#     def __init__(self, **kwargs):\n",
        "#         self.kwargs = kwargs\n",
        "#         self.create_embedding_fn()\n",
        "        \n",
        "#     def create_embedding_fn(self):\n",
        "#         embed_fns = []\n",
        "#         d = self.kwargs['input_dims']\n",
        "#         out_dim = 0\n",
        "#         if self.kwargs['include_input']:\n",
        "#             embed_fns.append(lambda x : x)\n",
        "#             out_dim += d\n",
        "            \n",
        "#         max_freq = self.kwargs['max_freq_log2']\n",
        "#         N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "#         if self.kwargs['log_sampling']:\n",
        "#             freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "#         else:\n",
        "#             freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "#         for freq in freq_bands:\n",
        "#             for p_fn in self.kwargs['periodic_fns']:\n",
        "#                 embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "#                 out_dim += d\n",
        "                    \n",
        "#         self.embed_fns = embed_fns\n",
        "#         self.out_dim = out_dim\n",
        "        \n",
        "#     def embed(self, inputs):\n",
        "#         return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "# def get_embedder(multires):\n",
        "#     embed_kwargs = {\n",
        "#                 'include_input' : True,\n",
        "#                 'input_dims' : 3,\n",
        "#                 'max_freq_log2' : multires-1,\n",
        "#                 'num_freqs' : multires,\n",
        "#                 'log_sampling' : True,\n",
        "#                 'periodic_fns' : [torch.sin, torch.cos],\n",
        "#     }\n",
        "    \n",
        "#     embedder_obj = Embedder(**embed_kwargs)\n",
        "#     embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "#     return embed, embedder_obj.out_dim"
      ],
      "metadata": {
        "id": "ooT3zo23rA62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_model = Decoder(multires=2).to(device)\n",
        "# pred = test_model(tets_verts)"
      ],
      "metadata": {
        "id": "ixiLERLsrDz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def sdf_train(iterations, model, optimizer):\n",
        "#   model.eval()\n",
        "#   for it in range(iterations):\n",
        "#       pred = model(tet_verts) # predict SDF and per-vertex deformation\n",
        "#       sdf, deform = pred[:,0], pred[:,1:]\n",
        "#       verts_deformed = tet_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
        "#       mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(verts_deformed.unsqueeze(0), tets, sdf.unsqueeze(0)) # running MT (batched) to extract surface mesh\n",
        "#       mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "#       loss = loss_f(mesh_verts, mesh_faces, sample_verts, sample_faces, it)\n",
        "#       optimizer.zero_grad()\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "#       scheduler.step()\n",
        "#       if (it) % save_every == 0 or it == (iterations - 1): \n",
        "#           print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "#           sign = kaolin.ops.mesh.check_sign(sample_verts.unsqueeze(0).to(device), sample_faces.to(device), verts_deformed.unsqueeze(0))[0]\n",
        "#           print(sign[sign == True])\n",
        "#           # save reconstructed mesh\n",
        "#           timelapse.add_mesh_batch(\n",
        "#               iteration=it+1,\n",
        "#               category='extracted_mesh',\n",
        "#               vertices_list=[mesh_verts.cpu()],\n",
        "#               faces_list=[mesh_faces.cpu()]\n",
        "#           )"
      ],
      "metadata": {
        "id": "24GAvO6IrKbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}