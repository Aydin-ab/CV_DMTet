{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aydin-ab/CV_DMTet/blob/main/DMTet_Tut_(David).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Af_jBwcMwG8"
      },
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x7VxtwyMthl",
        "outputId": "1e24b390-45a1-4dea-b8c4-db13ae6ab03d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "env: XDG_CACHE_HOME=/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, auth\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/MyDrive/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH\n",
        "%env XDG_CACHE_HOME=/content/drive/MyDrive/CV_DMTet"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAP99SJ8Fjpg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomq21yA4wP8",
        "outputId": "7443e067-1cff-483c-9106-71c83e8db76f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 0.29.20\n",
            "Uninstalling Cython-0.29.20:\n",
            "  Successfully uninstalled Cython-0.29.20\n"
          ]
        }
      ],
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "import torch\n",
        "# if not torch.__version__.startswith(\"1.12\"):\n",
        "#   !pip uninstall torch --yes\n",
        "# !pip install torch==1.12 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install  Cython==0.29.20  --quiet\n",
        "!pip install  usd-core --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2gnrsxeoc_W",
        "outputId": "b4bd2ef9-b593-40ed-d1a3-2966cc9e6796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: IGNORE_TORCH_VER=1\n",
            "env: KAOLIN_INSTALL_EXPERIMENTAL=1\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Checking if /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/version.py exists\n"
          ]
        }
      ],
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "!echo Checking if $SETUP_CHECK exists\n",
        "!if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "# !python -c \"import kaolin; print(kaolin.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWMtC40fLr1",
        "outputId": "159f7c17-cb49-4e54-eb2f-cbcb0a5fb93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup.py:36: UserWarning: Kaolin is compatible with PyTorch >=1.6.0, <=1.13.0, but found version 1.13.0+cu116. Continuing with the installed version as IGNORE_TORCH_VER is set.\n",
            "  warnings.warn(\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling kaolin/cython/ops/mesh/triangle_hash.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "Compiling kaolin/cython/ops/conversions/mise.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "[1/2] Cythonizing kaolin/cython/ops/conversions/mise.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/conversions/mise.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "[2/2] Cythonizing kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running develop\n",
            "running egg_info\n",
            "writing kaolin.egg-info/PKG-INFO\n",
            "writing dependency_links to kaolin.egg-info/dependency_links.txt\n",
            "writing requirements to kaolin.egg-info/requires.txt\n",
            "writing top-level names to kaolin.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'kaolin.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'kaolin.ops.mesh.triangle_hash' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/mesh/triangle_hash.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=triangle_hash -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:656\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_f_6kaolin_3ops_4mesh_13triangle_hash_12TriangleHash_query(__pyx_obj_6kaolin_3ops_4mesh_13triangle_hash_TriangleHash*, __Pyx_memviewslice, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2880:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2889:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so\n",
            "building 'kaolin.ops.conversions.mise' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/conversions/mise.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mise -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6kaolin_3ops_11conversions_4mise_4MISE_8get_points(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3476:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_10 = 0; \u001b[01;35m\u001b[K__pyx_t_10 < __pyx_t_9\u001b[m\u001b[K; __pyx_t_10+=1) {\n",
            "                        \u001b[01;35m\u001b[K~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid __pyx_f_6kaolin_3ops_11conversions_4mise_4MISE_subdivide_voxels(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3703:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3712:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3744:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3753:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K At global scope:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:15782:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyObject* __pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D(__pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " static PyObject* \u001b[01;35m\u001b[K__pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D\u001b[m\u001b[K(struct __pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D s) {\n",
            "                  \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/_C.so -> kaolin\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so -> kaolin/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so -> kaolin/ops/conversions\n",
            "Creating /usr/local/lib/python3.8/dist-packages/kaolin.egg-link (link to .)\n",
            "kaolin 0.12.0 is already the active version in easy-install.pth\n",
            "Installing kaolin-dash3d script to /usr/local/bin\n",
            "\n",
            "Installed /content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Processing dependencies for kaolin==0.12.0\n",
            "Searching for usd-core==22.5.post1\n",
            "Best match: usd-core 22.5.post1\n",
            "Processing usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "usd-core 22.5.post1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "Searching for Flask==2.0.3\n",
            "Best match: Flask 2.0.3\n",
            "Processing Flask-2.0.3-py3.8.egg\n",
            "Flask 2.0.3 is already the active version in easy-install.pth\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Flask-2.0.3-py3.8.egg\n",
            "Searching for tornado==6.1\n",
            "Best match: tornado 6.1\n",
            "Processing tornado-6.1-py3.8-linux-x86_64.egg\n",
            "tornado 6.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Pillow==9.3.0\n",
            "Best match: Pillow 9.3.0\n",
            "Processing Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Pillow 9.3.0 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Searching for scipy==1.7.2\n",
            "Best match: scipy 1.7.2\n",
            "Processing scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "scipy 1.7.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "Searching for itsdangerous==2.1.2\n",
            "Best match: itsdangerous 2.1.2\n",
            "Processing itsdangerous-2.1.2-py3.8.egg\n",
            "itsdangerous 2.1.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/itsdangerous-2.1.2-py3.8.egg\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Werkzeug==2.2.2\n",
            "Best match: Werkzeug 2.2.2\n",
            "Processing Werkzeug-2.2.2-py3.8.egg\n",
            "Werkzeug 2.2.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Werkzeug-2.2.2-py3.8.egg\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Processing Jinja2-3.1.2-py3.8.egg\n",
            "Jinja2 3.1.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Jinja2-3.1.2-py3.8.egg\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for MarkupSafe==2.1.1\n",
            "Best match: MarkupSafe 2.1.1\n",
            "Processing MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "MarkupSafe 2.1.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "Finished processing dependencies for kaolin==0.12.0\n"
          ]
        }
      ],
      "source": [
        "# !python setup.py install_lib install_scripts build\n",
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ItNJXfPQPA"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xI6uNv5JPP0i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        print(f\"version_str : {version_str}\")\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKhngPBlPbTs"
      },
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LWdkJJr1y_wW"
      },
      "outputs": [],
      "source": [
        "import pytorch3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G126GQfpf1nB"
      },
      "outputs": [],
      "source": [
        "# state_dict = torch.load('/content/drive/MyDrive/CV_DMTet/shapenet.pvcnn.c1.pth.tar')\n",
        "# state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yMSLuRoDPfkp"
      },
      "outputs": [],
      "source": [
        "sys.path.append(INSTALL_PATH / \"examples\")\n",
        "sys.path.append(INSTALL_PATH / \"examples\" / \"tutorial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aTCgE2WCPiAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88871309-ef1c-4dda-be0e-66ca5a232315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i3zs2M-kOA1z"
      },
      "outputs": [],
      "source": [
        "# # path to the point cloud to be reconstructed\n",
        "# pcd_path = KAOLIN_PATH / \"examples/samples/bear_pointcloud.usd\"\n",
        "# # path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# # We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-D0gGzDS3-7"
      },
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZbYIPn4OEuRV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oEEdkp9yFI2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LyIoND6-SxAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c5112c-b3aa-452e-e652-b84894d1ea40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e89bff709631>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  tets = torch.tensor(([np.load(KAOLIN_PATH / 'examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n"
          ]
        }
      ],
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load(KAOLIN_PATH / \"examples/samples/128_verts.npz\")['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load(KAOLIN_PATH / 'examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTFQbA5awlr"
      },
      "source": [
        "# Loading from ShapeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fxK5Qw4xay7g"
      },
      "outputs": [],
      "source": [
        "# Not using for now, using libigl tutorial x-cylinder below\n",
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "SYNSETS_IDS = ['02747177', '02801938', '02808440', '02818832', '02828884', '02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uhzpP8kua2Rm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf31486-b0f0-4f1d-8973-50035c1a2110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6038, 3])\n"
          ]
        }
      ],
      "source": [
        "mesh = shapenet_train[10]['mesh'] # change the index here for different models\n",
        "gt_verts = mesh[0].to(device)\n",
        "gt_faces = mesh[1].to(device)\n",
        "print(gt_verts.shape)\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[gt_verts.cpu()],\n",
        "    faces_list=[gt_faces.cpu()]\n",
        ")\n",
        "gt_sample = int(0.99*gt_verts.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RKRJZwFjPaPl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K8Cm7qVUA_hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c198643-b459-4c03-ddc1-2ad000089a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIBIGL_TUTORIAL_DATA: /content/drive/MyDrive/CV_DMTet/libigl-tutorial-data\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n"
          ]
        }
      ],
      "source": [
        "# Clone sample meshes from libigl tutorial 1x\n",
        "LIBIGL_TUTORIAL_DATA = INSTALL_PATH / \"libigl-tutorial-data\"\n",
        "print(f\"LIBIGL_TUTORIAL_DATA: {LIBIGL_TUTORIAL_DATA}\")\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $LIBIGL_TUTORIAL_DATA ]; then git clone --recursive https://github.com/libigl/libigl-tutorial-data.git; fi;\n",
        "%cd $KAOLIN_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wo9-f58yGLmK"
      },
      "outputs": [],
      "source": [
        "# Load cylinder (along x-axis) mesh (V,F) = (42,80)\n",
        "# mesh = kaolin.io.obj.import_mesh(LIBIGL_TUTORIAL_DATA / \"arm.obj\") #xcylinder.obj\n",
        "# gt_verts = mesh[0].to(device)\n",
        "# gt_faces = mesh[1].to(device)\n",
        "# timelapse.add_mesh_batch(\n",
        "#     category='gt',\n",
        "#     vertices_list=[gt_verts.cpu()],\n",
        "#     faces_list=[gt_faces.cpu()]\n",
        "# )\n",
        "# gt_sample = int(0.99*gt_verts.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xI0lLPcwF5LM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HjBnktJULzWd"
      },
      "outputs": [],
      "source": [
        "points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, gt_sample)[0][0]\n",
        "center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
        "max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
        "points = ((points - center) / max_l)* 0.9\n",
        "points.to(device)\n",
        "timelapse.add_pointcloud_batch(category='input',\n",
        "                               pointcloud_list=[points.cpu()], points_type = \"usd_geom_points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJG7i2wbHC7"
      },
      "source": [
        "# Convert model to watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "e93m-kdBHD7G"
      },
      "outputs": [],
      "source": [
        "# wt_grid\n",
        "# Convert mesh (V,F) to a voxel grid \n",
        "# voxels = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "#     vertices=mesh_verts.unsqueeze(0).to(device),\n",
        "#     faces=mesh_faces.to(device),\n",
        "#     resolution=16\n",
        "# )\n",
        "\n",
        "# # Convert the voxel grid back into a mesh as GroundTruth\n",
        "# # I am not sure this step is necessary\n",
        "# # The intention is to have mesh_vertices, mesh_faces for the voxel grid for loss function\n",
        "# wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(voxels)\n",
        "# wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "# max_gt_len = (mesh_verts.max(0)[0] - mesh_faces.min(0)[0]).max()\n",
        "# max_vox_len = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "# scale = max_gt_len / max_vox_len\n",
        "# center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "# wt_verts = ((wt_verts - center) * scale)\n",
        "\n",
        "# timelapse.add_mesh_batch(\n",
        "#     category='watertight_test',\n",
        "#     vertices_list=[wt_verts.cpu()],\n",
        "#     faces_list=[wt_faces.cpu()]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-iQiev1XYcD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Kaolin bear point cloud data (PCD) right now since tutorial uses PCD\n",
        "# pcd_path = KAOLIN_PATH / \"examples/samples/bear_pointcloud.usd\"\n",
        "# points = kaolin.io.usd.import_pointclouds(str(pcd_path))[0].points.to(device)\n",
        "# if points.shape[0] > 100000:\n",
        "#     idx = list(range(points.shape[0]))\n",
        "#     np.random.shuffle(idx)\n",
        "#     idx = torch.tensor(idx[:100000], device=points.device, dtype=torch.long)    \n",
        "#     points = points[idx]\n",
        "\n",
        "# # The reconstructed object needs to be slightly smaller than the grid to get watertight surface after MT.\n",
        "# # The idea is that we want our point cloud to expand since it will converge faster if all face expansions are outward.\n",
        "# center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
        "# max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
        "# points = ((points - center) / max_l)* 0.9\n",
        "# timelapse.add_pointcloud_batch(category='input',\n",
        "#                                pointcloud_list=[points.cpu()], points_type = \"usd_geom_points\")"
      ],
      "metadata": {
        "id": "LfFGWqUYTPqx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-S8nTTuCDzfF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEBw5esdYX__"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaolin.ops.conversions.voxelgrids_to_cubic_meshes(\n",
        "\n",
        "Convert voxelgrids to meshes by replacing each occupied voxel with a cuboid mesh (unit cube). Each cube has 8 vertices and 6 (for quadmesh) or 12 faces (for triangular mesh). Internal faces are ignored. If is_trimesh==True, this function performs the same operation as “Cubify” defined in the ICCV 2019 paper “Mesh R-CNN”: https://arxiv.org/abs/1906.02739.\n",
        "\n",
        "Parameters\n",
        "voxelgrids (torch.Tensor) – binary voxel array, of shape .\n",
        "\n",
        "is_trimesh (optional, bool) – if True, the outputs are triangular meshes. Otherwise quadmeshes are returned. Default: True.\n",
        "\n",
        "Returns\n",
        "The list of vertices for each mesh.\n",
        "\n",
        "The list of faces for each mesh.\n",
        "\n",
        "Return type\n",
        "(list[torch.Tensor], list[torch.LongTensor])"
      ],
      "metadata": {
        "id": "D5X80R95XgJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SeRiCeTULDEv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUbuf5PETHwp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Mc2UjaWTYqc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaolin.ops.conversions.marching_tetrahedra(vertices, tets, sdf, return_tet_idx=False)¶\n",
        "Convert discrete signed distance fields encoded on tetrahedral grids to triangle meshes using marching tetrahedra algorithm as described in An efficient method of triangulating equi-valued surfaces by using tetrahedral cells. The output surface is differentiable with respect to input vertex positions and the SDF values. For more details and example usage in learning, see Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis NeurIPS 2021.\n"
      ],
      "metadata": {
        "id": "BMbohHY-W8a_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scLBY-eAaBUf"
      },
      "source": [
        "# SDF model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "outputs": [],
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "ENCODER_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 800, 1600, 1600],\n",
        "    'output_dim' : 832, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}\n",
        "\n",
        "lr = 0.001\n",
        "laplacian_weight = 0.1\n",
        "iterations = 2000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_sdfs(model, tets_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pred, f_vs = model(tets_verts)\n",
        "    pred_sdfs = pred[0]\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  d,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  d[s==True] *= -1\n",
        "\n",
        "  return d.squeeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "IW8t7bl5IEKg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "cS9kStkdKQlC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from pytorch3d.utils import ico_sphere\n",
        "\n",
        "# Comes from the DMTet tutorial \n",
        "# MLP + Positional Encoding\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, input_dims = 3, internal_dims = 64, output_dims = 4, hidden = 5, multires = 2):\n",
        "        super().__init__()\n",
        "        self.embed_fn = None\n",
        "        if multires > 0:\n",
        "            embed_fn, input_ch = get_embedder(multires)\n",
        "            self.embed_fn = embed_fn\n",
        "            input_dims = input_ch\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        net = (torch.nn.Linear(input_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "        for i in range(hidden-1):\n",
        "            net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "        self.net = torch.nn.Sequential(*net)\n",
        "        self.output = torch.nn.Linear(internal_dims, output_dims, bias=False)\n",
        "\n",
        "    def forward(self, p):\n",
        "        if self.embed_fn is not None:\n",
        "            p = self.embed_fn(p)\n",
        "        p = self.net(p)\n",
        "        out = self.output(p)\n",
        "        return out, p\n",
        "    \n",
        "    def pre_train_sphere(self, iter):    \n",
        "        print (\"Initialize SDF to sphere\")\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "        \n",
        "\n",
        "        for i in tqdm(range(iter)):\n",
        "            p = torch.rand((1024, 3), device='cuda') - 0.5\n",
        "            ref_value  = torch.sqrt(((p+.5)**2).sum(-1)) - 0.3\n",
        "            output, _ = self(p)\n",
        "            loss = loss_fn(output[...,0], ref_value)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Pre-trained MLP\", loss.item())\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 3,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return output + last feature layer vector\n",
        "\n",
        "    def pre_train_sphere(self, iter):    \n",
        "        print (\"Initialize SDF to sphere\")\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "        \n",
        "\n",
        "        for i in tqdm(range(iter)):\n",
        "            p = torch.rand((1024,self.input_dim), device=device) - 0.5\n",
        "            ref_value  = torch.sqrt(((p+.5)**2).sum(-1)) - 0.3\n",
        "            output, _ = self(p)\n",
        "            loss = loss_fn(output[...,0], ref_value)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Pre-trained MLP\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "Pvc0K8laC3JJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f0564a-77e9-496a-e16c-f2b4e4712f9c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# # Initialize model and create optimizer\n",
        "sdf_model = Decoder(multires=2).to(device)\n",
        "sdf_model.pre_train_sphere(1000)\n",
        "# print(sdf_model)\n",
        "# print('\\n\\n')\n",
        "# summary(sdf_model, input_size=tets_verts.shape)"
      ],
      "metadata": {
        "id": "m_z6PaowshTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0aaf476-1820-4512-cff2-22ac19cc18f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 258.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 7.655046647414565e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5c_4VfPjEYp2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vafkQj0AEezj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KLOS3kFWrd4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e2c519-a914-4524-9a1a-f865e08d56fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1          [-1, 277410, 256]           1,024\n",
            "            Linear-2          [-1, 277410, 256]          65,792\n",
            "            Linear-3          [-1, 277410, 128]          32,896\n",
            "            Linear-4           [-1, 277410, 64]           8,256\n",
            "            Linear-5            [-1, 277410, 1]              65\n",
            "================================================================\n",
            "Total params: 108,033\n",
            "Trainable params: 108,033\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.17\n",
            "Forward/backward pass size (MB): 1492.11\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 1495.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "encoder_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "print(encoder_model)\n",
        "# print('\\n\\n')\n",
        "summary(encoder_model, input_size=tets_verts.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select SDF Model\n",
        "* sdf_model is standard MLP (all hidden dims are same) + f_v + comes with encoder deformer\n",
        "* encoder_model is from DMTet and encodes layers + f_v + no deformer"
      ],
      "metadata": {
        "id": "DPNokxTmjPZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = encoder_model"
      ],
      "metadata": {
        "id": "TDTokPx9jMHS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3RhnpiEL35m"
      },
      "source": [
        "Little Test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SqcbsCj7L5eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0b6464-b6eb-47d2-d8ca-cf89e1a5fdef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred shape is : torch.Size([277410, 1])\n",
            "Input grid shape is : torch.Size([277410, 3])\n"
          ]
        }
      ],
      "source": [
        "# signed distance fields encoded on tetrahedral grid\n",
        "\n",
        "# pred_sdfs dim = (tets_vertices.shape[0])\n",
        "# f_vs ie f_v feature vector\n",
        "\n",
        "# sdf, delta x_i, delta y_i, delta z_i, \n",
        "# sdf = binary occupancy of tetrahedron \n",
        "pred, _ = MODEL(tets_verts)\n",
        "print(f'pred shape is : {pred.shape}')\n",
        "\n",
        "# pred_sdfs, f_vs = sdf_model(tets_verts)\n",
        "\n",
        "print(f'Input grid shape is : {tets_verts.shape}')\n",
        "# print(f'Output shape of the predicted SDFs should be {tets_verts.shape[0], 1} and it actually is {tuple(pred_sdfs.shape)}')\n",
        "# print(f'Output shape of the feature vectors f_vs should be {tets_verts.shape[0], 64} and it actually is {tuple(f_vs.shape)}')\n",
        "# print(pred_sdfs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WeFlWiqDJrPK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2_4nDFUooHT3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeX6jmo_oERf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Dh9gJiTWEq"
      },
      "source": [
        "# Set up Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rENv3tMyTSdT"
      },
      "outputs": [],
      "source": [
        "sdf_vars = [p for _, p in MODEL.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf6lBBcPTcwd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cDjptlAn_Biz"
      },
      "outputs": [],
      "source": [
        "# # # # takes in a module and applies the specified weight initialization\n",
        "# def weights_init_normal(m):\n",
        "#     '''Takes in a module and initializes all linear layers with weight\n",
        "#         values taken from a normal distribution.'''\n",
        "#     classname = m.__class__.__name__\n",
        "#     # for every Linear layer in a model\n",
        "#     if classname.find('Linear') != -1:\n",
        "#         y = m.in_features\n",
        "#     # m.weight.data shoud be taken from a normal distribution\n",
        "#         m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
        "#         m.weight.data = torch.randint(-1,2,m.weight.shape)\n",
        "#     # m.bias.data should be 0\n",
        "#         if m.bias is not None:\n",
        "#           m.bias.data.fill_(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5qoVPBuJ_EaA"
      },
      "outputs": [],
      "source": [
        "# sdf_model.apply(weights_init_normal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sdf_model.net[10].weight.data"
      ],
      "metadata": {
        "id": "S5xGr21AjroK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "oSbqopQVh3yf"
      },
      "outputs": [],
      "source": [
        "# Laplacian regularization using umbrella operator (Fujiwara / Desbrun).\n",
        "# https://mgarland.org/class/geom04/material/smoothing.pdf\n",
        "from pytorch3d import loss\n",
        "def laplace_regularizer_const(pred_mesh_verts, pred_mesh_faces):\n",
        "    term = torch.zeros_like(pred_mesh_verts, device=device)\n",
        "    norm = torch.zeros_like(pred_mesh_verts[..., 0:1], device=device)\n",
        "\n",
        "    v0 = pred_mesh_verts[pred_mesh_faces[:, 0], :]\n",
        "    v1 = pred_mesh_verts[pred_mesh_faces[:, 1], :]\n",
        "    v2 = pred_mesh_verts[pred_mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def loss_f(pred_mesh_verts, pred_mesh_faces, pts, it):\n",
        "    num_samples = int(0.3 * pred_mesh_verts.shape[0])\n",
        "    pred_points = kaolin.ops.mesh.sample_points(pred_mesh_verts.unsqueeze(0), \n",
        "                                                pred_mesh_faces, num_samples)[0][0]\n",
        "    \n",
        "    chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), pts.unsqueeze(0)).mean()\n",
        "    # chamfer.clone().detach().requires_grad_(True)\n",
        "    if it > iterations//2:\n",
        "        lap = laplace_regularizer_const(pred_mesh_verts, pred_mesh_faces)\n",
        "        return chamfer + lap * laplacian_weight\n",
        "    return chamfer \n",
        "\n",
        "\n",
        "def sdf_train(iterations, model, optimizer, scheduler):\n",
        "  # Set to training mode\n",
        "  model.train()\n",
        "\n",
        "  for it in range(iterations):\n",
        "      pred, _ = model(tets_verts)\n",
        "      \n",
        "      # Replace pred_sdfs with the new SDF\n",
        "      # Replace deform with surface refinement \n",
        "\n",
        "      pred_sdfs, deform = pred[:,0], pred[:,1:]\n",
        "      verts_deformed = tets_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
        "      pred_mesh_verts, pred_mesh_faces = marching_tetrahedra(verts_deformed.unsqueeze(0), tets, pred_sdfs.unsqueeze(0))\n",
        "      pred_mesh_verts, pred_mesh_faces = pred_mesh_verts[0], pred_mesh_faces[0]\n",
        "\n",
        "      loss = loss_f(pred_mesh_verts, pred_mesh_faces, points, it)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n",
        "          # save reconstructed mesh\n",
        "          timelapse.add_mesh_batch(\n",
        "              iteration=it+1,\n",
        "              category='extracted_mesh',\n",
        "              vertices_list=[pred_mesh_verts.cpu()],\n",
        "              faces_list=[pred_mesh_faces.cpu()]\n",
        "          )\n",
        "\n",
        "def encoder_train(iterations, model, optimizer, scheduler, tv = None):\n",
        "  # Set to training mode\n",
        "  model.train()\n",
        "\n",
        "  if tv is None:\n",
        "    tv = tets_verts\n",
        "\n",
        "  for it in range(iterations):\n",
        "      pred_sdfs, _ = model(tv)\n",
        "      \n",
        "      gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0))\n",
        "\n",
        "      loss = F.mse_loss(pred_sdfs, gt_sdfs) \n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n",
        "          # save reconstructed mesh\n",
        "          # timelapse.add_mesh_batch(\n",
        "          #     iteration=it+1,\n",
        "          #     category='extracted_mesh',\n",
        "          #     vertices_list=[pred_mesh_verts.cpu()],\n",
        "          #     faces_list=[pred_mesh_faces.cpu()]\n",
        "          # )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "5bFm72fRWCyG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tfPUfWWCbCC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL.pre_train_sphere(1000)\n",
        "sdf_vars = [p for _, p in MODEL.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# ~12 min. Speed up?\n",
        "encoder_train(iterations, MODEL, sdf_optimizer, sdf_scheduler)\n",
        "# sdf_train(iterations, MODEL, sdf_optimizer, sdf_scheduler)"
      ],
      "metadata": {
        "id": "Fcw5NxASCxNk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "0cfc7dab-1ac6-422c-db40-de7baed9b025"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 319.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 9.1721612989204e-06\n",
            "Iteration 0 - loss: 0.4624950587749481\n",
            "Iteration 100 - loss: 0.00012578710447996855\n",
            "Iteration 200 - loss: 2.572278208390344e-05\n",
            "Iteration 300 - loss: 1.6134466932271607e-05\n",
            "Iteration 400 - loss: 1.3485100680554751e-05\n",
            "Iteration 500 - loss: 1.1769434422603808e-05\n",
            "Iteration 600 - loss: 1.0726682376116514e-05\n",
            "Iteration 700 - loss: 9.74570957623655e-06\n",
            "Iteration 800 - loss: 9.058786417881493e-06\n",
            "Iteration 900 - loss: 8.547104698664043e-06\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-51cd13c15d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msdf_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# LR decay over time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ~12 min. Speed up?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# sdf_train(iterations, MODEL, sdf_optimizer, sdf_scheduler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-eb8a3f521b5a>\u001b[0m in \u001b[0;36mencoder_train\u001b[0;34m(iterations, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mpred_sdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtets_verts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0mgt_sdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gt_sdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_verts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtets_verts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_sdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-ce09319ab4d7>\u001b[0m in \u001b[0;36mget_gt_sdfs\u001b[0;34m(gt_verts, gt_faces, points, f)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkaolin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_sign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_verts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOLR1SY1IoFk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIZbLWiqaL5d"
      },
      "source": [
        " # Surface refinement utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqLaXVlkBty-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3BDxwiZBfHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "outputs": [],
      "source": [
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if thresh = 0, return all surface tetrahedrons\n",
        "# if thresh > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "def extract_tet(tets, sdf, thresh, non_surf=False):\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  if thresh == 0:\n",
        "    mask = sdf[tets] > 0\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (sdf[tets] >= -thresh) & (sdf[tets] <= thresh)\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    if thresh == 0:\n",
        "      non_surf_tets = tets[~((t > 0) & (t < 4))]\n",
        "    else:\n",
        "      non_surf_tets = tets[t < 4]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred, f_vs = sdf_model(tets_verts)\n",
        "pred_sdfs = pred[:,0]\n",
        "d = get_gt_sdfs(gt_verts.unsqueeze(0).to(device), gt_faces.to(device), tets_verts.unsqueeze(0))\n",
        "pred_sdfs, _ = get_pred_sdfs(sdf_model, tets_verts)"
      ],
      "metadata": {
        "id": "2K3Oyhenh3FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-zgVu7bG1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nAc-DFKb5rd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrEgkw5TksFD"
      },
      "source": [
        "# Surface refinement model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9uLf6MBUn49"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        deform = torch.tanh(deform)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5GGfOyM3NRu"
      },
      "outputs": [],
      "source": [
        "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
        "    term = torch.zeros_like(mesh_verts)\n",
        "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
        "\n",
        "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
        "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
        "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    m = pytorch3d.structures.Meshes([mesh_verts, gt_verts], [mesh_faces, gt_faces])\n",
        "  \n",
        "    # pc = pytorch3d.ops.sample_points_from_meshes(m, num_samples=50000)\n",
        "    if mesh_verts.shape[0] > 0:\n",
        "      pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, gt_sample)[0][0]\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, gt_sample)[0][0]\n",
        "      # pred_points,gt_points = pc[0], pc[1]\n",
        "      chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), squared=False).mean()\n",
        "    else:\n",
        "      chamfer = 0\n",
        "\n",
        "\n",
        "    #chamfer, p_norms = pytorch3d.loss.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), point_reduction='sum')\n",
        "    # norm = torch.sum(1-torch.abs(p_norms))\n",
        "    Lnorm = pytorch3d.loss.mesh_normal_consistency(m)\n",
        "    if it > iterations//2:\n",
        "      lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
        "      return 500*chamfer + lap * laplacian_weight + 1e-6*Lnorm\n",
        "    return 500*chamfer + 1e-6*Lnorm "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzjoso_kziVb"
      },
      "source": [
        "# Train GCN Model for Surface Refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QO7CuxCzohb"
      },
      "outputs": [],
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}\n",
        "\n",
        "# Same set of Hyperparam is applied\n",
        "lr = 1e-4\n",
        "laplacian_weight = 0.1\n",
        "gcn_iterations = 5000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cl9-59QXoBte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWy-gnDBvaWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ4L--ys4rh2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def gcn_pretrain(iterations, gcn_model, optimizer, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdf, thresh)\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = pred_sdf[surf_tets_verts_idx]\n",
        "  surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "  \n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "\n",
        "  timelapse.add_mesh_batch(\n",
        "          category='tet_surface',\n",
        "          vertices_list=[surf_tets_verts.cpu()],\n",
        "          faces_list=[surf_tets_faces.cpu()]\n",
        "      )\n",
        "\n",
        "  for it in tqdm(range(iterations)):\n",
        "    verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(verts_f, surf_tets_edges)\n",
        "\n",
        "    update_verts = surf_tets_verts + deform / grid_res\n",
        "    update_sdfs = surf_sdfs + sdf\n",
        "\n",
        "    gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "    sdf_loss = F.mse_loss(sdf, gt_sdfs - surf_sdfs, reduction='sum')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    sdf_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "\n",
        "    if it == iterations-1:\n",
        "      print('Iteration {} - loss: {}'.format(iterations, sdf_loss))"
      ],
      "metadata": {
        "id": "UQk-b5sAL6Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Identify surface Tetrahedral\n",
        "input: f = [v, s, F_vol, f_64]\n",
        "output: f = [delta v, delta s, f_64]\n",
        "\n",
        "update v = v + delta v, s = s + delta s\n",
        "generate new meshes by marching tet from v and s; calculate loss\n",
        "\n",
        "loss = chamfer + sdf_loss + deform_loss\n",
        "\"\"\"\n",
        "\n",
        "def gcn_train(iterations, gcn_model, optimizer, scheduler, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Firstly, based on predicted sdf value, extract out all surface tetrahedrons\n",
        "  i.e. 1-3 vertices of tetrahedrons are with different sdf signs\n",
        "  return value: \n",
        "  --> surf_tets_idx: origin index of vertices as in tet grid\n",
        "  --> surf_tets_faces: reindexed faces list start from 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdf, thresh)\n",
        "  surf_tets_edges = get_edges(surf_tets_faces).to(device)\n",
        "\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  # obtain per vertex features: \n",
        "  # sdf, position, feature vector\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = torch.clone(pred_sdf[surf_tets_verts_idx])\n",
        "  surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "  # calculate ground truth sdf value over all vertices in tet mesh\n",
        "\n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "  \n",
        "  gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "  for it in tqdm(range(iterations)):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Secondly, predict with a 2-layer GCN followed by 2-layer MLP\n",
        "    output:\n",
        "    --> [delta v, delta s, new f_s] \\in R^68\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = torch.clone(pred_sdf)\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "    \n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    vd = deform\n",
        "    update_tets_verts = torch.clone(tets_verts)\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    vfvs = fv.detach()\n",
        "    update_tets_f = torch.clone(tets_verts_features)\n",
        "    update_tets_f[surf_tets_verts_idx] += vfvs\n",
        "\n",
        "    #test\n",
        "    MT_sdf = surf_sdfs + sdf\n",
        "    MT_verts = surf_tets_verts + deform\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    # s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts[surf_tets_verts_idx].unsqueeze(0), gt_f)\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "\n",
        "    sdf_loss = F.mse_loss(update_sdfs, s_sdfs, reduction='mean')\n",
        "\n",
        "    # #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='mean')\n",
        "\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it)\n",
        "\n",
        "    g_loss = r_loss + 0.4*sdf_loss + deform_loss \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if (it) % save_every == 0 or it == (iterations - 1): \n",
        "      print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=it+1,\n",
        "          category='train_res',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )"
      ],
      "metadata": {
        "id": "NBGRmGWDzOsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)\n",
        "\n",
        "pre_vars = [p for _, p in refine_model.named_parameters()]\n",
        "pre_optimizer = torch.optim.Adam(pre_vars, lr=lr)\n"
      ],
      "metadata": {
        "id": "mjynxhHk2w11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pn7Q89vgch9"
      },
      "outputs": [],
      "source": [
        "gcn_pretrain(500, refine_model, pre_optimizer, d, tets_verts, tets, f_vs, gt_verts, gt_faces, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refine_vars = [p for _, p in refine_model.named_parameters()]\n",
        "refine_optimizer = torch.optim.Adam(pre_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(pre_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "     "
      ],
      "metadata": {
        "id": "hRTcq_QatAfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sdfs, _ = get_pred_sdfs(sdf_model, tets_verts)"
      ],
      "metadata": {
        "id": "aPq9b5Qha7lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNTiNtIygrJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gcn_train(1000, refine_model, refine_optimizer, refine_scheduler, sdfs.unsqueeze(0), tets_verts, tets, f_vs, gt_verts, gt_faces, 0.001)"
      ],
      "metadata": {
        "id": "H_KBEdwytCc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IxqV7DVAM1DI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLsjyWXSJric"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oicuzl0WSHRE"
      },
      "outputs": [],
      "source": [
        "surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, sdfs, 0.001)\n",
        "E = get_edges(surf_tets_faces).to(device)\n",
        "refine_model(tets_verts, E)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Surface Refinement"
      ],
      "metadata": {
        "id": "xoE7xYCtM572"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm5aud4mz6ZJ"
      },
      "outputs": [],
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)\n",
        "\n",
        "pre_vars = [p for _, p in refine_model.named_parameters()]\n",
        "pre_optimizer = torch.optim.Adam(pre_vars, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iADZ6VnsBTCJ"
      },
      "outputs": [],
      "source": [
        "# pred_sdfs, _ = get_pred_sdfs(sdf_model, tets_verts)\n",
        "pred, features = sdf_model(tets_verts)\n",
        "pred_sdfs, deform = pred[:,0], pred[:,1:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtgAIHqJpIrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hlf1luSRwZ3"
      },
      "outputs": [],
      "source": [
        "gcn_pretrain(500, refine_model, pred_sdfs, tets_verts, tets,  0.001)\n",
        "# gcn_pretrain(2000, refine_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ylyiYXI08J"
      },
      "outputs": [],
      "source": [
        "refine_vars = [p for _, p in refine_model.named_parameters()]\n",
        "refine_optimizer = torch.optim.Adam(pre_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(pre_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KqpAj60k-ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqEaSvssI8it"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gcn_train(gcn_iterations, refine_model, refine_optimizer, refine_scheduler, pred_sdfs, tets_verts, tets, features, gt_verts, gt_faces, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhShD27xy42k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RPwOOP0bNH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsUxitzdzEja"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore"
      ],
      "metadata": {
        "id": "SuSL2XdvFEwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx0o-m2bukdz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "to-dos: volume subdivision\n",
        "\n",
        "identify T_surf's neighbors: i.e. share a same edge\n",
        "\n",
        "subdivide T_surf to perform another surface refinement\n",
        "unsubdivded tet, i.e. not surface's neighbor, is dropped to save memory and computation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#neightbor if share an edge\n",
        "#identify edge based on surf_faces and adj matrix\n",
        "\n",
        "\"\"\"\n",
        "convert face_lists = [v1, v2, v3, v4] --> \n",
        "[\n",
        "  [v1, v2, v3, E, o1],\n",
        "  [v2, v3, v4, E, o2],\n",
        "  [v1, v2, v4, E, o3],\n",
        "  [v1, v3, v4, E, o4]\n",
        "]\n",
        "\n",
        "by torch combinations, E = tet index, o_i = face_i index\n",
        "\"\"\"\n",
        "def convert_face_lists(tets):\n",
        "  face_idx = torch.tensor([1,2,3,4])\n",
        "  tet_face_list = []\n",
        "  for idx, tet in enumerate(tets):\n",
        "    tet_idx = torch.full(4, idx)\n",
        "    tet_faces = torch.combinations(tet, r=3)\n",
        "    tet_faces = torch.cat((tet_faces, tet_idx, face_idx), dim=1)\n",
        "    tet_face_list.append(tet_faces)\n",
        "\n",
        "  tet_face_list = torch.stack(tet_face_list, dim=0)\n",
        "\n",
        "  def compare(face_1, face_2):\n",
        "    o1 = face_1[0]-face_2[0]\n",
        "    o2 = face_1[1]-face_2[1]\n",
        "    o3 = face_1[2]-face_2[2]\n",
        "\n",
        "    if o1 <= 0 or (o1 == 0 and o2 < 0) or (o1 == 0 and o2 == 0 and o3 < 0):\n",
        "      return -1\n",
        "    elif o1 == 0 and o2 == 0 and o3 == 0:\n",
        "      return 0\n",
        "    else: \n",
        "      return 1\n",
        "\n",
        "  sorted(tet_face_list, cmp=compare)\n",
        "  return tet_face_list\n",
        "\n",
        "def get_neighbor(surf_tet_verts, surf_tets, tet_verts, tets):\n",
        "  tet_face_list = convert_face_lists(tets)\n",
        "  \n",
        "\n",
        "surf_idx, surf = extract_tet(tets, pred_sdfs, 0.003)\n",
        "\n",
        "print(surf_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Too6Yu0KxrRH"
      },
      "outputs": [],
      "source": [
        "def get_faces(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=3)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e-1rPxP3Ru9"
      },
      "outputs": [],
      "source": [
        "# a = get_faces(tets)\n",
        "# b = get_faces(tets[surf_idx])\n",
        "\n",
        "# # OPTIMIZE TF OUT OF THIS\n",
        "# for f in b:\n",
        "#   mask = a == f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDF Model and Interpolation"
      ],
      "metadata": {
        "id": "U6zin3bFFOuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Other idea is to use a Point Cloud Encoder to retrieve a feature vector from the output's activation."
      ],
      "metadata": {
        "id": "B9ptcCU-GJpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 800, 1600, 1600],\n",
        "    'output_dim' : 832, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}"
      ],
      "metadata": {
        "id": "P1yXmafcGF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return output + last feature layer vector"
      ],
      "metadata": {
        "id": "KsocgWHOFMX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pointnet = MLP(ENCODER_MLP_CONFIG)\n",
        "# pointnet = pointnet.to(device)\n",
        "\n",
        "# pc = pc.to(device)\n",
        "\n",
        "# print(pointnet)\n",
        "# print('\\n\\n')\n",
        "# summary(pointnet, input_size= pc.shape)"
      ],
      "metadata": {
        "id": "T7myzQgsFuI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpolate feature values on the grid"
      ],
      "metadata": {
        "id": "aZDz1X0XF1UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We* implement an inverse distance interpolation based on a K-NN algorithm :\n",
        "Given N known points and their features and a batch of M points with unknown features, the interpolator find the K nearest neigbors in the set N for each point of the batch M. Then it interpolates the features of the batch points M using an inverse distance weighting of the features of the K known neighbour points. \n",
        "\n",
        "K can be fine-tuned to balance efficiency and speed.\n",
        "\n",
        "Implementation can be found here\n",
        "https://stackoverflow.com/questions/3104781/inverse-distance-weighted-idw-interpolation-with-python"
      ],
      "metadata": {
        "id": "fqW_Z2I6F4Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree as KDTree\n",
        "    # http://docs.scipy.org/doc/scipy/reference/spatial.html\n",
        "\n",
        "__date__ = \"2010-11-09 Nov\"  # weights, doc\n",
        "\n",
        "#...............................................................................\n",
        "class Invdisttree:\n",
        "    \"\"\" inverse-distance-weighted interpolation using KDTree:\n",
        "invdisttree = Invdisttree( X, z )  -- data points, values\n",
        "interpol = invdisttree( q, nnear=3, eps=0, p=1, weights=None, stat=0 )\n",
        "    interpolates z from the 3 points nearest each query point q;\n",
        "    For example, interpol[ a query point q ]\n",
        "    finds the 3 data points nearest q, at distances d1 d2 d3\n",
        "    and returns the IDW average of the values z1 z2 z3\n",
        "        (z1/d1 + z2/d2 + z3/d3)\n",
        "        / (1/d1 + 1/d2 + 1/d3)\n",
        "        = .55 z1 + .27 z2 + .18 z3  for distances 1 2 3\n",
        "\n",
        "    q may be one point, or a batch of points.\n",
        "    eps: approximate nearest, dist <= (1 + eps) * true nearest\n",
        "    p: use 1 / distance**p\n",
        "    weights: optional multipliers for 1 / distance**p, of the same shape as q\n",
        "    stat: accumulate wsum, wn for average weights\n",
        "\n",
        "How many nearest neighbors should one take ?\n",
        "a) start with 8 11 14 .. 28 in 2d 3d 4d .. 10d; see Wendel's formula\n",
        "b) make 3 runs with nnear= e.g. 6 8 10, and look at the results --\n",
        "    |interpol 6 - interpol 8| etc., or |f - interpol*| if you have f(q).\n",
        "    I find that runtimes don't increase much at all with nnear -- ymmv.\n",
        "\n",
        "p=1, p=2 ?\n",
        "    p=2 weights nearer points more, farther points less.\n",
        "    In 2d, the circles around query points have areas ~ distance**2,\n",
        "    so p=2 is inverse-area weighting. For example,\n",
        "        (z1/area1 + z2/area2 + z3/area3)\n",
        "        / (1/area1 + 1/area2 + 1/area3)\n",
        "        = .74 z1 + .18 z2 + .08 z3  for distances 1 2 3\n",
        "    Similarly, in 3d, p=3 is inverse-volume weighting.\n",
        "\n",
        "Scaling:\n",
        "    if different X coordinates measure different things, Euclidean distance\n",
        "    can be way off.  For example, if X0 is in the range 0 to 1\n",
        "    but X1 0 to 1000, the X1 distances will swamp X0;\n",
        "    rescale the data, i.e. make X0.std() ~= X1.std() .\n",
        "\n",
        "A nice property of IDW is that it's scale-free around query points:\n",
        "if I have values z1 z2 z3 from 3 points at distances d1 d2 d3,\n",
        "the IDW average\n",
        "    (z1/d1 + z2/d2 + z3/d3)\n",
        "    / (1/d1 + 1/d2 + 1/d3)\n",
        "is the same for distances 1 2 3, or 10 20 30 -- only the ratios matter.\n",
        "In contrast, the commonly-used Gaussian kernel exp( - (distance/h)**2 )\n",
        "is exceedingly sensitive to distance and to h.\n",
        "\n",
        "    \"\"\"\n",
        "# anykernel( dj / av dj ) is also scale-free\n",
        "# error analysis, |f(x) - idw(x)| ? todo: regular grid, nnear ndim+1, 2*ndim\n",
        "\n",
        "    def __init__( self, X, z, leafsize=10, stat=0 ):\n",
        "        assert len(X) == len(z), \"len(X) %d != len(z) %d\" % (len(X), len(z))\n",
        "        self.tree = KDTree( X, leafsize=leafsize )  # build the tree\n",
        "        self.z = z\n",
        "        self.stat = stat\n",
        "        self.wn = 0\n",
        "        self.wsum = None;\n",
        "\n",
        "    def __call__( self, q, nnear=6, eps=0, p=1, weights=None ):\n",
        "            # nnear nearest neighbours of each query point --\n",
        "        q = np.asarray(q)\n",
        "        qdim = q.ndim\n",
        "        if qdim == 1:\n",
        "            q = np.array([q])\n",
        "        if self.wsum is None:\n",
        "            self.wsum = np.zeros(nnear)\n",
        "\n",
        "        self.distances, self.ix = self.tree.query( q, k=nnear, eps=eps )\n",
        "        interpol = np.zeros( (len(self.distances),) + np.shape(self.z[0]) )\n",
        "        jinterpol = 0\n",
        "        for dist, ix in zip( self.distances, self.ix ):\n",
        "            if nnear == 1:\n",
        "                wz = self.z[ix]\n",
        "            elif dist[0] < 1e-10:\n",
        "                wz = self.z[ix[0]]\n",
        "            else:  # weight z s by 1/dist --\n",
        "                w = 1 / dist**p\n",
        "                if weights is not None:\n",
        "                    w *= weights[ix]  # >= 0\n",
        "                w /= np.sum(w)\n",
        "                wz = np.dot( w, self.z[ix] )\n",
        "                if self.stat:\n",
        "                    self.wn += 1\n",
        "                    self.wsum += w\n",
        "            interpol[jinterpol] = wz\n",
        "            jinterpol += 1\n",
        "        return interpol if qdim > 1  else interpol[0]"
      ],
      "metadata": {
        "id": "r5WHgsIIF0sy"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test the interpolation by splitting the point cloud (of size 1000) into a \n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "known set of size N= 600 and an unknown batch of M= 400 points"
      ],
      "metadata": {
        "id": "OwsoSX9tF8Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INTERP_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 800, 1600, 1600],\n",
        "    'output_dim' : 832, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}\n",
        "\n",
        "\n",
        "pointnet = MLP(INTERP_MLP_CONFIG).to(device)\n",
        "print(pointnet)\n",
        "print('\\n\\n')\n",
        "summary(pointnet, input_size= points.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4Gg6_YJsAdM",
        "outputId": "cb6f15a7-7856-4671-f42d-be0022cebb80"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=800, bias=True)\n",
            "    (2): Linear(in_features=800, out_features=1600, bias=True)\n",
            "    (3): Linear(in_features=1600, out_features=1600, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=1600, out_features=832, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1            [-1, 5977, 256]           1,024\n",
            "            Linear-2            [-1, 5977, 800]         205,600\n",
            "            Linear-3           [-1, 5977, 1600]       1,281,600\n",
            "            Linear-4           [-1, 5977, 1600]       2,561,600\n",
            "            Linear-5            [-1, 5977, 832]       1,332,032\n",
            "================================================================\n",
            "Total params: 5,381,856\n",
            "Trainable params: 5,381,856\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.07\n",
            "Forward/backward pass size (MB): 232.02\n",
            "Params size (MB): 20.53\n",
            "Estimated Total Size (MB): 252.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pointnet = MLP(INTERP_MLP_CONFIG).to(device)\n",
        "pointnet.pre_train_sphere(1000)\n",
        "sdf_vars = [p for _, p in pointnet.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# ~12 min. Speed up?\n",
        "encoder_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler)\n",
        "\n",
        "pointnet.eval()\n",
        "f_vol, _ = pointnet(points)\n",
        "\n",
        "\n",
        "sample_known = points.squeeze()[:600] # shape 600 x 3. Set of N= 600 points with known features\n",
        "sample_unknown = points.squeeze()[600:] # shape 400x3. Batch of M= 400 points on which we will interpolate the features\n",
        "f_vol_known = f_vol.squeeze()[:600] # Shape 600 x 832. Set of the feature vectors F_vol of the set N\n",
        "f_vol_unknown = f_vol.squeeze()[600:] # Shape 400 x 832. Ground truth of F_vol for the batch M unknown points. Used to test the interpolation performance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qskzIevespSQ",
        "outputId": "fe4d0bfb-65cd-44f7-baa7-9f7481a9be87"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:15<00:00, 65.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 7.087472795319627e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-ac6b83eda0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msdf_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# LR decay over time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ~12 min. Speed up?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mencoder_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpointnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-be8e5e3b4705>\u001b[0m in \u001b[0;36mencoder_train\u001b[0;34m(iterations, model, optimizer, scheduler, tv)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0mpred_sdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mgt_sdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gt_sdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_verts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtets_verts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-635b1f17ff71>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# No activation (linear) cuz we do regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (277410x3 and 835x256)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_known = pc.squeeze()[:600] # shape 600 x 3. Set of N= 600 points with known features\n",
        "# sample_unknown = pc.squeeze()[600:] # shape 400x3. Batch of M= 400 points on which we will interpolate the features\n",
        "# f_vol_known = f_vol.squeeze()[:600] # Shape 600 x 832. Set of the feature vectors F_vol of the set N\n",
        "# f_vol_unknown = f_vol.squeeze()[600:] # Shape 400 x 832. Ground truth of F_vol for the batch M unknown points. Used to test the interpolation performance\n",
        "\n",
        "\n",
        "leafsize = 10 # leaf size of the KDTree. This means the KDTree will store \"leafsize\" number of neighbour points for each data point\n",
        "eps = .1  # approximate nearest, dist <= (1 + eps) * true nearest\n",
        "p = 1  # weights ~ 1 / distance**p\n",
        "Nnear = 8  # 8 2d, 11 3d => 5 % chance one-sided -- Wendel, mathoverflow.com\n",
        "\n",
        "\n",
        "invdisttree = Invdisttree( sample_known.squeeze().detach().cpu(), f_vol_known.squeeze().detach().cpu(), leafsize=leafsize, stat=1 )\n",
        "interpol = invdisttree( sample_unknown.detach().cpu(), nnear=Nnear, eps=eps, p=p ) # return numpy array\n",
        "\n",
        "# err = np.abs( f_vol_unknown.detach().numpy() - interpol )\n",
        "# print(\"average |ground_truth - interpolated|: %.2g\" % np.mean(err))"
      ],
      "metadata": {
        "id": "NZUzypIZGBE4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCWKQ1wDsoiU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we compute the F_vol interpolation on the grid vertices"
      ],
      "metadata": {
        "id": "Je8hhXqLYmPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tets_f_vol = invdisttree( tets_verts.detach().cpu(), nnear=Nnear, eps=eps, p=p ) # ~ 5-10sec\n",
        "tets_f_vol = torch.tensor(tets_f_vol, device=device, dtype=torch.float)"
      ],
      "metadata": {
        "id": "RXa2RPGOYk_F"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_input = torch.cat(tensors= (tets_f_vol, tets_verts), dim= 1)"
      ],
      "metadata": {
        "id": "-bS7jgfB0vQA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HafKuXZ0YrEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next part, add this to MLP Encoder"
      ],
      "metadata": {
        "id": "e7ZCP7BBYuXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 3 + 832, # Coordinates of the grid's vertices + F_vol dimension (concatenation)\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}\n",
        "sdf_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "sdf_model.pre_train_sphere(2000)\n",
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# ~12 min. Speed up?\n",
        "encoder_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler, tv=sdf_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "ZR7mJdk2uhI0",
        "outputId": "fff2d460-88fa-47c0-8b33-3a5d7508b9b1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:22<00:00, 90.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 0.35540616512298584\n",
            "Iteration 0 - loss: 29.653545379638672\n",
            "Iteration 100 - loss: 29.653545379638672\n",
            "Iteration 200 - loss: 29.653545379638672\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-6300b1e29c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msdf_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambdaLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# LR decay over time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ~12 min. Speed up?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mencoder_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdf_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msdf_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-be8e5e3b4705>\u001b[0m in \u001b[0;36mencoder_train\u001b[0;34m(iterations, model, optimizer, scheduler, tv)\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0mpred_sdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mgt_sdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gt_sdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_verts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtets_verts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_sdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-ce09319ab4d7>\u001b[0m in \u001b[0;36mget_gt_sdfs\u001b[0;34m(gt_verts, gt_faces, points, f)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkaolin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_sign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_verts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# pred_sdfs, f_vs = sdf_model(sdf_input)"
      ],
      "metadata": {
        "id": "jonGw_6AYw47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sChTVQkAt_UX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2XxoP2lY1Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7RCV62USts"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p68GrPqkUU07"
      },
      "outputs": [],
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Hzzzh94FgOXssVkSP5Yffz8uYg_By2RMDZLTPx1aXakhYfH\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWJ2SS1EUYjn"
      },
      "outputs": [],
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RZLd8x7UrUa"
      },
      "outputs": [],
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lqIYyxq_sN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooT3zo23rA62"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixiLERLsrDz3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24GAvO6IrKbC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9ZyP7cuGPR7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "R-D0gGzDS3-7",
        "NXJG7i2wbHC7",
        "xoE7xYCtM572",
        "SuSL2XdvFEwJ",
        "U6zin3bFFOuP"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}