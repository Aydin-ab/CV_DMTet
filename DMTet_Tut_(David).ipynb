{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aydin-ab/CV_DMTet/blob/main/DMTet_Tut_(David).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Af_jBwcMwG8"
      },
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x7VxtwyMthl",
        "outputId": "2c73f569-c8ef-483e-e1c7-66b8b850a60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, auth\n",
        "\n",
        "# from googleapiclient.discovery import build\n",
        "# auth.authenticate_user()\n",
        "# drive_service = build('drive', 'v3')\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/MyDrive/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomq21yA4wP8",
        "outputId": "8ccf2026-b463-4cfa-f37e-33f556652081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 0.29.20\n",
            "Uninstalling Cython-0.29.20:\n",
            "  Successfully uninstalled Cython-0.29.20\n"
          ]
        }
      ],
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "!pip install Cython==0.29.20  --quiet\n",
        "!pip install usd-core --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2gnrsxeoc_W",
        "outputId": "447f30d9-8e7a-4727-cbf5-49451707f06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: IGNORE_TORCH_VER=1\n",
            "env: KAOLIN_INSTALL_EXPERIMENTAL=1\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Checking if /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/version.py exists\n"
          ]
        }
      ],
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "!echo Checking if $SETUP_CHECK exists\n",
        "!if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "# !python -c \"import kaolin; print(kaolin.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWMtC40fLr1",
        "outputId": "918f3f69-b4d8-46c9-f520-a8a75876a9ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup.py:36: UserWarning: Kaolin is compatible with PyTorch >=1.6.0, <=1.13.0, but found version 1.13.0+cu116. Continuing with the installed version as IGNORE_TORCH_VER is set.\n",
            "  warnings.warn(\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling kaolin/cython/ops/mesh/triangle_hash.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "Compiling kaolin/cython/ops/conversions/mise.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "[1/2] Cythonizing kaolin/cython/ops/conversions/mise.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/conversions/mise.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "[2/2] Cythonizing kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running install_lib\n",
            "running build_py\n",
            "copying kaolin/version.py -> build/lib.linux-x86_64-3.8/kaolin\n",
            "running egg_info\n",
            "writing kaolin.egg-info/PKG-INFO\n",
            "writing dependency_links to kaolin.egg-info/dependency_links.txt\n",
            "writing requirements to kaolin.egg-info/requires.txt\n",
            "writing top-level names to kaolin.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'kaolin.egg-info/SOURCES.txt'\n",
            "copying kaolin/cython/ops/conversions/mise.cpp -> build/lib.linux-x86_64-3.8/kaolin/cython/ops/conversions\n",
            "copying kaolin/cython/ops/mesh/triangle_hash.cpp -> build/lib.linux-x86_64-3.8/kaolin/cython/ops/mesh\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'kaolin.ops.mesh.triangle_hash' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/mesh/triangle_hash.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=triangle_hash -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:656\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_f_6kaolin_3ops_4mesh_13triangle_hash_12TriangleHash_query(__pyx_obj_6kaolin_3ops_4mesh_13triangle_hash_TriangleHash*, __Pyx_memviewslice, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2880:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2889:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so\n",
            "building 'kaolin.ops.conversions.mise' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/conversions/mise.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mise -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6kaolin_3ops_11conversions_4mise_4MISE_8get_points(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3476:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_10 = 0; \u001b[01;35m\u001b[K__pyx_t_10 < __pyx_t_9\u001b[m\u001b[K; __pyx_t_10+=1) {\n",
            "                        \u001b[01;35m\u001b[K~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid __pyx_f_6kaolin_3ops_11conversions_4mise_4MISE_subdivide_voxels(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3703:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3712:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3744:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3753:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K At global scope:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:15782:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyObject* __pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D(__pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " static PyObject* \u001b[01;35m\u001b[K__pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D\u001b[m\u001b[K(struct __pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D s) {\n",
            "                  \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so -> /usr/local/lib/python3.8/dist-packages/kaolin/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so -> /usr/local/lib/python3.8/dist-packages/kaolin/ops/conversions\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.cpp -> /usr/local/lib/python3.8/dist-packages/kaolin/cython/ops/conversions\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.cpp -> /usr/local/lib/python3.8/dist-packages/kaolin/cython/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/version.py -> /usr/local/lib/python3.8/dist-packages/kaolin\n",
            "byte-compiling /usr/local/lib/python3.8/dist-packages/kaolin/version.py to version.cpython-38.pyc\n",
            "running install_scripts\n",
            "running build_scripts\n",
            "changing mode of build/scripts-3.8/kaolin-dash3d from 700 to 755\n",
            "changing mode of /usr/local/bin/kaolin-dash3d to 755\n",
            "running build\n"
          ]
        }
      ],
      "source": [
        "!python setup.py install_lib install_scripts build\n",
        "# !python setup.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ItNJXfPQPA"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xI6uNv5JPP0i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        print(f\"version_str : {version_str}\")\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKhngPBlPbTs"
      },
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LWdkJJr1y_wW"
      },
      "outputs": [],
      "source": [
        "import pytorch3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G126GQfpf1nB"
      },
      "outputs": [],
      "source": [
        "# state_dict = torch.load('/content/drive/MyDrive/CV_DMTet/shapenet.pvcnn.c1.pth.tar')\n",
        "# state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yMSLuRoDPfkp"
      },
      "outputs": [],
      "source": [
        "sys.path.append(INSTALL_PATH / \"examples\")\n",
        "sys.path.append(INSTALL_PATH / \"examples\" / \"tutorial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aTCgE2WCPiAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf07ca4-57ad-4d57-9eb7-8824ffff2a85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i3zs2M-kOA1z"
      },
      "outputs": [],
      "source": [
        "# # path to the point cloud to be reconstructed\n",
        "# pcd_path = KAOLIN_PATH / \"examples/samples/bear_pointcloud.usd\"\n",
        "# # path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# # We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-D0gGzDS3-7"
      },
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZbYIPn4OEuRV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oEEdkp9yFI2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LyIoND6-SxAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a978334-1815-403a-e1ee-d1c82c889ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load(KAOLIN_PATH / \"examples/samples/128_verts.npz\")['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load(KAOLIN_PATH / 'examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTFQbA5awlr"
      },
      "source": [
        "# Loading from ShapeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fxK5Qw4xay7g"
      },
      "outputs": [],
      "source": [
        "# Not using for now, using libigl tutorial x-cylinder below\n",
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "SYNSETS_IDS = ['02747177', '02801938', '02808440', '02818832', '02828884', '02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uhzpP8kua2Rm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1f7d86-d3e6-4a7d-a58c-fabb37a556b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6038, 3])\n"
          ]
        }
      ],
      "source": [
        "mesh = shapenet_train[10]['mesh'] # change the index here for different models\n",
        "gt_verts = mesh[0].to(device)\n",
        "gt_faces = mesh[1].to(device)\n",
        "print(gt_verts.shape)\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[gt_verts.cpu()],\n",
        "    faces_list=[gt_faces.cpu()]\n",
        ")\n",
        "gt_sample = int(0.99*gt_verts.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RKRJZwFjPaPl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K8Cm7qVUA_hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab14bde2-fc18-44b5-f7a7-2c6a6772f2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIBIGL_TUTORIAL_DATA: /content/drive/MyDrive/CV_DMTet/libigl-tutorial-data\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n"
          ]
        }
      ],
      "source": [
        "# Clone sample meshes from libigl tutorial 1x\n",
        "LIBIGL_TUTORIAL_DATA = INSTALL_PATH / \"libigl-tutorial-data\"\n",
        "print(f\"LIBIGL_TUTORIAL_DATA: {LIBIGL_TUTORIAL_DATA}\")\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $LIBIGL_TUTORIAL_DATA ]; then git clone --recursive https://github.com/libigl/libigl-tutorial-data.git; fi;\n",
        "%cd $KAOLIN_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Wo9-f58yGLmK"
      },
      "outputs": [],
      "source": [
        "# Load cylinder (along x-axis) mesh (V,F) = (42,80)\n",
        "mesh = kaolin.io.obj.import_mesh(LIBIGL_TUTORIAL_DATA / \"arm.obj\") #xcylinder.obj\n",
        "gt_verts = mesh[0].to(device)\n",
        "gt_faces = mesh[1].to(device)\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[gt_verts.cpu()],\n",
        "    faces_list=[gt_faces.cpu()]\n",
        ")\n",
        "gt_sample = int(0.99*gt_verts.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xI0lLPcwF5LM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HjBnktJULzWd"
      },
      "outputs": [],
      "source": [
        "points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, gt_sample)[0][0]\n",
        "center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
        "max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
        "points = ((points - center) / max_l)* 0.9\n",
        "points.to(device)\n",
        "timelapse.add_pointcloud_batch(category='input',\n",
        "                               pointcloud_list=[points.cpu()], points_type = \"usd_geom_points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJG7i2wbHC7"
      },
      "source": [
        "# Convert model to watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e93m-kdBHD7G"
      },
      "outputs": [],
      "source": [
        "# wt_grid\n",
        "# Convert mesh (V,F) to a voxel grid \n",
        "# voxels = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "#     vertices=mesh_verts.unsqueeze(0).to(device),\n",
        "#     faces=mesh_faces.to(device),\n",
        "#     resolution=16\n",
        "# )\n",
        "\n",
        "# # Convert the voxel grid back into a mesh as GroundTruth\n",
        "# # I am not sure this step is necessary\n",
        "# # The intention is to have mesh_vertices, mesh_faces for the voxel grid for loss function\n",
        "# wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(voxels)\n",
        "# wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "# max_gt_len = (mesh_verts.max(0)[0] - mesh_faces.min(0)[0]).max()\n",
        "# max_vox_len = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "# scale = max_gt_len / max_vox_len\n",
        "# center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "# wt_verts = ((wt_verts - center) * scale)\n",
        "\n",
        "# timelapse.add_mesh_batch(\n",
        "#     category='watertight_test',\n",
        "#     vertices_list=[wt_verts.cpu()],\n",
        "#     faces_list=[wt_faces.cpu()]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-iQiev1XYcD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Kaolin bear point cloud data (PCD) right now since tutorial uses PCD\n",
        "# pcd_path = KAOLIN_PATH / \"examples/samples/bear_pointcloud.usd\"\n",
        "# points = kaolin.io.usd.import_pointclouds(str(pcd_path))[0].points.to(device)\n",
        "# if points.shape[0] > 100000:\n",
        "#     idx = list(range(points.shape[0]))\n",
        "#     np.random.shuffle(idx)\n",
        "#     idx = torch.tensor(idx[:100000], device=points.device, dtype=torch.long)    \n",
        "#     points = points[idx]\n",
        "\n",
        "# # The reconstructed object needs to be slightly smaller than the grid to get watertight surface after MT.\n",
        "# # The idea is that we want our point cloud to expand since it will converge faster if all face expansions are outward.\n",
        "# center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
        "# max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
        "# points = ((points - center) / max_l)* 0.9\n",
        "# timelapse.add_pointcloud_batch(category='input',\n",
        "#                                pointcloud_list=[points.cpu()], points_type = \"usd_geom_points\")"
      ],
      "metadata": {
        "id": "LfFGWqUYTPqx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-S8nTTuCDzfF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEBw5esdYX__"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaolin.ops.conversions.voxelgrids_to_cubic_meshes(\n",
        "\n",
        "Convert voxelgrids to meshes by replacing each occupied voxel with a cuboid mesh (unit cube). Each cube has 8 vertices and 6 (for quadmesh) or 12 faces (for triangular mesh). Internal faces are ignored. If is_trimesh==True, this function performs the same operation as “Cubify” defined in the ICCV 2019 paper “Mesh R-CNN”: https://arxiv.org/abs/1906.02739.\n",
        "\n",
        "Parameters\n",
        "voxelgrids (torch.Tensor) – binary voxel array, of shape .\n",
        "\n",
        "is_trimesh (optional, bool) – if True, the outputs are triangular meshes. Otherwise quadmeshes are returned. Default: True.\n",
        "\n",
        "Returns\n",
        "The list of vertices for each mesh.\n",
        "\n",
        "The list of faces for each mesh.\n",
        "\n",
        "Return type\n",
        "(list[torch.Tensor], list[torch.LongTensor])"
      ],
      "metadata": {
        "id": "D5X80R95XgJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SeRiCeTULDEv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUbuf5PETHwp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Mc2UjaWTYqc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaolin.ops.conversions.marching_tetrahedra(vertices, tets, sdf, return_tet_idx=False)¶\n",
        "Convert discrete signed distance fields encoded on tetrahedral grids to triangle meshes using marching tetrahedra algorithm as described in An efficient method of triangulating equi-valued surfaces by using tetrahedral cells. The output surface is differentiable with respect to input vertex positions and the SDF values. For more details and example usage in learning, see Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis NeurIPS 2021.\n"
      ],
      "metadata": {
        "id": "BMbohHY-W8a_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scLBY-eAaBUf"
      },
      "source": [
        "# SDF model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "outputs": [],
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "lr = 0.001\n",
        "laplacian_weight = 0.1\n",
        "iterations = 2000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "cS9kStkdKQlC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "# Comes from the DMTet tutorial \n",
        "# MLP + Positional Encoding\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, input_dims = 3, internal_dims = 128, output_dims = 4, hidden = 5, multires = 2):\n",
        "        super().__init__()\n",
        "        self.embed_fn = None\n",
        "        if multires > 0:\n",
        "            embed_fn, input_ch = get_embedder(multires)\n",
        "            self.embed_fn = embed_fn\n",
        "            input_dims = input_ch\n",
        "\n",
        "        net = (torch.nn.Linear(input_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "        for i in range(hidden-1):\n",
        "            net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "        net = net + (torch.nn.Linear(internal_dims, output_dims, bias=False),)\n",
        "        self.net = torch.nn.Sequential(*net)\n",
        "\n",
        "    def forward(self, p):\n",
        "        if self.embed_fn is not None:\n",
        "            p = self.embed_fn(p)\n",
        "        out = self.net(p)\n",
        "        return out\n",
        "\n",
        "    def pre_train_sphere(self, iter):\n",
        "        print (\"Initialize SDF to sphere\")\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "        \n",
        "\n",
        "        for i in tqdm(range(iter)):\n",
        "            p = torch.rand((1024,3), device='cuda') - 0.5\n",
        "            ref_value  = torch.sqrt((p**2).sum(-1)) - 0.3\n",
        "            output = self(p)\n",
        "            loss = loss_fn(output[...,0], ref_value)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Pre-trained MLP\", loss.item())\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 3,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvc0K8laC3JJ",
        "outputId": "b8b9a28c-7518-4685-a627-ee115215ef92"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# # Initialize model and create optimizer\n",
        "sdf_model = Decoder(multires=2).to(device)\n",
        "sdf_model.pre_train_sphere(1000)\n",
        "# print(sdf_model)\n",
        "# print('\\n\\n')\n",
        "# summary(sdf_model, input_size=tets_verts.shape)"
      ],
      "metadata": {
        "id": "m_z6PaowshTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b60174e-3550-4e6c-ceb1-6b12b3203464"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 457.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 4.892159267910756e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "KLOS3kFWrd4n"
      },
      "outputs": [],
      "source": [
        "# sdf_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "# print(sdf_model)\n",
        "# print('\\n\\n')\n",
        "# summary(sdf_model, input_size=tets_verts.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3RhnpiEL35m"
      },
      "source": [
        "Little Test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SqcbsCj7L5eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756dc608-b944-44d9-f60f-0aa39e8e4b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred shape is : torch.Size([277410, 4])\n",
            "Input grid shape is : torch.Size([277410, 3])\n"
          ]
        }
      ],
      "source": [
        "# signed distance fields encoded on tetrahedral grid\n",
        "\n",
        "# pred_sdfs dim = (tets_vertices.shape[0])\n",
        "# f_vs ie f_v feature vector\n",
        "\n",
        "# sdf, delta x_i, delta y_i, delta z_i, \n",
        "# sdf = binary occupancy of tetrahedron \n",
        "pred = sdf_model(tets_verts)\n",
        "print(f'pred shape is : {pred.shape}')\n",
        "\n",
        "# pred_sdfs, f_vs = sdf_model(tets_verts)\n",
        "\n",
        "print(f'Input grid shape is : {tets_verts.shape}')\n",
        "# print(f'Output shape of the predicted SDFs should be {tets_verts.shape[0], 1} and it actually is {tuple(pred_sdfs.shape)}')\n",
        "# print(f'Output shape of the feature vectors f_vs should be {tets_verts.shape[0], 64} and it actually is {tuple(f_vs.shape)}')\n",
        "# print(pred_sdfs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WeFlWiqDJrPK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2_4nDFUooHT3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeX6jmo_oERf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Dh9gJiTWEq"
      },
      "source": [
        "# Set up Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rENv3tMyTSdT"
      },
      "outputs": [],
      "source": [
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf6lBBcPTcwd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cDjptlAn_Biz"
      },
      "outputs": [],
      "source": [
        "# # takes in a module and applies the specified weight initialization\n",
        "# def weights_init_normal(m):\n",
        "#     '''Takes in a module and initializes all linear layers with weight\n",
        "#         values taken from a normal distribution.'''\n",
        "\n",
        "#     classname = m.__class__.__name__\n",
        "#     # for every Linear layer in a model\n",
        "#     if classname.find('Linear') != -1:\n",
        "#         y = m.in_features\n",
        "#     # m.weight.data shoud be taken from a normal distribution\n",
        "#         m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
        "#     # m.bias.data should be 0\n",
        "#         m.bias.data.fill_(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5qoVPBuJ_EaA"
      },
      "outputs": [],
      "source": [
        "# sdf_model.apply(weights_init_normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "oSbqopQVh3yf"
      },
      "outputs": [],
      "source": [
        "# Laplacian regularization using umbrella operator (Fujiwara / Desbrun).\n",
        "# https://mgarland.org/class/geom04/material/smoothing.pdf\n",
        "from pytorch3d import loss\n",
        "def laplace_regularizer_const(pred_mesh_verts, pred_mesh_faces):\n",
        "    term = torch.zeros_like(pred_mesh_verts)\n",
        "    norm = torch.zeros_like(pred_mesh_verts[..., 0:1])\n",
        "\n",
        "    v0 = pred_mesh_verts[pred_mesh_faces[:, 0], :]\n",
        "    v1 = pred_mesh_verts[pred_mesh_faces[:, 1], :]\n",
        "    v2 = pred_mesh_verts[pred_mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def loss_f(pred_mesh_verts, pred_mesh_faces, pts, it):\n",
        "    # sample_number = mesh_verts.shape[0] * .5\n",
        "    pred_points = kaolin.ops.mesh.sample_points(pred_mesh_verts.unsqueeze(0), pred_mesh_faces, 50000)[0][0]\n",
        "    \n",
        "    chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), pts.unsqueeze(0)).mean()\n",
        "    # chamfer = loss.chamfer_distance(pred_points.unsqueeze(0), pts.unsqueeze(0))[0]\n",
        "    # print(chamfer)\n",
        "    # chamfer = torch.tensor(chamfer, requires_grad=True)\n",
        "    # chamfer.clone().detach().requires_grad_(True)\n",
        "    if it > iterations//2:\n",
        "        lap = laplace_regularizer_const(pred_mesh_verts, pred_mesh_faces)\n",
        "        return chamfer + lap * laplacian_weight\n",
        "    return chamfer \n",
        "\n",
        "\n",
        "def sdf_train(iterations, model, optimizer, scheduler):\n",
        "  # Set to training mode\n",
        "  model.train()\n",
        "\n",
        "  for it in range(iterations):\n",
        "      pred = model(tets_verts)\n",
        "      \n",
        "      # Replace pred_sdfs with the new SDF\n",
        "      # Replace deform with surface refinement \n",
        "\n",
        "      pred_sdfs, deform = pred[:,0], pred[:,1:]\n",
        "\n",
        "      \n",
        "      verts_deformed = tets_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
        "      # print(f\"verts_deformed : {verts_deformed.shape}\")\n",
        "\n",
        "      pred_mesh_verts, pred_mesh_faces = marching_tetrahedra(verts_deformed.unsqueeze(0), tets, pred_sdfs.unsqueeze(0))\n",
        "      pred_mesh_verts, pred_mesh_faces = pred_mesh_verts[0], pred_mesh_faces[0]\n",
        "      # print(f\"pred_mesh_verts empty: {pred_mesh_verts.nelement() == 0}\")\n",
        "      # print(f\"pred_sdfs : {pred_sdfs}\")\n",
        "      # print(f\"verts_deformed : {verts_deformed}\")\n",
        "      # print(f\"tets : {tets}\")\n",
        "      \n",
        "      loss = loss_f(pred_mesh_verts, pred_mesh_faces, points, it)\n",
        "      # print(loss.shape)\n",
        "      # loss = F.mse_loss(pred_sdfs, gt_sdfs.squeeze(0).unsqueeze(1), reduction='sum')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n",
        "          # save reconstructed mesh\n",
        "          timelapse.add_mesh_batch(\n",
        "              iteration=it+1,\n",
        "              category='extracted_mesh',\n",
        "              vertices_list=[pred_mesh_verts.cpu()],\n",
        "              faces_list=[pred_mesh_faces.cpu()]\n",
        "          )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bFm72fRWCyG"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tfPUfWWCbCC"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_model = Decoder(multires=2).to(device)\n",
        "sdf_model.pre_train_sphere(1000)\n",
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# ~12 min. Speed up?\n",
        "sdf_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcw5NxASCxNk",
        "outputId": "65053f37-ef11-441c-eb22-c254a18ffb6b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:02<00:00, 448.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 5.996178970235633e-06\n",
            "Iteration 0 - loss: 0.056564778089523315\n",
            "Iteration 100 - loss: 0.00035423709778115153\n",
            "Iteration 200 - loss: 0.0001338023430434987\n",
            "Iteration 300 - loss: 7.230698247440159e-05\n",
            "Iteration 400 - loss: 6.221563671715558e-05\n",
            "Iteration 500 - loss: 4.6070210373727605e-05\n",
            "Iteration 600 - loss: 4.5048262109048665e-05\n",
            "Iteration 700 - loss: 3.970160105382092e-05\n",
            "Iteration 800 - loss: 3.556008232408203e-05\n",
            "Iteration 900 - loss: 0.0007746580522507429\n",
            "Iteration 1000 - loss: 0.00108240672852844\n",
            "Iteration 1100 - loss: 0.00017891003517434\n",
            "Iteration 1200 - loss: 6.203664815984666e-05\n",
            "Iteration 1300 - loss: 0.00010509687854209915\n",
            "Iteration 1400 - loss: 5.496963785844855e-05\n",
            "Iteration 1500 - loss: 4.85259442939423e-05\n",
            "Iteration 1600 - loss: 4.529577199718915e-05\n",
            "Iteration 1700 - loss: 4.188844468444586e-05\n",
            "Iteration 1800 - loss: 3.8608737668255344e-05\n",
            "Iteration 1900 - loss: 3.71672649635002e-05\n",
            "Iteration 1999 - loss: 0.00017360292258672416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "MOLR1SY1IoFk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIZbLWiqaL5d"
      },
      "source": [
        " # Surface refinement utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqLaXVlkBty-"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3BDxwiZBfHQ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "outputs": [],
      "source": [
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if eps = 0, return all surface tetrahedrons\n",
        "# if eps > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "# return all tetrahedrons whose 4 vertices i = [0,1,2,3] have abs(sdf(v[i])) <= eps\n",
        "\n",
        "def extract_surf_tets(tets, sdf, eps=0, non_surf=False):\n",
        "\n",
        "  assert eps >= 0\n",
        "\n",
        "  if eps == 0:\n",
        "    mask = (sdf[tets] > 0)\n",
        "    mask_int = mask.long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (abs(sdf[tets]) <= eps)\n",
        "    mask_int = mask.long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    non_surf_tets = tets[t == 0]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n",
        "def get_pred_sdfs(model, tets_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pred_sdfs, f_vs = model(tets_verts)\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  sdf,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  sdf = sdf[s == True]\n",
        "\n",
        "  return sdf.squeeze(0).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = sdf_model(tets_verts)\n",
        "pred_sdfs = pred[:,0]\n",
        "# print(pred_sdfs.shape)\n",
        "# mask = (torch.abs(pred_sdfs) <= 3e-1)\n",
        "# masked_tets = mask[tets].long()\n",
        "# masked_tets.sum(1)"
      ],
      "metadata": {
        "id": "2K3Oyhenh3FO"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_sdfs[abs(pred_sdfs) <= 1e-3]"
      ],
      "metadata": {
        "id": "g-zgVu7bG1XU"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "6nAc-DFKb5rd"
      },
      "outputs": [],
      "source": [
        "# surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, eps=0)\n",
        "# surf_tets_verts = tets_verts[surf_tets_verts_idx]\n",
        "surf_tets_verts_idx, surf_tets_faces = extract_surf_tets(tets, pred_sdfs, eps=0)\n",
        "surf_tets_verts = tets_verts[surf_tets_verts_idx]\n",
        "    \n",
        "timelapse.add_mesh_batch(\n",
        "            category='tet_surface',\n",
        "            vertices_list=[surf_tets_verts.cpu()],\n",
        "            faces_list=[surf_tets_faces.cpu()]\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrEgkw5TksFD"
      },
      "source": [
        "# Surface refinement model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "z9uLf6MBUn49"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "U5GGfOyM3NRu"
      },
      "outputs": [],
      "source": [
        "lambda_cd = 500\n",
        "lambda_norm = 1e-6\n",
        "lambda_def = 1\n",
        "lamdba_sdf = 0.4\n",
        "\n",
        "def gcn_loss(iterations, pred_verts, pred_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    m = pytorch3d.structures.Meshes([pred_verts, gt_verts], [pred_faces, gt_faces])\n",
        "  \n",
        "    # pc = pytorch3d.ops.sample_points_from_meshes(m, num_samples=50000)\n",
        "    pred_points = kaolin.ops.mesh.sample_points(pred_verts.unsqueeze(0), pred_faces, 50000)[0][0]\n",
        "    gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 50000)[0][0]\n",
        "\n",
        "    # pred_points,gt_points = pc[0], pc[1]\n",
        "    Lcd = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0)).mean()\n",
        "    # chamfer.clone().detach().requires_grad_(True)\n",
        "    \n",
        "    Lnorm = pytorch3d.loss.mesh_normal_consistency(m)\n",
        "    if it > iterations//2:\n",
        "      lap = pytorch3d.loss.mesh_laplacian_smoothing(m)\n",
        "      return lambda_cd*Lcd + lap * laplacian_weight + lambda_norm*Lnorm # + sdf_loss + deform_loss\n",
        "    return lambda_cd*Lcd + lambda_norm*Lnorm #+ sdf_loss + deform_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzjoso_kziVb"
      },
      "source": [
        "# Train GCN Model for Surface Refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "6QO7CuxCzohb"
      },
      "outputs": [],
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}\n",
        "\n",
        "# Same set of Hyperparam is applied\n",
        "lr = 1e-4\n",
        "laplacian_weight = 0.1\n",
        "gcn_iterations = 5000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = torch.rand((2,3), device='cuda') - 0.5 # -.5 to .5\n",
        "print(p)\n",
        "ref_value  = torch.sqrt((p**2).sum(-1)) - .3\n",
        "ref_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl9-59QXoBte",
        "outputId": "eceead6f-9933-479c-d259-8fb4c9639ba3"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4506,  0.3199,  0.0129],\n",
            "        [-0.0751,  0.2240, -0.0084]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2528, -0.0636], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = sdf_model(p)\n",
        "print(output)\n",
        "print(output[...,0]) #gets the 1st column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWy-gnDBvaWw",
        "outputId": "d901bbd7-9c71-4fb4-d936-cdf422d05a26"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4844, -0.1064,  0.6909, -0.4993],\n",
            "        [ 0.2055, -0.0546,  0.2990, -0.2611]], device='cuda:0',\n",
            "       grad_fn=<MmBackward0>)\n",
            "tensor([0.4844, 0.2055], device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "QJ4L--ys4rh2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def pre_train_sphere(self, iter):\n",
        "  print (\"Initialize SDF to sphere\")\n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "  \n",
        "\n",
        "  for i in tqdm(range(iter)):\n",
        "      p = torch.rand((1024,3), device='cuda') - 0.5\n",
        "      ref_value  = torch.sqrt((p**2).sum(-1)) - 0.3\n",
        "      output = self(p)\n",
        "      loss = loss_fn(output[...,0], ref_value)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  print(\"Pre-trained MLP\", loss.item())\n",
        "\n",
        "# Spheres centered at (0,0,0) with radius=1\n",
        "# https://math.stackexchange.com/questions/1784106/how-do-i-compute-the-closest-points-on-a-sphere-given-a-point-outside-the-sphere\n",
        "# dist = sdf = sqrt(a^2 + b^2 + c^2)\n",
        "# Why do we subtract 0.3 though??\n",
        "# dir = deform = (- a/dist, -b/dist, -c/dist)\n",
        "def gcn_pretrain(iterations, gcn_model, pred_sdf, tets_verts, tets, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "  \n",
        "  loss_fn = torch.nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(list(gcn_model.parameters()), lr=1e-4)\n",
        "  \n",
        "  # Random feature vector\n",
        "  tets_verts_features = torch.zeros((tets_verts.shape[0],64), device=device)\n",
        "\n",
        "  # p = torch.rand((pred_sdf.shape[0],3), device='cuda')*2 - 0.5\n",
        "  ref_sdf  = torch.sqrt((tets_verts**2).sum(-1)) - 0.3 #sdf\n",
        "  ref_deform = - tets_verts / ref_sdf.unsqueeze(1) #deform\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces = extract_surf_tets(tets, pred_sdf, thresh)\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "  print(f\"surf_tets_verts_idx : {surf_tets_verts_idx}\")\n",
        "\n",
        "  # Correcting for surface\n",
        "  ref_sdf = ref_sdf[surf_tets_verts_idx]\n",
        "  ref_deform = ref_deform[surf_tets_verts_idx]\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = pred_sdf[surf_tets_verts_idx].detach()\n",
        "  surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "  print(f\"surf_tets_edges : {surf_tets_edges.shape}\")\n",
        "  \n",
        "  for it in tqdm(range(iterations)):\n",
        "    verts_f = torch.cat((surf_tets_verts, surf_sdfs.unsqueeze(1), surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(verts_f, surf_tets_edges)\n",
        "\n",
        "    update_verts = surf_tets_verts + torch.tanh(deform) / grid_res\n",
        "    update_sdfs = surf_sdfs + sdf\n",
        "    # print(update_sdfs.shape)\n",
        "    # print(ref_sdf.shape)\n",
        "\n",
        "    # loss = F.mse_loss(update_sdfs, ref_sdf, reduction='mean')\n",
        "    loss = loss_fn(update_sdfs, ref_sdf)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Pre-trained GCN\", loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "pred = sdf_model(tets_verts)\n",
        "pred_sdf = pred[:,0]\n",
        "gcn_pretrain(1000, refine_model, pred_sdf, tets_verts, tets, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBGRmGWDzOsd",
        "outputId": "e56f8336-7ddf-484c-e2ad-9d6b9779e894"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "surf_tets_verts_idx : tensor([ 64469,  64472,  64477,  ..., 242053, 242305, 242313], device='cuda:0')\n",
            "surf_tets_edges : torch.Size([168174, 2])\n",
            "torch.Size([9933, 3])\n",
            "torch.Size([9933, 1])\n",
            "torch.Size([9933, 1, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:30<00:00, 32.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained GCN 4.0547922253608704e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "5pn7Q89vgch9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Identify surface Tetrahedral\n",
        "input: f = [v, s, F_vol, f_64]\n",
        "output: f = [delta v, delta s, f_64]\n",
        "\n",
        "update v = v + delta v, s = s + delta s\n",
        "generate new meshes by marching tet from v and s; calculate loss\n",
        "\n",
        "loss = chamfer + sdf_loss + deform_loss\n",
        "\"\"\"\n",
        "from pytorch3d import loss\n",
        "\n",
        "def gcn_train(iterations, gcn_model, optimizer, scheduler, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Firstly, based on predicted sdf value, extract out all surface tetrahedrons\n",
        "  i.e. 1-3 vertices of tetrahedrons are with different sdf signs\n",
        "  return value: \n",
        "  --> surf_tets_idx: origin index of vertices as in tet grid\n",
        "  --> surf_tets_faces: reindexed faces list start from 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces, non_surf_idx, non_surf_tets = extract_surf_tets(tets, pred_sdf, thresh, True)\n",
        "  surf_tets_edges = get_edges(surf_tets_faces).to(device)\n",
        "\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  # obtain per vertex features: \n",
        "  # sdf, position, feature vector\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = pred_sdf[surf_tets_verts_idx].detach()\n",
        "  surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "  non_surf_verts = torch.clone(tets_verts[non_surf_idx])\n",
        "\n",
        "  # calculate ground truth sdf value over all vertices in tet mesh\n",
        "\n",
        "  # gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces).to(device)\n",
        "  # gt_sdfs, _, _ = point_to_mesh_distance(tets_verts.unsqueeze(0), gt_f)\n",
        "  # gt_sdfs = gt_sdfs.squeeze(0).unsqueeze(1)\n",
        "\n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "  \n",
        "  gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "  for it in range(iterations):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Secondly, predict with a 2-layer GCN followed by 2-layer MLP\n",
        "    output:\n",
        "    --> [delta v, delta s, new f_s] \\in R^68\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    us = sdf.detach()\n",
        "    update_sdfs = torch.clone(pred_sdf)\n",
        "    update_sdfs[surf_tets_verts_idx] += us\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    vd = torch.tanh(deform).detach()\n",
        "    update_tets_verts = torch.clone(tets_verts)\n",
        "    update_tets_verts[surf_tets_verts_idx] += vd / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    vfvs = fv.detach()\n",
        "    update_tets_f = torch.clone(tets_verts_features)\n",
        "    update_tets_f[surf_tets_verts_idx] += vfvs\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    # Calculate SDF non_surface tetrahedron in newly generated mesh\n",
        "\n",
        "    p_sdfs = get_gt_sdfs(mesh_verts.unsqueeze(0), mesh_faces, non_surf_verts.unsqueeze(0))\n",
        "\n",
        "    # Get ground truth SDF value of non_surface tetrahedron vertices and truncate at +- 0.3 to focus on surface\n",
        "\n",
        "    ns_g = gt_sdfs[non_surf_idx]\n",
        "    mask = (ns_g >= -0.3) & (ns_g <= 0.3)\n",
        "    p = p_sdfs[mask]\n",
        "    g = ns_g[mask]\n",
        "\n",
        "    # Also calculate surface sdf loss\n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts[surf_tets_verts_idx].unsqueeze(0), gt_f)\n",
        "\n",
        "    sdf_loss = F.mse_loss(sdf, s_sdfs - surf_sdfs, reduction='sum') #+F.mse_loss(p, g, reduction='sum') +\n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(deform, torch.zeros(deform.shape).to(device), reduction='sum')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it)\n",
        "\n",
        "    loss = r_loss + 0.4*sdf_loss + deform_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if (it) % save_every == 0 or it == (iterations - 1): \n",
        "      print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=it+1,\n",
        "          category='extracted_mesh',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN Train with Subdivision"
      ],
      "metadata": {
        "id": "IxqV7DVAM1DI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oicuzl0WSHRE"
      },
      "outputs": [],
      "source": [
        "# from pytorch3d import loss\n",
        "\n",
        "# def gcn_train_wsubdiv(iterations, gcn_model, optimizer, scheduler, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "#   gcn_model.train()\n",
        "\n",
        "#   assert thresh >= 0\n",
        "\n",
        "#   \"\"\"\n",
        "\n",
        "#   Firstly, based on predicted sdf value, extract out all surface tetrahedrons\n",
        "#   i.e. 1-3 vertices of tetrahedrons are with different sdf signs\n",
        "#   return value: \n",
        "#   --> surf_tets_idx: origin index of vertices as in tet grid\n",
        "#   --> surf_tets_faces: reindexed faces list start from 0\n",
        "\n",
        "#   \"\"\"\n",
        "\n",
        "#   # Get surface and non-surface tetrahedron indices\n",
        "\n",
        "#   surf_tets_verts_idx, surf_tets_faces, non_surf_idx, non_surf_tets = extract_tet(tets, pred_sdf, thresh, True)\n",
        "\n",
        "#   # Use surface faces to obtain edge list\n",
        "\n",
        "#   surf_tets_edges = get_edges(surf_tets_faces).to(device)\n",
        "\n",
        "\n",
        "#   # Use surface indices obtain per vertex features: \n",
        "\n",
        "#   # Surface vertices positions:\n",
        "\n",
        "#   surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "#   # Surface per vertex feature vector:\n",
        "\n",
        "#   surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "\n",
        "#   # Surface per vertex predicted sdf value:\n",
        "\n",
        "#   surf_sdfs = torch.clone(pred_sdf[surf_tets_verts_idx])\n",
        "\n",
        "#   # Cat all features together as the input into model\n",
        "\n",
        "#   surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "#   # Obtain non_surface vertices position\n",
        "\n",
        "#   non_surf_verts = torch.clone(tets_verts[non_surf_idx])\n",
        "\n",
        "#   # Calculate ground truth sdf value over all vertices in tet mesh\n",
        "\n",
        "#   gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "#   gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "\n",
        "#   gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "#   for it in range(100):\n",
        "    \n",
        "#     \"\"\"\n",
        "    \n",
        "#     Secondly, predict with a 2-layer GCN followed by 2-layer MLP\n",
        "#     output:\n",
        "#     --> [delta v, delta s, new f_s] \\in R^68\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "#     \"\"\"\n",
        "\n",
        "#     Update surface position, sdf, and f_s\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     #updated sdf\n",
        "\n",
        "#     us = sdf.detach()\n",
        "#     update_sdfs = torch.clone(pred_sdf)\n",
        "#     update_sdfs[surf_tets_verts_idx] += us\n",
        "\n",
        "#     #update vertices positions\n",
        "\n",
        "#     vd = torch.tanh(deform).detach()\n",
        "#     update_tets_verts = torch.clone(tets_verts)\n",
        "#     update_tets_verts[surf_tets_verts_idx] += vd / grid_res\n",
        "\n",
        "#     #update vertices features\n",
        "\n",
        "#     vfvs = fv.detach()\n",
        "#     update_tets_f = torch.clone(tets_verts_features)\n",
        "#     update_tets_f[surf_tets_verts_idx] += vfvs\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     Volume subdivision:\n",
        "#     Re-identify surface tets based on updated sdf value and subdivide identified surface tets\n",
        "\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Extract surface tetrahedrons based on updated sdf value\n",
        "\n",
        "#     d_surf_tets_verts_idx, d_surf_tets_faces = extract_tet(tets, update_sdfs, thresh)\n",
        "#     if d_surf_tets_faces.shape[0] == 0:\n",
        "#       d_surf_tets_verts_idx, d_surf_tets_faces = surf_tets_verts_idx, surf_tets_faces\n",
        "\n",
        "#     # Use new surface indices to get new surface vertices positions\n",
        "\n",
        "#     d_surf_tets_verts = torch.clone(update_tets_verts[d_surf_tets_verts_idx])\n",
        "\n",
        "#     # Use new surface indices to get new surface per vertex sdf and features\n",
        "\n",
        "#     d_surf_tets_verts_features = torch.clone(update_tets_f[d_surf_tets_verts_idx])\n",
        "#     d_surf_sdfs = torch.clone(update_sdfs[d_surf_tets_verts_idx])\n",
        "\n",
        "#     # Cat new surface per vertex features together for subdivide\n",
        "\n",
        "#     d_surf_verts_f = torch.cat((d_surf_sdfs, d_surf_tets_verts_features), dim=1)\n",
        "\n",
        "#     # Perform subdivide, returns subdivided surface tetrahedron \n",
        "\n",
        "#     d_tets_verts, d_tets_faces, d_tets_fvs = kaolin.ops.mesh.subdivide_tetmesh(d_surf_tets_verts.unsqueeze(0), d_surf_tets_faces, d_surf_verts_f.unsqueeze(0))\n",
        "#     d_tets_verts, d_tets_fvs = d_tets_verts[0], d_tets_fvs[0]\n",
        "#     d_tets_sdfs = d_tets_fvs[:, 0]\n",
        "\n",
        "\n",
        "#     # Get surface edges from tetrahedron faces\n",
        "\n",
        "#     d_tets_edges = get_edges(d_tets_faces).to(device)\n",
        "\n",
        "#     # Cat to obtain feature input into GCN\n",
        "\n",
        "#     d_tets_fvs = torch.cat((d_tets_verts, d_tets_fvs), dim=1)\n",
        "\n",
        "#     d_sdf, d_deform, d_fv = gcn_model(d_tets_fvs, d_tets_edges)\n",
        "\n",
        "#     # Updated sdf\n",
        "\n",
        "#     d_update_sdfs = d_tets_sdfs.unsqueeze(1).detach() + d_sdf #since we need this to back propagate\n",
        "\n",
        "\n",
        "#     # Update vertices positions\n",
        "\n",
        "#     d_vd = torch.tanh(d_deform).detach()\n",
        "#     d_update_tets_verts = d_tets_verts + d_vd / grid_res\n",
        "\n",
        "#     # Update vertices features\n",
        "\n",
        "#     d_vfvs = d_fv.detach()\n",
        "#     d_update_tets_f = d_tets_fvs[:, 4:] + d_vfvs\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(d_update_tets_verts.unsqueeze(0), d_tets_faces, d_update_sdfs.squeeze(1).unsqueeze(0))\n",
        "#     mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "#     print(mesh_verts.shape, mesh_faces.shape)\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     Compute Loss for First surface refinement: \n",
        "#     Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     # L2 sdf reg: \n",
        "\n",
        "#     # Calculate SDF non_surface tetrahedron in newly generated mesh\n",
        "\n",
        "#     p_sdfs = get_gt_sdfs(mesh_verts.unsqueeze(0), mesh_faces, non_surf_verts.unsqueeze(0))\n",
        "\n",
        "#     # Get ground truth SDF value of non_surface tetrahedron vertices and truncate at +- 0.3 to focus on surface\n",
        "\n",
        "#     ns_g = gt_sdfs[non_surf_idx]\n",
        "#     mask = (ns_g >= -0.3) & (ns_g <= 0.3)\n",
        "#     p = p_sdfs[mask]\n",
        "#     g = ns_g[mask]\n",
        "\n",
        "#     # Also calculate surface sdf loss\n",
        "\n",
        "#     # s_sdfs, _, _ = point_to_mesh_distance(update_tets_verts[surf_tets_verts_idx].unsqueeze(0), gt_f)\n",
        "#     # s_sign = kaolin.ops.mesh.check_sign(gt_verts.unsqueeze(0), gt_faces, update_tets_verts[surf_tets_verts_idx].unsqueeze(0))\n",
        "#     # s_sdfs[s_sign==False] *= -1\n",
        "\n",
        "#     # s_sdfs = s_sdfs.squeeze(0).unsqueeze(1)\n",
        "\n",
        "#     s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, d_update_tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "#     sdf_loss = F.mse_loss(p, g, reduction='sum') + F.mse_loss(d_update_sdfs, s_sdfs, reduction='sum')\n",
        "\n",
        "#     #L2 deform reg\n",
        "\n",
        "#     deform_loss = F.mse_loss(d_deform, torch.zeros(d_deform.shape).to(device), reduction='sum')\n",
        "\n",
        "#     #surface alignment loss\n",
        "\n",
        "#     r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it)\n",
        "    \n",
        "#     loss = r_loss + deform_loss + 0.4*sdf_loss \n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     torch.autograd.set_detect_anomaly(True)\n",
        "#     loss.backward(retain_graph=True)\n",
        "#     optimizer.step()\n",
        "#     scheduler.step()\n",
        "\n",
        "#     # print('Iteration {} - loss: {}'.format(it, loss))\n",
        "\n",
        "#     if (it) % save_every == 0 or it == (iterations - 1): \n",
        "#       print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      \n",
        "#       # save reconstructed mesh\n",
        "#       timelapse.add_mesh_batch(\n",
        "#           iteration=it+1,\n",
        "#           category='extracted_mesh',\n",
        "#           vertices_list=[mesh_verts.cpu()],\n",
        "#           faces_list=[mesh_faces.cpu()]\n",
        "#       )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Surface Refinement"
      ],
      "metadata": {
        "id": "xoE7xYCtM572"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm5aud4mz6ZJ"
      },
      "outputs": [],
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)\n",
        "\n",
        "pre_vars = [p for _, p in refine_model.named_parameters()]\n",
        "pre_optimizer = torch.optim.Adam(pre_vars, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iADZ6VnsBTCJ"
      },
      "outputs": [],
      "source": [
        "# pred_sdfs, _ = get_pred_sdfs(sdf_model, tets_verts)\n",
        "\n",
        "\n",
        "pred = sdf_model(tets_verts)\n",
        "pred_sdfs, deform = pred[:,0], pred[:,1:]\n",
        "print(extract_tets(tets, pred_sdfs, 0.001)[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hlf1luSRwZ3"
      },
      "outputs": [],
      "source": [
        "gcn_pretrain(500, refine_model, pre_optimizer, pred_sdfs, tets_verts, tets, deform, sample_verts, sample_faces, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ylyiYXI08J"
      },
      "outputs": [],
      "source": [
        "refine_vars = [p for _, p in refine_model.named_parameters()]\n",
        "refine_optimizer = torch.optim.Adam(pre_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(pre_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqEaSvssI8it"
      },
      "outputs": [],
      "source": [
        "gcn_train(gcn_iterations, refine_model, refine_optimizer, refine_scheduler, pred_sdfs, tets_verts, tets, deform, sample_verts, sample_faces, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhShD27xy42k"
      },
      "outputs": [],
      "source": [
        "# test_gcn = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "# t_v = [p for _, p in test_gcn.named_parameters()]\n",
        "# t_op = torch.optim.Adam(t_v, lr=lr)\n",
        "# t_sch = torch.optim.lr_scheduler.LambdaLR(t_op, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RPwOOP0bNH"
      },
      "outputs": [],
      "source": [
        "# gcn_pretrain(700, test_gcn, t_op, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsUxitzdzEja"
      },
      "outputs": [],
      "source": [
        "# gcn_train_wsubdiv(gcn_iterations, test_gcn, t_op, t_sch, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx0o-m2bukdz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "to-dos: volume subdivision\n",
        "\n",
        "identify T_surf's neighbors: i.e. share a same edge\n",
        "\n",
        "subdivide T_surf to perform another surface refinement\n",
        "unsubdivded tet, i.e. not surface's neighbor, is dropped to save memory and computation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#neightbor if share an edge\n",
        "#identify edge based on surf_faces and adj matrix\n",
        "\n",
        "\"\"\"\n",
        "convert face_lists = [v1, v2, v3, v4] --> \n",
        "[\n",
        "  [v1, v2, v3, E, o1],\n",
        "  [v2, v3, v4, E, o2],\n",
        "  [v1, v2, v4, E, o3],\n",
        "  [v1, v3, v4, E, o4]\n",
        "]\n",
        "\n",
        "by torch combinations, E = tet index, o_i = face_i index\n",
        "\"\"\"\n",
        "def convert_face_lists(tets):\n",
        "  face_idx = torch.tensor([1,2,3,4])\n",
        "  tet_face_list = []\n",
        "  for idx, tet in enumerate(tets):\n",
        "    tet_idx = torch.full(4, idx)\n",
        "    tet_faces = torch.combinations(tet, r=3)\n",
        "    tet_faces = torch.cat((tet_faces, tet_idx, face_idx), dim=1)\n",
        "    tet_face_list.append(tet_faces)\n",
        "\n",
        "  tet_face_list = torch.stack(tet_face_list, dim=0)\n",
        "\n",
        "  def compare(face_1, face_2):\n",
        "    o1 = face_1[0]-face_2[0]\n",
        "    o2 = face_1[1]-face_2[1]\n",
        "    o3 = face_1[2]-face_2[2]\n",
        "\n",
        "    if o1 <= 0 or (o1 == 0 and o2 < 0) or (o1 == 0 and o2 == 0 and o3 < 0):\n",
        "      return -1\n",
        "    elif o1 == 0 and o2 == 0 and o3 == 0:\n",
        "      return 0\n",
        "    else: \n",
        "      return 1\n",
        "\n",
        "  sorted(tet_face_list, cmp=compare)\n",
        "  return tet_face_list\n",
        "\n",
        "def get_neighbor(surf_tet_verts, surf_tets, tet_verts, tets):\n",
        "  tet_face_list = convert_face_lists(tets)\n",
        "  \n",
        "\n",
        "surf_idx, surf = extract_tet(tets, pred_sdfs, 0.003)\n",
        "\n",
        "print(surf_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Too6Yu0KxrRH"
      },
      "outputs": [],
      "source": [
        "def get_faces(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=3)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e-1rPxP3Ru9"
      },
      "outputs": [],
      "source": [
        "# a = get_faces(tets)\n",
        "# b = get_faces(tets[surf_idx])\n",
        "\n",
        "# # OPTIMIZE TF OUT OF THIS\n",
        "# for f in b:\n",
        "#   mask = a == f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7RCV62USts"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "p68GrPqkUU07"
      },
      "outputs": [],
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Hzzzh94FgOXssVkSP5Yffz8uYg_By2RMDZLTPx1aXakhYfH\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "rWJ2SS1EUYjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "d63cdcce-a614-427b-f5ff-3301d3d42fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2022-12-12T17:31:15+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=e74430c4376398fb err=\"Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2Ip6TwbmkH8gSVsJO5EB2c9XTqv, tn_2Ip6eqpQu2KhYFjRvOfwb9ksKKy, tn_2Ip6TvbgTsxOkkDinIwZthykoXZ\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokHTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-8ea39ab033a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#generating a public url mapped to localhost 80\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"bind_tls\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"local\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tracking URL:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating tunnel with options: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     tunnel = NgrokTunnel(api_request(\"{}/api/tunnels\".format(api_url), method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    272\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    273\u001b[0m                          pyngrok_config, api_url)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Response {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         raise PyngrokNgrokHTTPError(\"ngrok client exception, API returned {}: {}\".format(status_code, response_data),\n\u001b[0m\u001b[1;32m    478\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                                     status_code, e.msg, e.hdrs, response_data)\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2Ip6TwbmkH8gSVsJO5EB2c9XTqv, tn_2Ip6eqpQu2KhYFjRvOfwb9ksKKy, tn_2Ip6TvbgTsxOkkDinIwZthykoXZ\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n"
          ]
        }
      ],
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "9RZLd8x7UrUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56003546-66f8-49aa-ea1a-f02dcc464f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash3D server starting. Go to: http://localhost:80\n",
            "2022-12-12 17:31:18,305|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaolin-dash3d\", line 6, in <module>\n",
            "    run_main()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/kaolin/experimental/dash3d/run.py\", line 96, in run_main\n",
            "    server.listen(args.port)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado/web.py\", line 2116, in listen\n",
            "    server.listen(port, address)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado/tcpserver.py\", line 151, in listen\n",
            "    sockets = bind_sockets(port, address=address)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado/netutil.py\", line 174, in bind_sockets\n",
            "    sock.bind(sockaddr)\n",
            "OSError: [Errno 98] Address already in use\n"
          ]
        }
      ],
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lqIYyxq_sN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooT3zo23rA62"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixiLERLsrDz3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24GAvO6IrKbC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9ZyP7cuGPR7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IxqV7DVAM1DI"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}