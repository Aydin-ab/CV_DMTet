{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aydin-ab/CV_DMTet/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Af_jBwcMwG8"
      },
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x7VxtwyMthl",
        "outputId": "ce07c04c-cce4-4177-962a-6214ba2cb368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "env: XDG_CACHE_HOME=/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, auth\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/MyDrive/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH\n",
        "%env XDG_CACHE_HOME=/content/drive/MyDrive/CV_DMTet"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAP99SJ8Fjpg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomq21yA4wP8",
        "outputId": "5494ac3e-a339-4348-af63-75b40891809e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 0.29.20\n",
            "Uninstalling Cython-0.29.20:\n",
            "  Successfully uninstalled Cython-0.29.20\n"
          ]
        }
      ],
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "import torch\n",
        "!pip install  Cython==0.29.20  --quiet\n",
        "!pip install  usd-core --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2gnrsxeoc_W",
        "outputId": "acb08ab8-c7d6-4310-9edd-73e43f5ec707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: IGNORE_TORCH_VER=1\n",
            "env: KAOLIN_INSTALL_EXPERIMENTAL=1\n",
            "/content/drive/MyDrive/CV_DMTet\n",
            "/content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Checking if /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/version.py exists\n"
          ]
        }
      ],
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "!echo Checking if $SETUP_CHECK exists\n",
        "!if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "# !python -c \"import kaolin; print(kaolin.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWMtC40fLr1",
        "outputId": "3d3b1d37-ff9e-47f9-ffcd-2c951c102b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setup.py:36: UserWarning: Kaolin is compatible with PyTorch >=1.6.0, <=1.13.0, but found version 1.13.0+cu116. Continuing with the installed version as IGNORE_TORCH_VER is set.\n",
            "  warnings.warn(\n",
            "Warning: passing language='c++' to cythonize() is deprecated. Instead, put \"# distutils: language=c++\" in your .pyx or .pxd file(s)\n",
            "Compiling kaolin/cython/ops/mesh/triangle_hash.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "Compiling kaolin/cython/ops/conversions/mise.pyx because it depends on /usr/local/lib/python3.8/dist-packages/Cython/Includes/libcpp/vector.pxd.\n",
            "[1/2] Cythonizing kaolin/cython/ops/conversions/mise.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/conversions/mise.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:90:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "warning: kaolin/cython/ops/conversions/mise.pyx:284:33: Not all members given for struct 'Voxel'\n",
            "[2/2] Cythonizing kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/drive/MyDrive/CV_DMTet/kaolin/kaolin/cython/ops/mesh/triangle_hash.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running develop\n",
            "running egg_info\n",
            "writing kaolin.egg-info/PKG-INFO\n",
            "writing dependency_links to kaolin.egg-info/dependency_links.txt\n",
            "writing requirements to kaolin.egg-info/requires.txt\n",
            "writing top-level names to kaolin.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'kaolin.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:387: UserWarning: The detected CUDA version (11.2) has a minor version mismatch with the version that was used to compile PyTorch (11.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "building 'kaolin.ops.mesh.triangle_hash' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/mesh/triangle_hash.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=triangle_hash -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1969:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:656\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_f_6kaolin_3ops_4mesh_13triangle_hash_12TriangleHash_query(__pyx_obj_6kaolin_3ops_4mesh_13triangle_hash_TriangleHash*, __Pyx_memviewslice, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2880:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/mesh/triangle_hash.cpp:2889:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_6 = 0; \u001b[01;35m\u001b[K__pyx_t_6 < __pyx_t_19\u001b[m\u001b[K; __pyx_t_6+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/mesh/triangle_hash.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so\n",
            "building 'kaolin.ops.conversions.mise' extension\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c kaolin/cython/ops/conversions/mise.cpp -o build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=mise -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6kaolin_3ops_11conversions_4mise_4MISE_8get_points(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3476:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_10 = 0; \u001b[01;35m\u001b[K__pyx_t_10 < __pyx_t_9\u001b[m\u001b[K; __pyx_t_10+=1) {\n",
            "                        \u001b[01;35m\u001b[K~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid __pyx_f_6kaolin_3ops_11conversions_4mise_4MISE_subdivide_voxels(__pyx_obj_6kaolin_3ops_11conversions_4mise_MISE*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3703:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3712:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3744:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "   for (__pyx_t_9 = 0; \u001b[01;35m\u001b[K__pyx_t_9 < __pyx_t_11\u001b[m\u001b[K; __pyx_t_9+=1) {\n",
            "                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:3753:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     __pyx_t_12 = (((__pyx_v_self->voxels[__pyx_v_idx]).level == __pyx_v_self->depth) != 0);\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:\u001b[m\u001b[K At global scope:\n",
            "\u001b[01m\u001b[Kkaolin/cython/ops/conversions/mise.cpp:15782:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyObject* __pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D(__pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D)\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " static PyObject* \u001b[01;35m\u001b[K__pyx_convert__to_py_struct____pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D\u001b[m\u001b[K(struct __pyx_t_6kaolin_3ops_11conversions_4mise_Vector3D s) {\n",
            "                  \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/kaolin/cython/ops/conversions/mise.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/_C.so -> kaolin\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/mesh/triangle_hash.so -> kaolin/ops/mesh\n",
            "copying build/lib.linux-x86_64-3.8/kaolin/ops/conversions/mise.so -> kaolin/ops/conversions\n",
            "Creating /usr/local/lib/python3.8/dist-packages/kaolin.egg-link (link to .)\n",
            "kaolin 0.12.0 is already the active version in easy-install.pth\n",
            "Installing kaolin-dash3d script to /usr/local/bin\n",
            "\n",
            "Installed /content/drive/MyDrive/CV_DMTet/kaolin\n",
            "Processing dependencies for kaolin==0.12.0\n",
            "Searching for usd-core==22.5.post1\n",
            "Best match: usd-core 22.5.post1\n",
            "Processing usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "usd-core 22.5.post1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/usd_core-22.5.post1-py3.8-linux-x86_64.egg\n",
            "Searching for Flask==2.0.3\n",
            "Best match: Flask 2.0.3\n",
            "Processing Flask-2.0.3-py3.8.egg\n",
            "Flask 2.0.3 is already the active version in easy-install.pth\n",
            "Installing flask script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Flask-2.0.3-py3.8.egg\n",
            "Searching for tornado==6.1\n",
            "Best match: tornado 6.1\n",
            "Processing tornado-6.1-py3.8-linux-x86_64.egg\n",
            "tornado 6.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Pillow==9.3.0\n",
            "Best match: Pillow 9.3.0\n",
            "Processing Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Pillow 9.3.0 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Pillow-9.3.0-py3.8-linux-x86_64.egg\n",
            "Searching for scipy==1.7.2\n",
            "Best match: scipy 1.7.2\n",
            "Processing scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "scipy 1.7.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/scipy-1.7.2-py3.8-linux-x86_64.egg\n",
            "Searching for itsdangerous==2.1.2\n",
            "Best match: itsdangerous 2.1.2\n",
            "Processing itsdangerous-2.1.2-py3.8.egg\n",
            "itsdangerous 2.1.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/itsdangerous-2.1.2-py3.8.egg\n",
            "Searching for click==7.1.2\n",
            "Best match: click 7.1.2\n",
            "Adding click 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Werkzeug==2.2.2\n",
            "Best match: Werkzeug 2.2.2\n",
            "Processing Werkzeug-2.2.2-py3.8.egg\n",
            "Werkzeug 2.2.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Werkzeug-2.2.2-py3.8.egg\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Processing Jinja2-3.1.2-py3.8.egg\n",
            "Jinja2 3.1.2 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/Jinja2-3.1.2-py3.8.egg\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for MarkupSafe==2.1.1\n",
            "Best match: MarkupSafe 2.1.1\n",
            "Processing MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "MarkupSafe 2.1.1 is already the active version in easy-install.pth\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages/MarkupSafe-2.1.1-py3.8-linux-x86_64.egg\n",
            "Finished processing dependencies for kaolin==0.12.0\n"
          ]
        }
      ],
      "source": [
        "# !python setup.py install_lib install_scripts build\n",
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ItNJXfPQPA"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xI6uNv5JPP0i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        print(f\"version_str : {version_str}\")\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8J8kP1FV7x1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D24NPgYx7x5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup dashboard to "
      ],
      "metadata": {
        "id": "y-MnH1TK7yOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Hzzzh94FgOXssVkSP5Yffz8uYg_By2RMDZLTPx1aXakhYfH\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "id": "mNiFL0mT7pP6"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)\n",
        "\n",
        "#Start Kaolin Dash3D on localhost:80 \n",
        "# Can run this in terminal to not interfere with notebook\n",
        "# !kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL-wLA6s7uMW",
        "outputId": "f4ce116c-4227-4e18-92e0-e8bf49b7be4a"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking URL: NgrokTunnel: \"http://52ee-34-141-173-195.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKhngPBlPbTs"
      },
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LWdkJJr1y_wW"
      },
      "outputs": [],
      "source": [
        "import pytorch3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G126GQfpf1nB"
      },
      "outputs": [],
      "source": [
        "# state_dict = torch.load('/content/drive/MyDrive/CV_DMTet/shapenet.pvcnn.c1.pth.tar')\n",
        "# state_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yMSLuRoDPfkp"
      },
      "outputs": [],
      "source": [
        "sys.path.append(INSTALL_PATH / \"examples\")\n",
        "sys.path.append(INSTALL_PATH / \"examples\" / \"tutorial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aTCgE2WCPiAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60cecd93-ea78-44b6-9e0c-68a4d23a4a6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i3zs2M-kOA1z"
      },
      "outputs": [],
      "source": [
        "# # path to the point cloud to be reconstructed\n",
        "# pcd_path = KAOLIN_PATH / \"examples/samples/bear_pointcloud.usd\"\n",
        "# # path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# # We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-D0gGzDS3-7"
      },
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZbYIPn4OEuRV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oEEdkp9yFI2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 565,
      "metadata": {
        "id": "LyIoND6-SxAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e60b1a-ae06-41e7-a983-103d5a145811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load(KAOLIN_PATH / \"examples/samples/128_verts.npz\")['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load(KAOLIN_PATH / 'examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTFQbA5awlr"
      },
      "source": [
        "# Loading from ShapeNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 726,
      "metadata": {
        "id": "fxK5Qw4xay7g"
      },
      "outputs": [],
      "source": [
        "# Not using for now, using libigl tutorial x-cylinder below\n",
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "# SYNSETS_IDS = ['02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02843684'] #'02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "SYNSETS_IDS = ['02808440']\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 727,
      "metadata": {
        "id": "uhzpP8kua2Rm"
      },
      "outputs": [],
      "source": [
        "def get_next_shapenet(idx, object=\"bench\"):\n",
        "  idx +=1\n",
        "  while 1:\n",
        "    try:\n",
        "      gt_model = shapenet_train[idx][\"mesh\"]\n",
        "      break\n",
        "    except:\n",
        "      idx+=1\n",
        "  \n",
        "  gt_verts = gt_model[0].to(device)\n",
        "  gt_faces = gt_model[1].to(device)\n",
        "  gt_verts = ((gt_verts - ((gt_verts.max(0)[0] + gt_verts.min(0)[0]) / 2)) / ((gt_verts.max(0)[0] - gt_verts.min(0)[0]).max()))* 0.8\n",
        "\n",
        "  wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "        vertices=gt_verts.unsqueeze(0),\n",
        "        faces=gt_faces,\n",
        "        resolution=64\n",
        "    )\n",
        "  wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "  wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "  center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "  max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "  wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "\n",
        "  points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 5000)[0][0]\n",
        "  center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
        "  max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
        "  points = ((points - center) / max_l)* 0.9\n",
        "\n",
        "  timelapse.add_mesh_batch(\n",
        "      category=f'gt_bench_{idx}',\n",
        "      vertices_list=[gt_verts.cpu()],\n",
        "      faces_list=[gt_faces.cpu()]\n",
        "  )\n",
        "  gt_verts.to(device)\n",
        "  gt_faces.to(device)\n",
        "  wt_grid.to(device)\n",
        "  wt_verts.to(device)\n",
        "  wt_faces.to(device)\n",
        "  points.to(device)\n",
        "  return idx, gt_verts, gt_faces, wt_grid, wt_verts, wt_faces, points\n",
        "\n",
        "idx, gt_verts, gt_faces, wt_grid, wt_verts, wt_faces, points = get_next_shapenet(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert model to watertight meshes"
      ],
      "metadata": {
        "id": "-2Az3OQjzJgE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 728,
      "metadata": {
        "id": "RKRJZwFjPaPl"
      },
      "outputs": [],
      "source": [
        "def group_shapenet(idx, groupnum, obj=\"bench\"):\n",
        "  group = []\n",
        "  for g in range(groupnum):\n",
        "    idx, gt_verts, gt_faces, wt_grid, wt_verts, wt_faces, points = get_next_shapenet(idx, obj)\n",
        "    dct = {\"idx\": idx, \"gt_verts\": gt_verts, \"gt_faces\": gt_faces, \"wt_grid\": wt_grid, \n",
        "           \"wt_verts\": wt_verts, \"wt_faces\": wt_faces, \"points\" : points}\n",
        "    group.append(dct)\n",
        "  return group\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "group = group_shapenet(-1, 4, \"bathtub\")"
      ],
      "metadata": {
        "id": "-wyfSCwml0tG"
      },
      "execution_count": 730,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqSP-G5CzOiW"
      },
      "execution_count": 607,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NJcqOAUm4H6I"
      },
      "execution_count": 568,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "3dFAfSMR3Z3R"
      },
      "execution_count": 568,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 569,
      "metadata": {
        "id": "K8Cm7qVUA_hl"
      },
      "outputs": [],
      "source": [
        "# # Clone sample meshes from libigl tutorial 1x\n",
        "# LIBIGL_TUTORIAL_DATA = INSTALL_PATH / \"libigl-tutorial-data\"\n",
        "# print(f\"LIBIGL_TUTORIAL_DATA: {LIBIGL_TUTORIAL_DATA}\")\n",
        "# %cd $INSTALL_PATH\n",
        "# !if [ ! -d $LIBIGL_TUTORIAL_DATA ]; then git clone --recursive https://github.com/libigl/libigl-tutorial-data.git; fi;\n",
        "# %cd $KAOLIN_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 570,
      "metadata": {
        "id": "Wo9-f58yGLmK"
      },
      "outputs": [],
      "source": [
        "# Load cylinder (along x-axis) mesh (V,F) = (42,80)\n",
        "# mesh = kaolin.io.obj.import_mesh(LIBIGL_TUTORIAL_DATA / \"arm.obj\") #xcylinder.obj\n",
        "# gt_verts = mesh[0].to(device)\n",
        "# gt_faces = mesh[1].to(device)\n",
        "# timelapse.add_mesh_batch(\n",
        "#     category='gt',\n",
        "#     vertices_list=[gt_verts.cpu()],\n",
        "#     faces_list=[gt_faces.cpu()]\n",
        "# )\n",
        "# gt_sample = int(0.99*gt_verts.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xI0lLPcwF5LM"
      },
      "execution_count": 570,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 570,
      "metadata": {
        "id": "HjBnktJULzWd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJG7i2wbHC7"
      },
      "source": [
        "# Convert model to watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 571,
      "metadata": {
        "id": "e93m-kdBHD7G"
      },
      "outputs": [],
      "source": [
        "# wt_grid\n",
        "# Convert mesh (V,F) to a voxel grid \n",
        "# voxels = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "#     vertices=mesh_verts.unsqueeze(0).to(device),\n",
        "#     faces=mesh_faces.to(device),\n",
        "#     resolution=16\n",
        "# )\n",
        "\n",
        "# # Convert the voxel grid back into a mesh as GroundTruth\n",
        "# # I am not sure this step is necessary\n",
        "# # The intention is to have mesh_vertices, mesh_faces for the voxel grid for loss function\n",
        "# wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(voxels)\n",
        "# wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "# max_gt_len = (mesh_verts.max(0)[0] - mesh_faces.min(0)[0]).max()\n",
        "# max_vox_len = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "# scale = max_gt_len / max_vox_len\n",
        "# center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "# wt_verts = ((wt_verts - center) * scale)\n",
        "\n",
        "# timelapse.add_mesh_batch(\n",
        "#     category='watertight_test',\n",
        "#     vertices_list=[wt_verts.cpu()],\n",
        "#     faces_list=[wt_faces.cpu()]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-iQiev1XYcD"
      },
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Kaolin bear point cloud data (PCD) right now since tutorial uses PCD\n",
        "# pcd_path = KAOLIN_PATH / \"examples/samples/bear_pointcloud.usd\"\n",
        "# points = kaolin.io.usd.import_pointclouds(str(pcd_path))[0].points.to(device)\n",
        "# if points.shape[0] > 100000:\n",
        "#     idx = list(range(points.shape[0]))\n",
        "#     np.random.shuffle(idx)\n",
        "#     idx = torch.tensor(idx[:100000], device=points.device, dtype=torch.long)    \n",
        "#     points = points[idx]\n",
        "\n",
        "# # The reconstructed object needs to be slightly smaller than the grid to get watertight surface after MT.\n",
        "# # The idea is that we want our point cloud to expand since it will converge faster if all face expansions are outward.\n",
        "# center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
        "# max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
        "# points = ((points - center) / max_l)* 0.9\n",
        "# timelapse.add_pointcloud_batch(category='input',\n",
        "#                                pointcloud_list=[points.cpu()], points_type = \"usd_geom_points\")"
      ],
      "metadata": {
        "id": "LfFGWqUYTPqx"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-S8nTTuCDzfF"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEBw5esdYX__"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 572,
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaolin.ops.conversions.voxelgrids_to_cubic_meshes(\n",
        "\n",
        "Convert voxelgrids to meshes by replacing each occupied voxel with a cuboid mesh (unit cube). Each cube has 8 vertices and 6 (for quadmesh) or 12 faces (for triangular mesh). Internal faces are ignored. If is_trimesh==True, this function performs the same operation as “Cubify” defined in the ICCV 2019 paper “Mesh R-CNN”: https://arxiv.org/abs/1906.02739.\n",
        "\n",
        "Parameters\n",
        "voxelgrids (torch.Tensor) – binary voxel array, of shape .\n",
        "\n",
        "is_trimesh (optional, bool) – if True, the outputs are triangular meshes. Otherwise quadmeshes are returned. Default: True.\n",
        "\n",
        "Returns\n",
        "The list of vertices for each mesh.\n",
        "\n",
        "The list of faces for each mesh.\n",
        "\n",
        "Return type\n",
        "(list[torch.Tensor], list[torch.LongTensor])"
      ],
      "metadata": {
        "id": "D5X80R95XgJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 572,
      "metadata": {
        "id": "SeRiCeTULDEv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUbuf5PETHwp"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 572,
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Mc2UjaWTYqc"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaolin.ops.conversions.marching_tetrahedra(vertices, tets, sdf, return_tet_idx=False)¶\n",
        "Convert discrete signed distance fields encoded on tetrahedral grids to triangle meshes using marching tetrahedra algorithm as described in An efficient method of triangulating equi-valued surfaces by using tetrahedral cells. The output surface is differentiable with respect to input vertex positions and the SDF values. For more details and example usage in learning, see Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis NeurIPS 2021.\n"
      ],
      "metadata": {
        "id": "BMbohHY-W8a_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scLBY-eAaBUf"
      },
      "source": [
        "# SDF model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 731,
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "outputs": [],
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 3 + 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "ENCODER_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 800, 1600, 1600],\n",
        "    'output_dim' : 832, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}\n",
        "\n",
        "lr = 0.001\n",
        "laplacian_weight = 0.1\n",
        "iterations = 3000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pred_sdfs(model, tets_verts, gt_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    F_vol = F.interpolate(gt_verts[None, None, None,:, :], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "    pred_sdfs, f_vs = model(F_vol)\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  d,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  d[s==True] *= -1\n",
        "\n",
        "  return d.squeeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "IW8t7bl5IEKg"
      },
      "execution_count": 732,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 733,
      "metadata": {
        "id": "cS9kStkdKQlC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from pytorch3d.utils import ico_sphere\n",
        "\n",
        "# Comes from the DMTet tutorial \n",
        "# MLP + Positional Encoding\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, input_dims = 6, internal_dims = 64, output_dims = 4, hidden = 5, multires = 2):\n",
        "        super().__init__()\n",
        "        self.embed_fn = None\n",
        "        self.pre_train_dims = input_dims\n",
        "        if multires > 0:\n",
        "            embed_fn, input_ch = get_embedder(multires)\n",
        "            self.embed_fn = embed_fn\n",
        "            input_dims = input_ch \n",
        "        self.input_dim = input_dims\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        net = (torch.nn.Linear(self.input_dim, internal_dims, bias=False), torch.nn.ReLU())\n",
        "        for i in range(hidden-1):\n",
        "            net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
        "        self.net = torch.nn.Sequential(*net)\n",
        "        self.output = torch.nn.Linear(internal_dims, output_dims, bias=False)\n",
        "\n",
        "    def forward(self, p):\n",
        "        if self.embed_fn is not None:\n",
        "            p = self.embed_fn(p)\n",
        "        p = self.net(p)\n",
        "        out = self.output(p)\n",
        "        return out, p\n",
        "    \n",
        "    def pre_train_sphere(self, iter):    \n",
        "        print (\"Initialize SDF to sphere\")\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "        \n",
        "\n",
        "        for i in tqdm(range(iter)):\n",
        "            p = torch.rand((1024, self.pre_train_dims), device=device) - 0.5\n",
        "            ref_value  = torch.sqrt(((p+.5)**2).sum(-1)) - 0.3\n",
        "            output, _ = self(p)\n",
        "            loss = loss_fn(output[...,0], ref_value)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Pre-trained MLP\", loss.item())\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 6,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return output + last feature layer vector\n",
        "\n",
        "    def pre_train_sphere(self, iter):    \n",
        "        print (\"Initialize SDF to sphere\")\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
        "        \n",
        "\n",
        "        for i in tqdm(range(iter)):\n",
        "            p = torch.rand((1024,self.input_dim), device=device) - 0.5\n",
        "            ref_value  = torch.sqrt(((p+.5)**2).sum(-1)) - 0.3\n",
        "            output, _ = self(p)\n",
        "            loss = loss_fn(output[...,0], ref_value)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Pre-trained MLP\", loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = Decoder(multires=2).to(device)\n",
        "# r.pre_train_sphere(100)"
      ],
      "metadata": {
        "id": "cCN0Rod2jeAF"
      },
      "execution_count": 734,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_value.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks1cZoEupMCO",
        "outputId": "fee821ec-e53f-457c-e5b8-04b01b4dd3c9"
      },
      "execution_count": 735,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024])"
            ]
          },
          "metadata": {},
          "execution_count": 735
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "Pvc0K8laC3JJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19504963-f3e8-478d-e2ac-015557f750a3"
      },
      "execution_count": 736,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# # Initialize model and create optimizer\n",
        "\n",
        "# sdf_model = Decoder(multires=2).to(device)\n",
        "# sdf_model.pre_train_sphere(1000)"
      ],
      "metadata": {
        "id": "m_z6PaowshTB"
      },
      "execution_count": 737,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, y = get_embedder(multires=0)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "5c_4VfPjEYp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62be421-4958-4854-fa06-7c821325bd04"
      },
      "execution_count": 738,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vafkQj0AEezj"
      },
      "execution_count": 738,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 739,
      "metadata": {
        "id": "KLOS3kFWrd4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f8ca27-97b8-4853-c4fe-41ec06e09485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=6, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "encoder_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "print(encoder_model)\n",
        "# print('\\n\\n')\n",
        "# summary(encoder_model, input_size=tets_verts.shape + 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select SDF Model\n",
        "* sdf_model is standard MLP (all hidden dims are same) + f_v + comes with encoder deformer\n",
        "* encoder_model is from DMTet and encodes layers + f_v + no deformer"
      ],
      "metadata": {
        "id": "DPNokxTmjPZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = encoder_model"
      ],
      "metadata": {
        "id": "TDTokPx9jMHS"
      },
      "execution_count": 740,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3RhnpiEL35m"
      },
      "source": [
        "Little Test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 742,
      "metadata": {
        "id": "SqcbsCj7L5eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbe5bcc-988d-4a9b-9b5e-9c9d901348c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred shape is : torch.Size([277410, 4])\n",
            "Input grid shape is : torch.Size([277410, 3])\n"
          ]
        }
      ],
      "source": [
        "# signed distance fields encoded on tetrahedral grid\n",
        "\n",
        "# pred_sdfs dim = (tets_vertices.shape[0])\n",
        "# f_vs ie f_v feature vector\n",
        "\n",
        "# sdf, delta x_i, delta y_i, delta z_i, \n",
        "# sdf = binary occupancy of tetrahedron \n",
        "# pred, _ = MODEL(tets_verts)\n",
        "print(f'pred shape is : {pred.shape}')\n",
        "\n",
        "# pred_sdfs, f_vs = sdf_model(tets_verts)\n",
        "\n",
        "print(f'Input grid shape is : {tets_verts.shape}')\n",
        "# print(f'Output shape of the predicted SDFs should be {tets_verts.shape[0], 1} and it actually is {tuple(pred_sdfs.shape)}')\n",
        "# print(f'Output shape of the feature vectors f_vs should be {tets_verts.shape[0], 64} and it actually is {tuple(f_vs.shape)}')\n",
        "# print(pred_sdfs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WeFlWiqDJrPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2_4nDFUooHT3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeX6jmo_oERf"
      },
      "execution_count": 741,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Dh9gJiTWEq"
      },
      "source": [
        "# Set up Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "rENv3tMyTSdT"
      },
      "outputs": [],
      "source": [
        "sdf_vars = [p for _, p in MODEL.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf6lBBcPTcwd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "cDjptlAn_Biz"
      },
      "outputs": [],
      "source": [
        "# # # # takes in a module and applies the specified weight initialization\n",
        "# def weights_init_normal(m):\n",
        "#     '''Takes in a module and initializes all linear layers with weight\n",
        "#         values taken from a normal distribution.'''\n",
        "#     classname = m.__class__.__name__\n",
        "#     # for every Linear layer in a model\n",
        "#     if classname.find('Linear') != -1:\n",
        "#         y = m.in_features\n",
        "#     # m.weight.data shoud be taken from a normal distribution\n",
        "#         m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
        "#         m.weight.data = torch.randint(-1,2,m.weight.shape)\n",
        "#     # m.bias.data should be 0\n",
        "#         if m.bias is not None:\n",
        "#           m.bias.data.fill_(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlK7_JVK-iEq",
        "outputId": "b498151b-4d07-4724-b3dd-251bd5bf7a05"
      },
      "execution_count": 623,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 623
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 616,
      "metadata": {
        "id": "5qoVPBuJ_EaA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sdf_model.apply(weights_init_normal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sdf_model.net[10].weight.data"
      ],
      "metadata": {
        "id": "S5xGr21AjroK"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 649,
      "metadata": {
        "id": "oSbqopQVh3yf"
      },
      "outputs": [],
      "source": [
        "# Laplacian regularization using umbrella operator (Fujiwara / Desbrun).\n",
        "# https://mgarland.org/class/geom04/material/smoothing.pdf\n",
        "from pytorch3d import loss\n",
        "from random import randint\n",
        "def laplace_regularizer_const(pred_mesh_verts, pred_mesh_faces):\n",
        "    term = torch.zeros_like(pred_mesh_verts, device=device)\n",
        "    norm = torch.zeros_like(pred_mesh_verts[..., 0:1], device=device)\n",
        "\n",
        "    v0 = pred_mesh_verts[pred_mesh_faces[:, 0], :]\n",
        "    v1 = pred_mesh_verts[pred_mesh_faces[:, 1], :]\n",
        "    v2 = pred_mesh_verts[pred_mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, pred_mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, pred_mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def loss_f(pred_mesh_verts, pred_mesh_faces, pts, it):\n",
        "    pred_points = kaolin.ops.mesh.sample_points(pred_mesh_verts.unsqueeze(0), \n",
        "                                                pred_mesh_faces, 5000)[0][0]\n",
        "    \n",
        "    chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), pts.unsqueeze(0)).mean()\n",
        "    # chamfer.clone().detach().requires_grad_(True)\n",
        "    if it > iterations//2:\n",
        "        lap = laplace_regularizer_const(pred_mesh_verts, pred_mesh_faces)\n",
        "        return chamfer + lap * laplacian_weight\n",
        "    return chamfer \n",
        "\n",
        "\n",
        "def sdf_train(iterations, model, optimizer, scheduler):\n",
        "  # Set to training mode\n",
        "  model.train()\n",
        "\n",
        "  for it in range(iterations):\n",
        "      gidx = randint(0, len(group) - 1)\n",
        "      points = group[gidx][\"points\"]\n",
        "\n",
        "      wt_verts = group[gidx][\"wt_verts\"]\n",
        "\n",
        "      F_vol = F.interpolate(points[None, None, None,:, :], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "      F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "      \n",
        "      pred, _ = model(F_vol)\n",
        "      \n",
        "      # Replace pred_sdfs with the new SDF\n",
        "      # Replace deform with surface refinement \n",
        "\n",
        "      pred_sdfs, deform = pred[:,0], pred[:,1:]\n",
        "      verts_deformed = tets_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
        "      pred_mesh_verts, pred_mesh_faces = marching_tetrahedra(verts_deformed.unsqueeze(0), tets, pred_sdfs.unsqueeze(0))\n",
        "      pred_mesh_verts, pred_mesh_faces = pred_mesh_verts[0], pred_mesh_faces[0]\n",
        "      if pred_mesh_faces.shape[0] == 0:\n",
        "        pred_sdfs[tets[0,0]] = -1\n",
        "        pred_sdfs[tets[0,1]] = 1\n",
        "        pred_sdfs[tets[0,2]] = 1\n",
        "        pred_sdfs[tets[0,3]] = 1\n",
        "\n",
        "        pred_mesh_verts, pred_mesh_faces = marching_tetrahedra(verts_deformed.unsqueeze(0), tets, pred_sdfs.unsqueeze(0))\n",
        "        pred_mesh_verts, pred_mesh_faces = pred_mesh_verts[0], pred_mesh_faces[0]\n",
        "\n",
        "      loss = loss_f(pred_mesh_verts, pred_mesh_faces, wt_verts, it)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n",
        "          # save reconstructed mesh\n",
        "          timelapse.add_mesh_batch(\n",
        "              iteration=it+1,\n",
        "              category='extracted_mesh',\n",
        "              vertices_list=[pred_mesh_verts.cpu()],\n",
        "              faces_list=[pred_mesh_faces.cpu()]\n",
        "          )\n",
        "\n",
        "def encoder_train(iterations, model, optimizer, scheduler, tv = None):\n",
        "  # Set to training mode\n",
        "  model.train()\n",
        "\n",
        "  if tv is None:\n",
        "    tv = tets_verts\n",
        "\n",
        "  for it in range(iterations):\n",
        "      pred_sdfs, _ = model(tv)\n",
        "      \n",
        "      gt_sdfs = get_gt_sdfs(wt_verts.unsqueeze(0), wt_faces, tets_verts.unsqueeze(0))\n",
        "\n",
        "      loss = F.mse_loss(pred_sdfs, gt_sdfs) \n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n",
        "          # save reconstructed mesh\n",
        "          # timelapse.add_mesh_batch(\n",
        "          #     iteration=it+1,\n",
        "          #     category='extracted_mesh',\n",
        "          #     vertices_list=[pred_mesh_verts.cpu()],\n",
        "          #     faces_list=[pred_mesh_faces.cpu()]\n",
        "          # )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5bFm72fRWCyG"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tfPUfWWCbCC"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hide training MLP"
      ],
      "metadata": {
        "id": "sJnyRZh-GPVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL.pre_train_sphere(1000)\n",
        "# sdf_vars = [p for _, p in MODEL.named_parameters()]\n",
        "# sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "# sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# # ~12 min. Speed up?\n",
        "# encoder_train(iterations, MODEL, sdf_optimizer, sdf_scheduler)\n"
      ],
      "metadata": {
        "id": "Fcw5NxASCxNk"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "MOLR1SY1IoFk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIZbLWiqaL5d"
      },
      "source": [
        " # Surface refinement utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "outputs": [],
      "source": [
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if thresh = 0, return all surface tetrahedrons\n",
        "# if thresh > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "def extract_tet(tets, sdf, thresh, non_surf=False):\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  if thresh == 0:\n",
        "    mask = sdf[tets] > 0\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (sdf[tets] >= -thresh) & (sdf[tets] <= thresh)\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    if thresh == 0:\n",
        "      non_surf_tets = tets[~((t > 0) & (t < 4))]\n",
        "    else:\n",
        "      non_surf_tets = tets[t < 4]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2K3Oyhenh3FO"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-zgVu7bG1XU"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "6nAc-DFKb5rd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrEgkw5TksFD"
      },
      "source": [
        "# Surface refinement model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 744,
      "metadata": {
        "id": "z9uLf6MBUn49"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        deform = torch.tanh(deform)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN Loss Function"
      ],
      "metadata": {
        "id": "1IFRjw5xqqF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 745,
      "metadata": {
        "id": "U5GGfOyM3NRu"
      },
      "outputs": [],
      "source": [
        "from pytorch3d.loss import(\n",
        "    chamfer_distance\n",
        ")\n",
        "\n",
        "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
        "    term = torch.zeros_like(mesh_verts)\n",
        "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
        "\n",
        "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
        "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
        "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    pm = pytorch3d.structures.Meshes([mesh_verts], [mesh_faces])\n",
        "    gm = pytorch3d.structures.Meshes([gt_verts], [gt_faces])\n",
        "  \n",
        "    if mesh_verts.shape[0] > 0:\n",
        "      pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 100000)[0][0]\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 100000)[0][0]\n",
        "      chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), squared=False).mean()\n",
        "    else:\n",
        "      chamfer = 0\n",
        "\n",
        "\n",
        "    if it > iterations//2:\n",
        "      lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
        "      return 500*chamfer + lap * laplacian_weight \n",
        "    return 500*chamfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzjoso_kziVb"
      },
      "source": [
        "# Train GCN Model for Surface Refinement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 753,
      "metadata": {
        "id": "6QO7CuxCzohb"
      },
      "outputs": [],
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}\n",
        "\n",
        "# Same set of Hyperparam is applied\n",
        "lr = 1e-4\n",
        "laplacian_weight = 0.1\n",
        "gcn_iterations = 5000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8nVQmoCxq1iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScFyP4vfIyvV"
      },
      "execution_count": 753,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWI2hvwoI31h"
      },
      "execution_count": 753,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train(iterations, sdf_model, gcn_model, optimizer, scheduler, epoch):\n",
        "  gcn_model.train()\n",
        "  sdf_model.train()\n",
        "  avg_loss = 0\n",
        "  wt_models = []\n",
        "\n",
        "  for i in range(iterations):\n",
        "\n",
        "    gidx = randint(0, len(group) - 1)\n",
        "    g = group[gidx]\n",
        "\n",
        "    wt_grid = g[\"wt_grid\"]\n",
        "    wt_verts = g[\"wt_verts\"]\n",
        "    wt_faces = g[\"wt_faces\"]\n",
        "    gt_verts = g[\"gt_verts\"]\n",
        "    gt_faces = g[\"gt_faces\"]\n",
        "\n",
        "\n",
        "\n",
        "    F_vol = F.interpolate(wt_grid.unsqueeze(0), size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "\n",
        "    pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "    \"\"\"\n",
        "    Surface Refinement\n",
        "    \"\"\"\n",
        "\n",
        "    surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0.02) #if not working modify the 0.008 here; this is the threshold for surface sdf value\n",
        "    surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "    surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "    surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "    surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "    surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = pred_sdfs.clone()\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    update_tets_verts = tets_verts.clone()\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    update_tets_f = f_vs.clone()\n",
        "    update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "    if epoch < 500:\n",
        "      gt_sdfs = get_gt_sdfs(wt_verts.unsqueeze(0), wt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "      sdf_loss = F.mse_loss(update_sdfs, gt_sdfs, reduction='mean')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      sdf_loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      avg_loss += sdf_loss.item()\n",
        "\n",
        "      if epoch == 0 and i == 0:\n",
        "        print('========== Start pretraining ==========')\n",
        "      \n",
        "      if i == (iterations - 1) and epoch % 100 == 0:\n",
        "        print ('Epoch {} - loss: {}'.format(epoch, avg_loss/iterations))\n",
        "\n",
        "      continue\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "    mask = ((s_sdfs >= -0.3) & (s_sdfs <= 0.3)).squeeze(1)\n",
        "    p = update_sdfs[mask]\n",
        "    g = s_sdfs[mask]\n",
        "\n",
        "    sdf_loss = F.mse_loss(p, g, reduction='mean') \n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='mean')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, i)\n",
        "\n",
        "    g_loss = r_loss + deform_loss + 0.4*sdf_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    avg_loss += g_loss.item()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch == 500 and i == 0:\n",
        "        print('========== Start Refinement ==========')\n",
        "\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      if (i) % 1 == 0: \n",
        "        # print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(i, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "        \n",
        "        # save reconstructed mesh\n",
        "        timelapse.add_mesh_batch(\n",
        "            iteration=epoch+1,\n",
        "            category='final_train_res',\n",
        "            vertices_list=[mesh_verts.cpu()],\n",
        "            faces_list=[mesh_faces.cpu()]\n",
        "        )\n",
        "      \n",
        "      if i == (iterations - 1):\n",
        "        print ('Epoch {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(epoch, avg_loss/iterations, mesh_verts.shape[0], mesh_faces.shape[0]))"
      ],
      "metadata": {
        "id": "NBGRmGWDzOsd"
      },
      "execution_count": 758,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9M3I5JPI2dN"
      },
      "execution_count": 758,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GCN Optimizer\n"
      ],
      "metadata": {
        "id": "jEjTelVwqRJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GCN_SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 6, # Coordinates of the grid's vertices #previously 3\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "sdf_model = MLP(GCN_SDF_MLP_CONFIG).to(device)\n",
        "\n",
        "print(refine_model)\n",
        "\n",
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "\n",
        "params = list(sdf_model.named_parameters()) + list(refine_model.named_parameters())\n",
        "\n",
        "refine_vars = [p for _, p in params]\n",
        "refine_optimizer = torch.optim.Adam(refine_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(refine_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "mjynxhHk2w11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8150a890-8cb6-48b2-b80e-124df8741f0f"
      },
      "execution_count": 759,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN_Res(\n",
            "  (gcn_res): ModuleList(\n",
            "    (0): GBottleneck(\n",
            "      (blocks): Sequential(\n",
            "        (0): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "        (1): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "      )\n",
            "      (conv1): GraphConv(68 -> 128, directed=False)\n",
            "    )\n",
            "  )\n",
            "  (sdf_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
            "  )\n",
            "  (deform_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=3, bias=False)\n",
            "  )\n",
            "  (feature_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=64, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 760,
      "metadata": {
        "id": "5pn7Q89vgch9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbd2103-30ba-4cb7-aeee-5775dbb85d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/3000 [00:00<24:33,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Start pretraining ==========\n",
            "Epoch 0 - loss: 0.04032648727297783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 101/3000 [00:45<23:41,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 - loss: 0.03344113752245903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 201/3000 [01:36<28:18,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200 - loss: 0.3127651810646057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 301/3000 [02:56<45:49,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 300 - loss: 0.015374894253909588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 401/3000 [04:47<51:15,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 400 - loss: 0.01308599766343832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 500/3000 [06:54<57:02,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Start Refinement ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 501/3000 [06:56<1:06:14,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500 - loss: 158.60443115234375, # of mesh vertices: 197362, # of mesh faces: 389557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 601/3000 [09:30<1:08:19,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 600 - loss: 120.02179718017578, # of mesh vertices: 81847, # of mesh faces: 161432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 701/3000 [12:10<1:18:41,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 700 - loss: 54.75283432006836, # of mesh vertices: 47356, # of mesh faces: 94021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 801/3000 [14:50<56:36,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 800 - loss: 28.627580642700195, # of mesh vertices: 28109, # of mesh faces: 56496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 901/3000 [17:18<46:28,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 900 - loss: 80.23519134521484, # of mesh vertices: 60688, # of mesh faces: 120098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1001/3000 [19:02<41:44,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000 - loss: 14.30440616607666, # of mesh vertices: 32388, # of mesh faces: 65364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 1101/3000 [20:59<30:59,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1100 - loss: 13.212596893310547, # of mesh vertices: 27948, # of mesh faces: 56620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 1201/3000 [22:36<28:50,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1200 - loss: 12.941976547241211, # of mesh vertices: 31681, # of mesh faces: 64778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 1301/3000 [24:22<31:15,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1300 - loss: 14.330855369567871, # of mesh vertices: 37542, # of mesh faces: 76268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 1401/3000 [25:52<34:10,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1400 - loss: 18.272363662719727, # of mesh vertices: 41446, # of mesh faces: 83672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1501/3000 [27:30<21:34,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500 - loss: 15.223045349121094, # of mesh vertices: 30970, # of mesh faces: 62564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 1601/3000 [29:14<24:04,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1600 - loss: 15.061433792114258, # of mesh vertices: 39004, # of mesh faces: 78764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 1701/3000 [30:55<31:48,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1700 - loss: 50.28614807128906, # of mesh vertices: 59404, # of mesh faces: 118672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 1801/3000 [32:13<21:47,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1800 - loss: 20.553956985473633, # of mesh vertices: 35837, # of mesh faces: 71754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1901/3000 [33:32<17:23,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1900 - loss: 20.540023803710938, # of mesh vertices: 33660, # of mesh faces: 67924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 2001/3000 [34:48<12:44,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000 - loss: 19.583452224731445, # of mesh vertices: 36162, # of mesh faces: 73024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 2101/3000 [36:07<13:06,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2100 - loss: 18.526134490966797, # of mesh vertices: 35644, # of mesh faces: 72488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 2201/3000 [37:29<12:06,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2200 - loss: 14.334057807922363, # of mesh vertices: 40008, # of mesh faces: 81744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 2301/3000 [38:42<10:17,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2300 - loss: 11.856159210205078, # of mesh vertices: 39330, # of mesh faces: 79800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 2401/3000 [39:56<09:24,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2400 - loss: 11.3319091796875, # of mesh vertices: 38388, # of mesh faces: 77856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 2501/3000 [41:10<07:57,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2500 - loss: 14.463262557983398, # of mesh vertices: 41242, # of mesh faces: 83920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 2601/3000 [42:23<05:17,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2600 - loss: 16.731491088867188, # of mesh vertices: 35648, # of mesh faces: 72416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 2701/3000 [43:42<04:18,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2700 - loss: 13.373225212097168, # of mesh vertices: 39150, # of mesh faces: 79276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 2801/3000 [44:52<02:47,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2800 - loss: 10.384215354919434, # of mesh vertices: 32560, # of mesh faces: 65920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 2901/3000 [46:10<02:04,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2900 - loss: 17.10131072998047, # of mesh vertices: 41580, # of mesh faces: 84528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [47:17<00:00,  1.06it/s]\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "for i in tqdm(range(3000)):\n",
        "  test_train(1, sdf_model, refine_model, refine_optimizer, refine_scheduler, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "sls6E1AgBIlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# break"
      ],
      "metadata": {
        "id": "Ftr5HFxBozyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# hyperparameters\n",
        "N = 18 \n",
        "r = 128\n",
        "Kg_min = math.pi / 16\n",
        "n_sample_patches = 10\n",
        "# iterations = 20000 "
      ],
      "metadata": {
        "id": "pwKUU9mU9VTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def calculate_gaussian_curvature(vertices, faces):\n",
        "    # Calculate the vertex normals\n",
        "    v_normals = torch.zeros_like(vertices)\n",
        "    for face in faces:\n",
        "        # Get the vertices of the current face\n",
        "        v1 = vertices[face[0]]\n",
        "        v2 = vertices[face[1]]\n",
        "        v3 = vertices[face[2]]\n",
        "\n",
        "        # Calculate the face normal\n",
        "        f_normal = torch.cross(v2 - v1, v3 - v1)\n",
        "        f_normal = f_normal / f_normal.norm()\n",
        "\n",
        "        # Add the face normal to the vertex normals of the vertices of the current face\n",
        "        v_normals[face[0]] += f_normal\n",
        "        v_normals[face[1]] += f_normal\n",
        "        v_normals[face[2]] += f_normal\n",
        "\n",
        "    # Normalize the vertex normals\n",
        "    v_normals = v_normals / v_normals.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # Calculate the Gaussian curvature for each vertex\n",
        "    gaussian_curvature = torch.zeros(vertices.shape[0])\n",
        "    for i in range(vertices.shape[0]):\n",
        "        # Get the neighbors of the current vertex\n",
        "        neighbors = []\n",
        "        for face in faces:\n",
        "            if i in face:\n",
        "                for j in face:\n",
        "                    if j != i:\n",
        "                        neighbors.append(j)\n",
        "        neighbors = torch.tensor(list(set(neighbors)))\n",
        "\n",
        "        # Calculate the angle sum at the current vertex\n",
        "        angle_sum = 0\n",
        "        for j in neighbors:\n",
        "            # Calculate the angle between the normals of the current vertex and its neighbor\n",
        "            angle = torch.acos(torch.clamp(torch.dot(v_normals[i], v_normals[j]), -1, 1))\n",
        "\n",
        "            # Add the angle to the angle sum\n",
        "            angle_sum += angle\n",
        "\n",
        "        # Calculate the Gaussian curvature at the current vertex\n",
        "        gaussian_curvature[i] = (2 * math.pi - angle_sum) / len(neighbors)\n",
        "\n",
        "    return gaussian_curvature\n"
      ],
      "metadata": {
        "id": "MjyuDDPDRuHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DISCRIMINATOR_CONFIG = {\n",
        "#     'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'kernel_size' : [4, 3, 3, 3, 3],\n",
        "    'out_channel' : [32, 64, 128, 256, 512],\n",
        "    'stride' : [1, 2, 1, 1, 1],\n",
        "    'output_dim' : 512 # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}"
      ],
      "metadata": {
        "id": "hRTcq_QatAfi"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/czq142857/DECOR-GAN/blob/3d736bf0f5bd9206cc26ee5336c1d7b4172f6cf8/evalFID.py#L63\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # self.config = config\n",
        "        self.voxel_size = 64\n",
        "\n",
        "        self.conv_1 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=4, stride=1, bias=True)\n",
        "        self.bn_1 = nn.InstanceNorm3d(32)\n",
        "\n",
        "        self.conv_2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=2, bias=True)\n",
        "        self.bn_2 = nn.InstanceNorm3d(64)\n",
        "\n",
        "        self.conv_3 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, bias=True)\n",
        "        self.bn_3 = nn.InstanceNorm3d(128)\n",
        "\n",
        "        self.conv_4 = nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, stride=1, bias=True)\n",
        "        self.bn_4 = nn.InstanceNorm3d(256)\n",
        "\n",
        "        self.conv_5 = nn.Conv3d(in_channels=256, out_channels=512, kernel_size=3, stride=1, bias=True)\n",
        "\n",
        "#         if self.voxel_size==256:\n",
        "#             self.bn_5 = nn.InstanceNorm3d(self.z_dim)\n",
        "#             self.conv_5_2 = nn.Conv3d(self.z_dim, self.z_dim, 4, stride=2, padding=1, bias=True)\n",
        "\n",
        "        self.linear1 = nn.Linear(512, 1, bias=True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out = inputs\n",
        "\n",
        "        out = self.bn_1(self.conv_1(out))\n",
        "        out = F.leaky_relu(out, negative_slope=0.01, inplace=True)\n",
        "\n",
        "        out = self.bn_2(self.conv_2(out))\n",
        "        out = F.leaky_relu(out, negative_slope=0.01, inplace=True)\n",
        "\n",
        "        out = self.bn_3(self.conv_3(out))\n",
        "        out = F.leaky_relu(out, negative_slope=0.01, inplace=True)\n",
        "\n",
        "        out = self.bn_4(self.conv_4(out))\n",
        "        out = F.leaky_relu(out, negative_slope=0.01, inplace=True)\n",
        "\n",
        "        out = self.conv_5(out)\n",
        "\n",
        "#         if self.voxel_size==256:\n",
        "#             out = self.bn_5(out)\n",
        "#             out = F.leaky_relu(out, negative_slope=0.01, inplace=True)\n",
        "#             out = self.conv_5_2(out)\n",
        "\n",
        "        z = F.adaptive_avg_pool3d(out, output_size=(1, 1, 1))\n",
        "        z = z.view(-1,512)\n",
        "        out = F.leaky_relu(z, negative_slope=0.01, inplace=True)\n",
        "        \n",
        "        # Add Fvol here (512) !!!\n",
        "        \n",
        "        out = self.linear1(out)\n",
        "\n",
        "        return out, z"
      ],
      "metadata": {
        "id": "aPq9b5Qha7lc"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_faces(faces, vertex_gaussians, threshold):\n",
        "  face_mask = vertex_gaussians[faces[:,0]] > threshold & vertex_gaussians[faces[:,1]] > threshold & vertex_gaussians[faces[:,2]] > threshold\n",
        "  return faces[face_mask]"
      ],
      "metadata": {
        "id": "nNTiNtIygrJw"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-qoObtdddnA"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def test_train2(iterations, sdf_model, gcn_model, discrim_model, optimizer, scheduler, epoch):\n",
        "#   gcn_model.train()\n",
        "#   sdf_model.train()\n",
        "#   discrim_model.train()\n",
        "#   avg_loss = 0\n",
        "#   wt_models = []\n",
        "\n",
        "#   for i in range(iterations):\n",
        "\n",
        "#     F_vol = F.interpolate(wt_grid.unsqueeze(0), size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "#     F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "\n",
        "#     pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "#     \"\"\"\n",
        "#     Surface Refinement\n",
        "#     \"\"\"\n",
        "\n",
        "#     surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0.008) #if not working modify the 0.008 here; this is the threshold for surface sdf value\n",
        "#     surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "#     surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "#     surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "#     surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "#     surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "#     sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "#     \"\"\"\n",
        "\n",
        "#     Update surface position, sdf, and f_s\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     #updated sdf\n",
        "\n",
        "#     update_sdfs = pred_sdfs.clone()\n",
        "#     update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "#     #update vertices positions\n",
        "\n",
        "#     update_tets_verts = tets_verts.clone()\n",
        "#     update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "#     #update vertices features\n",
        "\n",
        "#     update_tets_f = f_vs.clone()\n",
        "#     update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "#     #Generate sdf \n",
        "\n",
        "\n",
        "#     # shape of SDFs\n",
        "#     Sreal = np.ones((N,N,N)) #mesh \n",
        "#     Sgt = np.ones((N,N,N))\n",
        "\n",
        "#     # Kg is dimension Vgt x 1\n",
        "#     Kg = calculate_gaussian_curvature(gt_verts, gt_faces).to(device)\n",
        "#     # mask_curvature = Kg >= Kg_min\n",
        "\n",
        "#     # # mask vertices\n",
        "#     # V_gt = gt_verts[mask_curvature].clone()\n",
        "#     # V_pred = update_tets_verts[mask_curvature].clone()\n",
        "\n",
        "#     # remap faces to new \n",
        "#     F_gt = filter_faces(gt_faces, Kg, Kg_min)\n",
        "#     F_pred = filter_faces(surf_tets_faces, Kg, Kg_min)\n",
        "\n",
        "\n",
        "#     v_gt = kaolin.ops.mesh.sample_points(gt_verts, F_gt, 1)\n",
        "#     v_pred = kaolin.ops.mesh.sample_points(update_tets_verts, F_pred, 1)\n",
        "\n",
        "#     # N x N x N, N=18\n",
        "#     vox_gt = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(v_gt, F_gt, N)\n",
        "#     vox_pred = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(v_pred, F_pred, N)\n",
        "\n",
        "\n",
        "#     pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "\n",
        "\n",
        "#     s_real = SDF(Vgt + (Vgt.shape[0] - N/2) / r, (vgt, fgt))\n",
        "#     Sreal = SDF(Vgt + (Vgt.shape[0] - N/2) / r, (vgt, fgt))\n",
        "\n",
        "#     if epoch < 500:\n",
        "#       gt_sdfs = get_gt_sdfs(wt_verts.unsqueeze(0), wt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "#       sdf_loss = F.mse_loss(update_sdfs, gt_sdfs, reduction='mean')\n",
        "\n",
        "#       optimizer.zero_grad()\n",
        "#       sdf_loss.backward(retain_graph=True)\n",
        "#       optimizer.step()\n",
        "#       avg_loss += sdf_loss.item()\n",
        "\n",
        "#       if epoch == 0 and i == 0:\n",
        "#         print('========== Start pretraining ==========')\n",
        "      \n",
        "#       if i == (iterations - 1) and epoch % 100 == 0:\n",
        "#         print ('Epoch {} - loss: {}'.format(epoch, avg_loss/iterations))\n",
        "\n",
        "#       continue\n",
        "\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "#     mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     Compute Loss for First surface refinement: \n",
        "#     Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "#     \"\"\"\n",
        "\n",
        "#     # L2 sdf reg: \n",
        "\n",
        "#     s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "#     mask = ((s_sdfs >= -0.3) & (s_sdfs <= 0.3)).squeeze(1)\n",
        "#     p = update_sdfs[mask]\n",
        "#     g = s_sdfs[mask]\n",
        "\n",
        "#     sdf_loss = F.mse_loss(p, g, reduction='mean') \n",
        "\n",
        "#     #L2 deform reg\n",
        "\n",
        "#     deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='mean')\n",
        "\n",
        "#     #surface alignment loss\n",
        "\n",
        "#     r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, i)\n",
        "\n",
        "#     g_loss = r_loss + deform_loss + 0.4*sdf_loss\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     torch.autograd.set_detect_anomaly(True)\n",
        "#     g_loss.backward(retain_graph=True)\n",
        "#     avg_loss += g_loss.item()\n",
        "#     optimizer.step()\n",
        "#     scheduler.step()\n",
        "\n",
        "#     if epoch == 500 and i == 0:\n",
        "#         print('========== Start Refinement ==========')\n",
        "\n",
        "    \n",
        "#     if epoch % 100 == 0:\n",
        "#       if (i) % 1 == 0: \n",
        "#         # print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(i, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "        \n",
        "#         # save reconstructed mesh\n",
        "#         timelapse.add_mesh_batch(\n",
        "#             iteration=epoch+1,\n",
        "#             category='final_train_res',\n",
        "#             vertices_list=[mesh_verts.cpu()],\n",
        "#             faces_list=[mesh_faces.cpu()]\n",
        "#         )\n",
        "      \n",
        "#       if i == (iterations - 1):\n",
        "#         print ('Epoch {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(epoch, avg_loss/iterations, mesh_verts.shape[0], mesh_faces.shape[0]))"
      ],
      "metadata": {
        "id": "H_KBEdwytCc1"
      },
      "execution_count": 642,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IxqV7DVAM1DI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLsjyWXSJric"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "Oicuzl0WSHRE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xoE7xYCtM572"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "Fm5aud4mz6ZJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "iADZ6VnsBTCJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtgAIHqJpIrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Hlf1luSRwZ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7ylyiYXI08J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KqpAj60k-ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "HqEaSvssI8it"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhShD27xy42k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RPwOOP0bNH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsUxitzdzEja"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore"
      ],
      "metadata": {
        "id": "SuSL2XdvFEwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx0o-m2bukdz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "to-dos: volume subdivision\n",
        "\n",
        "identify T_surf's neighbors: i.e. share a same edge\n",
        "\n",
        "subdivide T_surf to perform another surface refinement\n",
        "unsubdivded tet, i.e. not surface's neighbor, is dropped to save memory and computation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#neightbor if share an edge\n",
        "#identify edge based on surf_faces and adj matrix\n",
        "\n",
        "\"\"\"\n",
        "convert face_lists = [v1, v2, v3, v4] --> \n",
        "[\n",
        "  [v1, v2, v3, E, o1],\n",
        "  [v2, v3, v4, E, o2],\n",
        "  [v1, v2, v4, E, o3],\n",
        "  [v1, v3, v4, E, o4]\n",
        "]\n",
        "\n",
        "by torch combinations, E = tet index, o_i = face_i index\n",
        "\"\"\"\n",
        "def convert_face_lists(tets):\n",
        "  face_idx = torch.tensor([1,2,3,4])\n",
        "  tet_face_list = []\n",
        "  for idx, tet in enumerate(tets):\n",
        "    tet_idx = torch.full(4, idx)\n",
        "    tet_faces = torch.combinations(tet, r=3)\n",
        "    tet_faces = torch.cat((tet_faces, tet_idx, face_idx), dim=1)\n",
        "    tet_face_list.append(tet_faces)\n",
        "\n",
        "  tet_face_list = torch.stack(tet_face_list, dim=0)\n",
        "\n",
        "  def compare(face_1, face_2):\n",
        "    o1 = face_1[0]-face_2[0]\n",
        "    o2 = face_1[1]-face_2[1]\n",
        "    o3 = face_1[2]-face_2[2]\n",
        "\n",
        "    if o1 <= 0 or (o1 == 0 and o2 < 0) or (o1 == 0 and o2 == 0 and o3 < 0):\n",
        "      return -1\n",
        "    elif o1 == 0 and o2 == 0 and o3 == 0:\n",
        "      return 0\n",
        "    else: \n",
        "      return 1\n",
        "\n",
        "  sorted(tet_face_list, cmp=compare)\n",
        "  return tet_face_list\n",
        "\n",
        "def get_neighbor(surf_tet_verts, surf_tets, tet_verts, tets):\n",
        "  tet_face_list = convert_face_lists(tets)\n",
        "  \n",
        "\n",
        "surf_idx, surf = extract_tet(tets, pred_sdfs, 0.003)\n",
        "\n",
        "print(surf_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Too6Yu0KxrRH"
      },
      "outputs": [],
      "source": [
        "def get_faces(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=3)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e-1rPxP3Ru9"
      },
      "outputs": [],
      "source": [
        "# a = get_faces(tets)\n",
        "# b = get_faces(tets[surf_idx])\n",
        "\n",
        "# # OPTIMIZE TF OUT OF THIS\n",
        "# for f in b:\n",
        "#   mask = a == f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inverse Distance Interpolation"
      ],
      "metadata": {
        "id": "U6zin3bFFOuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Other idea is to use a Point Cloud Encoder to retrieve a feature vector from the output's activation."
      ],
      "metadata": {
        "id": "B9ptcCU-GJpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 800, 1600, 1600],\n",
        "    'output_dim' : 832, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}"
      ],
      "metadata": {
        "id": "P1yXmafcGF6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return output + last feature layer vector"
      ],
      "metadata": {
        "id": "KsocgWHOFMX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pointnet = MLP(ENCODER_MLP_CONFIG)\n",
        "# pointnet = pointnet.to(device)\n",
        "\n",
        "# pc = pc.to(device)\n",
        "\n",
        "# print(pointnet)\n",
        "# print('\\n\\n')\n",
        "# summary(pointnet, input_size= pc.shape)"
      ],
      "metadata": {
        "id": "T7myzQgsFuI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpolate feature values on the grid"
      ],
      "metadata": {
        "id": "aZDz1X0XF1UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We* implement an inverse distance interpolation based on a K-NN algorithm :\n",
        "Given N known points and their features and a batch of M points with unknown features, the interpolator find the K nearest neigbors in the set N for each point of the batch M. Then it interpolates the features of the batch points M using an inverse distance weighting of the features of the K known neighbour points. \n",
        "\n",
        "K can be fine-tuned to balance efficiency and speed.\n",
        "\n",
        "Implementation can be found here\n",
        "https://stackoverflow.com/questions/3104781/inverse-distance-weighted-idw-interpolation-with-python"
      ],
      "metadata": {
        "id": "fqW_Z2I6F4Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree as KDTree\n",
        "    # http://docs.scipy.org/doc/scipy/reference/spatial.html\n",
        "\n",
        "__date__ = \"2010-11-09 Nov\"  # weights, doc\n",
        "\n",
        "#...............................................................................\n",
        "class Invdisttree:\n",
        "    \"\"\" inverse-distance-weighted interpolation using KDTree:\n",
        "invdisttree = Invdisttree( X, z )  -- data points, values\n",
        "interpol = invdisttree( q, nnear=3, eps=0, p=1, weights=None, stat=0 )\n",
        "    interpolates z from the 3 points nearest each query point q;\n",
        "    For example, interpol[ a query point q ]\n",
        "    finds the 3 data points nearest q, at distances d1 d2 d3\n",
        "    and returns the IDW average of the values z1 z2 z3\n",
        "        (z1/d1 + z2/d2 + z3/d3)\n",
        "        / (1/d1 + 1/d2 + 1/d3)\n",
        "        = .55 z1 + .27 z2 + .18 z3  for distances 1 2 3\n",
        "\n",
        "    q may be one point, or a batch of points.\n",
        "    eps: approximate nearest, dist <= (1 + eps) * true nearest\n",
        "    p: use 1 / distance**p\n",
        "    weights: optional multipliers for 1 / distance**p, of the same shape as q\n",
        "    stat: accumulate wsum, wn for average weights\n",
        "\n",
        "How many nearest neighbors should one take ?\n",
        "a) start with 8 11 14 .. 28 in 2d 3d 4d .. 10d; see Wendel's formula\n",
        "b) make 3 runs with nnear= e.g. 6 8 10, and look at the results --\n",
        "    |interpol 6 - interpol 8| etc., or |f - interpol*| if you have f(q).\n",
        "    I find that runtimes don't increase much at all with nnear -- ymmv.\n",
        "\n",
        "p=1, p=2 ?\n",
        "    p=2 weights nearer points more, farther points less.\n",
        "    In 2d, the circles around query points have areas ~ distance**2,\n",
        "    so p=2 is inverse-area weighting. For example,\n",
        "        (z1/area1 + z2/area2 + z3/area3)\n",
        "        / (1/area1 + 1/area2 + 1/area3)\n",
        "        = .74 z1 + .18 z2 + .08 z3  for distances 1 2 3\n",
        "    Similarly, in 3d, p=3 is inverse-volume weighting.\n",
        "\n",
        "Scaling:\n",
        "    if different X coordinates measure different things, Euclidean distance\n",
        "    can be way off.  For example, if X0 is in the range 0 to 1\n",
        "    but X1 0 to 1000, the X1 distances will swamp X0;\n",
        "    rescale the data, i.e. make X0.std() ~= X1.std() .\n",
        "\n",
        "A nice property of IDW is that it's scale-free around query points:\n",
        "if I have values z1 z2 z3 from 3 points at distances d1 d2 d3,\n",
        "the IDW average\n",
        "    (z1/d1 + z2/d2 + z3/d3)\n",
        "    / (1/d1 + 1/d2 + 1/d3)\n",
        "is the same for distances 1 2 3, or 10 20 30 -- only the ratios matter.\n",
        "In contrast, the commonly-used Gaussian kernel exp( - (distance/h)**2 )\n",
        "is exceedingly sensitive to distance and to h.\n",
        "\n",
        "    \"\"\"\n",
        "# anykernel( dj / av dj ) is also scale-free\n",
        "# error analysis, |f(x) - idw(x)| ? todo: regular grid, nnear ndim+1, 2*ndim\n",
        "\n",
        "    def __init__( self, X, z, leafsize=10, stat=0 ):\n",
        "        assert len(X) == len(z), \"len(X) %d != len(z) %d\" % (len(X), len(z))\n",
        "        self.tree = KDTree( X, leafsize=leafsize )  # build the tree\n",
        "        self.z = z\n",
        "        self.stat = stat\n",
        "        self.wn = 0\n",
        "        self.wsum = None;\n",
        "\n",
        "    def __call__( self, q, nnear=6, eps=0, p=1, weights=None ):\n",
        "            # nnear nearest neighbours of each query point --\n",
        "        q = np.asarray(q)\n",
        "        qdim = q.ndim\n",
        "        if qdim == 1:\n",
        "            q = np.array([q])\n",
        "        if self.wsum is None:\n",
        "            self.wsum = np.zeros(nnear)\n",
        "\n",
        "        self.distances, self.ix = self.tree.query( q, k=nnear, eps=eps )\n",
        "        interpol = np.zeros( (len(self.distances),) + np.shape(self.z[0]) )\n",
        "        jinterpol = 0\n",
        "        for dist, ix in zip( self.distances, self.ix ):\n",
        "            if nnear == 1:\n",
        "                wz = self.z[ix]\n",
        "            elif dist[0] < 1e-10:\n",
        "                wz = self.z[ix[0]]\n",
        "            else:  # weight z s by 1/dist --\n",
        "                w = 1 / dist**p\n",
        "                if weights is not None:\n",
        "                    w *= weights[ix]  # >= 0\n",
        "                w /= np.sum(w)\n",
        "                wz = np.dot( w, self.z[ix] )\n",
        "                if self.stat:\n",
        "                    self.wn += 1\n",
        "                    self.wsum += w\n",
        "            interpol[jinterpol] = wz\n",
        "            jinterpol += 1\n",
        "        return interpol if qdim > 1  else interpol[0]"
      ],
      "metadata": {
        "id": "r5WHgsIIF0sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test the interpolation by splitting the point cloud (of size 1000) into a \n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "known set of size N= 600 and an unknown batch of M= 400 points"
      ],
      "metadata": {
        "id": "OwsoSX9tF8Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INTERP_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 800, 1600, 1600],\n",
        "    'output_dim' : 832, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}\n",
        "\n",
        "pointnet = MLP(INTERP_MLP_CONFIG).to(device)\n",
        "print(pointnet)\n",
        "print('\\n\\n')\n",
        "summary(pointnet, input_size= gt_verts.shape)"
      ],
      "metadata": {
        "id": "C4Gg6_YJsAdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pointnet = MLP(INTERP_MLP_CONFIG).to(device)\n",
        "pointnet.pre_train_sphere(1000)\n",
        "sdf_vars = [p for _, p in pointnet.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# ~12 min. Speed up?\n",
        "encoder_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler)\n",
        "\n",
        "pointnet.eval()\n",
        "f_vol, _ = pointnet(wt_verts)\n",
        "\n",
        "\n",
        "sample_known = wt_verts.squeeze()[:600] # shape 600 x 3. Set of N= 600 points with known features\n",
        "sample_unknown = wt_verts.squeeze()[600:] # shape 400x3. Batch of M= 400 points on which we will interpolate the features\n",
        "f_vol_known = f_vol.squeeze()[:600] # Shape 600 x 832. Set of the feature vectors F_vol of the set N\n",
        "f_vol_unknown = f_vol.squeeze()[600:] # Shape 400 x 832. Ground truth of F_vol for the batch M unknown points. Used to test the interpolation performance\n"
      ],
      "metadata": {
        "id": "qskzIevespSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leafsize = 10 # leaf size of the KDTree. This means the KDTree will store \"leafsize\" number of neighbour points for each data point\n",
        "eps = .1  # approximate nearest, dist <= (1 + eps) * true nearest\n",
        "p = 1  # weights ~ 1 / distance**p\n",
        "Nnear = 8  # 8 2d, 11 3d => 5 % chance one-sided -- Wendel, mathoverflow.com\n",
        "\n",
        "\n",
        "invdisttree = Invdisttree( sample_known.squeeze().detach().cpu(), f_vol_known.squeeze().detach().cpu(), leafsize=leafsize, stat=1 )\n",
        "interpol = invdisttree( sample_unknown.detach().cpu(), nnear=Nnear, eps=eps, p=p ) # return numpy array\n",
        "\n",
        "# err = np.abs( f_vol_unknown.detach().numpy() - interpol )\n",
        "# print(\"average |ground_truth - interpolated|: %.2g\" % np.mean(err))"
      ],
      "metadata": {
        "id": "NZUzypIZGBE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCWKQ1wDsoiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we compute the F_vol interpolation on the grid vertices"
      ],
      "metadata": {
        "id": "Je8hhXqLYmPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tets_f_vol = invdisttree( tets_verts.detach().cpu(), nnear=Nnear, eps=eps, p=p ) # ~ 5-10sec\n",
        "tets_f_vol = torch.tensor(tets_f_vol, device=device, dtype=torch.float)"
      ],
      "metadata": {
        "id": "RXa2RPGOYk_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_input = torch.cat(tensors= (tets_f_vol, tets_verts), dim= 1)"
      ],
      "metadata": {
        "id": "-bS7jgfB0vQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HafKuXZ0YrEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To Do: Add this to MLP Encoder"
      ],
      "metadata": {
        "id": "e7ZCP7BBYuXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SDF_INTERPOLATE_MLP_CONFIG = {\n",
        "    'input_dim' : 3 + 832, # Coordinates of the grid's vertices + F_vol dimension (concatenation)\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "}\n",
        "sdf_model = MLP(SDF_INTERPOLATE_MLP_CONFIG).to(device)\n",
        "sdf_model.pre_train_sphere(2000)\n",
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "# ~12 min. Speed up?\n",
        "encoder_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler, tv=sdf_input)"
      ],
      "metadata": {
        "id": "ZR7mJdk2uhI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# pred_sdfs, f_vs = sdf_model(sdf_input)"
      ],
      "metadata": {
        "id": "jonGw_6AYw47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sChTVQkAt_UX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t2XxoP2lY1Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7RCV62USts"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 593,
      "metadata": {
        "id": "p68GrPqkUU07"
      },
      "outputs": [],
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2Hzzzh94FgOXssVkSP5Yffz8uYg_By2RMDZLTPx1aXakhYfH\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 686,
      "metadata": {
        "id": "rWJ2SS1EUYjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c549366-00e1-4300-ec54-2e4b71e6713a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking URL: NgrokTunnel: \"http://7b63-34-141-173-195.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ],
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wucOgHgu4WAN"
      },
      "execution_count": 686,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 687,
      "metadata": {
        "id": "9RZLd8x7UrUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f0c5cd-626c-4682-fcac-90d4c9144899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash3D server starting. Go to: http://localhost:80\n",
            "2022-12-16 00:52:48,131|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 00:52:53,782|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 00:52:53,809|    INFO| tornado.access| 200 GET / (127.0.0.1) 213.34ms\n",
            "2022-12-16 00:52:54,097|    INFO| tornado.access| 200 GET /static/thirdparty.css (127.0.0.1) 2.78ms\n",
            "2022-12-16 00:52:54,153|    INFO| tornado.access| 200 GET /static/thirdparty.js (127.0.0.1) 4.26ms\n",
            "2022-12-16 00:52:54,197|    INFO| tornado.access| 200 GET /static/style.css (127.0.0.1) 4.20ms\n",
            "2022-12-16 00:52:54,200|    INFO| tornado.access| 200 GET /static/core-min.js (127.0.0.1) 2.72ms\n",
            "2022-12-16 00:52:54,857|    INFO| tornado.access| 200 GET /static/green_plastic.frag (127.0.0.1) 2.53ms\n",
            "2022-12-16 00:52:54,877|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 0.58ms\n",
            "2022-12-16 00:52:55,047|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-16 00:52:55,059|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 3.54ms\n",
            "2022-12-16 00:52:55,185|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.50ms\n",
            "2022-12-16 00:52:55,309|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.04ms\n",
            "2022-12-16 00:52:55,456|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.40ms\n",
            "2022-12-16 00:52:55,458|    INFO| tornado.access| 200 GET /static/favicon.ico (127.0.0.1) 4.63ms\n",
            "2022-12-16 00:53:05,479|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.31ms\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg/tornado/platform/asyncio.py\", line 199, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1823, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaolin-dash3d\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/kaolin-dash3d\", line 6, in <module>\n",
            "    run_main()\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/run.py\", line 97, in run_main\n",
            "    IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg/tornado/platform/asyncio.py\", line 201, in start\n",
            "    asyncio.set_event_loop(old_loop)\n",
            "  File \"/usr/lib/python3.8/asyncio/events.py\", line 751, in set_event_loop\n",
            "    def set_event_loop(loop):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lqIYyxq_sN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "bFoaoNpro6Jq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "ooT3zo23rA62"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "ixiLERLsrDz3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "24GAvO6IrKbC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 636,
      "metadata": {
        "id": "T9ZyP7cuGPR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c269b8d7-e056-4ea8-d849-70cc77d239ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize SDF to sphere\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:17<00:00, 58.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained MLP 0.00047968627768568695\n",
            "Iteration 0 - loss: 1.1691309213638306\n",
            "Iteration 100 - loss: 0.9695544838905334\n",
            "Iteration 200 - loss: 0.09632495790719986\n",
            "Iteration 300 - loss: 0.002511597704142332\n",
            "Iteration 400 - loss: 0.004841003566980362\n",
            "Iteration 500 - loss: 0.0031850431114435196\n",
            "Iteration 600 - loss: 0.004886094946414232\n",
            "Iteration 700 - loss: 0.006782314274460077\n",
            "Iteration 800 - loss: 0.0021261628717184067\n",
            "Iteration 900 - loss: 0.004020349122583866\n",
            "Iteration 1000 - loss: 0.0036146368365734816\n",
            "Iteration 1100 - loss: 0.0021590515971183777\n",
            "Iteration 1200 - loss: 0.00301489420235157\n",
            "Iteration 1300 - loss: 0.0010439787292852998\n",
            "Iteration 1400 - loss: 0.00287272478453815\n",
            "Iteration 1500 - loss: 0.0029820026829838753\n",
            "Iteration 1600 - loss: 0.002300722524523735\n",
            "Iteration 1700 - loss: 0.003140554064884782\n",
            "Iteration 1800 - loss: 0.002698600059375167\n",
            "Iteration 1900 - loss: 0.0022180448286235332\n",
            "Iteration 2000 - loss: 0.0020990099292248487\n",
            "Iteration 2100 - loss: 0.0016078735934570432\n",
            "Iteration 2200 - loss: 0.001856100047007203\n",
            "Iteration 2300 - loss: 0.0017264183843508363\n",
            "Iteration 2400 - loss: 0.001992342062294483\n",
            "Iteration 2500 - loss: 0.0015225777169689536\n",
            "Iteration 2600 - loss: 0.0020036573987454176\n",
            "Iteration 2700 - loss: 0.0028501928318291903\n",
            "Iteration 2800 - loss: 0.002511064289137721\n",
            "Iteration 2900 - loss: 0.0019847676157951355\n",
            "Iteration 2999 - loss: 0.0018256535986438394\n"
          ]
        }
      ],
      "source": [
        "baseline = Decoder(multires=2).to(device)\n",
        "baseline.pre_train_sphere(1000)\n",
        "baseline_vars = [p for _, p in baseline.named_parameters()]\n",
        "baseline_optimizer = torch.optim.Adam(baseline_vars, lr=lr)\n",
        "baseline_scheduler = torch.optim.lr_scheduler.LambdaLR(baseline_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "sdf_train(iterations, baseline, baseline_optimizer, baseline_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUMKIG7FlJX9"
      },
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, points, gt_verts, df, label, modelname):\n",
        "  # Set to training mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      F_vol = F.interpolate(points[None, None, None,:, :], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "      F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "      \n",
        "      pred, _ = model(F_vol)\n",
        "\n",
        "      pred_sdfs, deform = pred[:,0], pred[:,1:]\n",
        "      verts_deformed = tets_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
        "      pred_mesh_verts, pred_mesh_faces = marching_tetrahedra(verts_deformed.unsqueeze(0), tets, pred_sdfs.unsqueeze(0))\n",
        "      pred_mesh_verts, pred_mesh_faces = pred_mesh_verts[0], pred_mesh_faces[0]\n",
        "\n",
        "      pred_points = kaolin.ops.mesh.sample_points(pred_mesh_verts.unsqueeze(0), \n",
        "                                                pred_mesh_faces, 5000)[0][0]\n",
        "\n",
        "      chamferL1 = 100*pytorch3d.loss.chamfer_distance(pred_points.unsqueeze(0), gt_verts.unsqueeze(0), norm=1)[0] \n",
        "      chamferL2 = 100*kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_verts.unsqueeze(0), squared=False)[0] \n",
        "      fscore = 100*kaolin.metrics.pointcloud.f_score(gt_verts.unsqueeze(0), pred_points.unsqueeze(0))[0]\n",
        "\n",
        "\n",
        "      print (f'chamfer loss (L1) for {label}: {chamferL1}')\n",
        "      res = [label, \n",
        "             modelname,\n",
        "             chamferL1.cpu().numpy(), \n",
        "             chamferL2.cpu().numpy(), \n",
        "             fscore.cpu().numpy()]\n",
        "      df = df.append({a:v for (a,v) in zip(df.columns, res)}, ignore_index=True)\n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          category=\"results_\" +label,\n",
        "          vertices_list=[pred_mesh_verts.cpu()],\n",
        "          faces_list=[pred_mesh_faces.cpu()]\n",
        "      )\n",
        "  return df"
      ],
      "metadata": {
        "id": "0G-BxK7Gzxk8"
      },
      "execution_count": 637,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_shapenet_idx = group[-1][\"idx\"]\n",
        "print(next_shapenet_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBzf7UGrtXqU",
        "outputId": "4c10e46c-3a16-48f5-faa5-a8a1351e95f1"
      },
      "execution_count": 638,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kL6NtI5lzohx"
      },
      "execution_count": 691,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rh-fIxem3sUy"
      },
      "execution_count": 586,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXUzSIAb3085"
      },
      "execution_count": 691,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_GCN(gcn_model, sdf_model, wt_grid, gt_verts, df, label, modelname):\n",
        "    # Set to training mode\n",
        "    gcn_model.eval()\n",
        "    sdf_model.eval()\n",
        "\n",
        "    F_vol = F.interpolate(wt_grid.unsqueeze(0), size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "\n",
        "    pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "    \"\"\"\n",
        "    Surface Refinement\n",
        "    \"\"\"\n",
        "\n",
        "    surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0.008) #if not working modify the 0.008 here; this is the threshold for surface sdf value\n",
        "    surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "    surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "    surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "    surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "    surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = pred_sdfs.clone()\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    update_tets_verts = tets_verts.clone()\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    update_tets_f = f_vs.clone()\n",
        "    update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), \n",
        "                                                mesh_faces, 5000)[0][0]\n",
        "\n",
        "    chamferL1 = 100*pytorch3d.loss.chamfer_distance(pred_points.unsqueeze(0).detach(), gt_verts.unsqueeze(0), norm=1)[0] \n",
        "    chamferL2 = 100*kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0).detach(), gt_verts.unsqueeze(0), squared=False)[0] \n",
        "    fscore = 100*kaolin.metrics.pointcloud.f_score(gt_verts.unsqueeze(0), pred_points.unsqueeze(0).detach())[0]\n",
        "\n",
        "\n",
        "    print (f'chamfer loss (L1) for {label}: {chamferL1}')\n",
        "    res = [label, \n",
        "            modelname,\n",
        "            chamferL1.cpu().numpy(), \n",
        "            chamferL2.cpu().numpy(), \n",
        "            fscore.cpu().numpy()]\n",
        "    df = df.append({a:v for (a,v) in zip(df.columns, res)}, ignore_index=True)\n",
        "    # save reconstructed mesh\n",
        "    timelapse.add_mesh_batch(\n",
        "        category=\"results_\" +label,\n",
        "        vertices_list=[mesh_verts.cpu()],\n",
        "        faces_list=[mesh_faces.cpu()]\n",
        "    )\n",
        "    return df"
      ],
      "metadata": {
        "id": "gPt7EGUaYlE9"
      },
      "execution_count": 709,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BsQ4kp78LSf-"
      },
      "execution_count": 709,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def  create_df(num_test_models, modelname ):\n",
        "  assert modelname in (\"Baseline\", \"Ours\")\n",
        "  next_shapenet_idx = group[-1][\"idx\"]\n",
        "  print(next_shapenet_idx)\n",
        "  df = pd.DataFrame(columns = ['Label', 'ModelName', 'L1 Chamfer', 'L2 Chamfer', 'F Score'])\n",
        "  \n",
        "  idx = next_shapenet_idx\n",
        "  label=f\"bench_{modelname}_{idx}\"\n",
        "\n",
        "  idx, gt_verts, gt_faces, wt_grid, wt_verts, wt_faces, points = get_next_shapenet(idx)\n",
        "  if modelname == \"Baseline\":\n",
        "    df = test(baseline, points, gt_verts, df, label, modelname)\n",
        "  else:\n",
        "    df = test_GCN(refine_model,sdf_model, wt_grid, gt_verts, df, label, modelname=modelname)\n",
        "  \n",
        "  for i in range(num_test_models - 1):\n",
        "    idx, gt_verts, gt_faces, wt_grid, wt_verts, wt_faces, points = get_next_shapenet(idx)\n",
        "    if modelname == \"Baseline\":\n",
        "      df = test(baseline, points, gt_verts, df,  label, modelname)\n",
        "    else:\n",
        "      df = test_GCN(refine_model,sdf_model, wt_grid, gt_verts, df, label, modelname=modelname)\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "d0Xvl92vLWGT"
      },
      "execution_count": 710,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_df(4, \"Baseline\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "g1iOIbJlf_BR",
        "outputId": "45086cd9-5ef8-4218-f372-704fa6d96dd0"
      },
      "execution_count": 711,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "chamfer loss (L1) for bench_Baseline_17: 20.075788497924805\n",
            "chamfer loss (L1) for bench_Baseline_17: 19.034822463989258\n",
            "chamfer loss (L1) for bench_Baseline_17: 8.30785846710205\n",
            "chamfer loss (L1) for bench_Baseline_17: 19.667226791381836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Label ModelName L1 Chamfer  L2 Chamfer     F Score\n",
              "0  bench_Baseline_17  Baseline  20.075788  15.6275425   3.3848615\n",
              "1  bench_Baseline_17  Baseline  19.034822   13.452649  0.15147115\n",
              "2  bench_Baseline_17  Baseline   8.307858    5.875101    6.636428\n",
              "3  bench_Baseline_17  Baseline  19.667227   14.449131  0.92735654"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92441b58-ecd9-49e4-b5d9-079c11841ebf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>ModelName</th>\n",
              "      <th>L1 Chamfer</th>\n",
              "      <th>L2 Chamfer</th>\n",
              "      <th>F Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bench_Baseline_17</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>20.075788</td>\n",
              "      <td>15.6275425</td>\n",
              "      <td>3.3848615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bench_Baseline_17</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>19.034822</td>\n",
              "      <td>13.452649</td>\n",
              "      <td>0.15147115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bench_Baseline_17</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>8.307858</td>\n",
              "      <td>5.875101</td>\n",
              "      <td>6.636428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bench_Baseline_17</td>\n",
              "      <td>Baseline</td>\n",
              "      <td>19.667227</td>\n",
              "      <td>14.449131</td>\n",
              "      <td>0.92735654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92441b58-ecd9-49e4-b5d9-079c11841ebf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92441b58-ecd9-49e4-b5d9-079c11841ebf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92441b58-ecd9-49e4-b5d9-079c11841ebf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 711
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_df(4, \"Ours\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "411kKHLCjCch",
        "outputId": "6d904366-eb8b-4d5b-b561-2843eb6665bf"
      },
      "execution_count": 712,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "chamfer loss (L1) for bench_Ours_17: 24.275863647460938\n",
            "chamfer loss (L1) for bench_Ours_17: 22.61875343322754\n",
            "chamfer loss (L1) for bench_Ours_17: 14.254079818725586\n",
            "chamfer loss (L1) for bench_Ours_17: 19.166410446166992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Label ModelName L1 Chamfer L2 Chamfer     F Score\n",
              "0  bench_Ours_17      Ours  24.275864  18.709873   2.6170237\n",
              "1  bench_Ours_17      Ours  22.618753  15.847124  0.17573375\n",
              "2  bench_Ours_17      Ours   14.25408  10.072594    2.519173\n",
              "3  bench_Ours_17      Ours   19.16641  14.010626   1.1579027"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c485dee-fc4b-4aed-8da9-4e1f2ee00bcf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>ModelName</th>\n",
              "      <th>L1 Chamfer</th>\n",
              "      <th>L2 Chamfer</th>\n",
              "      <th>F Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bench_Ours_17</td>\n",
              "      <td>Ours</td>\n",
              "      <td>24.275864</td>\n",
              "      <td>18.709873</td>\n",
              "      <td>2.6170237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bench_Ours_17</td>\n",
              "      <td>Ours</td>\n",
              "      <td>22.618753</td>\n",
              "      <td>15.847124</td>\n",
              "      <td>0.17573375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bench_Ours_17</td>\n",
              "      <td>Ours</td>\n",
              "      <td>14.25408</td>\n",
              "      <td>10.072594</td>\n",
              "      <td>2.519173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bench_Ours_17</td>\n",
              "      <td>Ours</td>\n",
              "      <td>19.16641</td>\n",
              "      <td>14.010626</td>\n",
              "      <td>1.1579027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c485dee-fc4b-4aed-8da9-4e1f2ee00bcf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c485dee-fc4b-4aed-8da9-4e1f2ee00bcf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c485dee-fc4b-4aed-8da9-4e1f2ee00bcf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 712
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xijM0NRajFoY"
      },
      "execution_count": 639,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OL62RM2tluBB"
      },
      "execution_count": 547,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzSoNAxUqnwZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SuSL2XdvFEwJ"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}