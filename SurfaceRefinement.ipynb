{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1Af_jBwcMwG8",
        "pKhngPBlPbTs",
        "R-D0gGzDS3-7",
        "4LTFQbA5awlr",
        "NXJG7i2wbHC7",
        "scLBY-eAaBUf",
        "W_Dh9gJiTWEq",
        "gf6lBBcPTcwd",
        "hIZbLWiqaL5d",
        "cfm6rGQnb3CG",
        "C9i1JpW0OaeW"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ],
      "metadata": {
        "id": "1Af_jBwcMwG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 --quiet"
      ],
      "metadata": {
        "id": "2IlF1Xx2_Ctn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f61f605-83cd-44ee-fb90-16168fc661d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |██████████████▌                 | 834.1 MB 1.2 MB/s eta 0:14:05tcmalloc: large alloc 1147494400 bytes == 0x38eda000 @  0x7f71e9b1b615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |██████████████████▍             | 1055.7 MB 1.2 MB/s eta 0:11:06tcmalloc: large alloc 1434370048 bytes == 0x7d530000 @  0x7f71e9b1b615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |███████████████████████▎        | 1336.2 MB 97.8 MB/s eta 0:00:06tcmalloc: large alloc 1792966656 bytes == 0x2362000 @  0x7f71e9b1b615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████████████▌  | 1691.1 MB 3.0 MB/s eta 0:00:49tcmalloc: large alloc 2241208320 bytes == 0x6d14a000 @  0x7f71e9b1b615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 1837.7 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1837744128 bytes == 0xf2aac000 @  0x7f71e9b1a1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2297184256 bytes == 0x160348000 @  0x7f71e9b1b615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 1837.7 MB 9.6 kB/s \n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 457 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 48.5 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1+cu113 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x7VxtwyMthl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f19d74-a985-4c31-caa7-1fd0bd05b571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/'MyDrive'/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "!pip install Cython==0.29.20  --quiet\n",
        "!pip install usd-core --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fomq21yA4wP8",
        "outputId": "542bd5c1-8e6e-4410-eab7-390073d90463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: Cython 0.29.32\n",
            "Uninstalling Cython-0.29.32:\n",
            "  Successfully uninstalled Cython-0.29.32\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 24.7 MB 3.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "# !echo Checking if $SETUP_CHECK exists\n",
        "# !if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "!python setup.py develop\n",
        "!python -c \"import kaolin; print(kaolin.__version__)\""
      ],
      "metadata": {
        "id": "w2gnrsxeoc_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "U-ItNJXfPQPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/pvcnn')\n",
        "\n",
        "torch.manual_seed(3407)\n",
        "torch.cuda.manual_seed(3407)"
      ],
      "metadata": {
        "id": "xI6uNv5JPP0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726c85eb-c636-499c-9496-a7aa2b26cf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221122.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221122-py3-none-any.whl size=61484 sha256=8678fd5f70d0233ca0fd5dc86b875d94dd83be81d87c6d7375d0650242e273a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/6e/e3/602889ca9c5c55020f8d205066445ac5b1b96df59f75170ca0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=cf8b6d9d38529d9463cfcc770559db88b91006562906a9da70f49588502519e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: portalocker, yacs, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221122 iopath-0.1.10 portalocker-2.6.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1121/pytorch3d-0.7.1-cp38-cp38-linux_x86_64.whl (47.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.2 MB 98.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fvcore in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.5.post20221122)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.8/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.21.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.4.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ],
      "metadata": {
        "id": "pKhngPBlPbTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch3d"
      ],
      "metadata": {
        "id": "LWdkJJr1y_wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('/content/drive/MyDrive/CV_DMTet/shapenet.pvcnn.c1.pth.tar')\n",
        "state_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G126GQfpf1nB",
        "outputId": "b6e31fff-be87-4459-f5ab-0d7f5444edff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['model'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/kaolin/examples/')\n",
        "sys.path.append('/content/drive/MyDrive/kaolin/examples/tutorial')"
      ],
      "metadata": {
        "id": "yMSLuRoDPfkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "aTCgE2WCPiAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0263c86e-6bc3-43d5-c1b9-c472bd6d8e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the point cloud to be reconstructed\n",
        "pcd_path = \"/content/drive/MyDrive/kaolin/examples/samples/bear_pointcloud.usd\"\n",
        "# path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ],
      "metadata": {
        "id": "i3zs2M-kOA1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ],
      "metadata": {
        "id": "R-D0gGzDS3-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load('/content/drive/MyDrive/kaolin/examples/samples/128_verts.npz')['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load('/content/drive/MyDrive/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyIoND6-SxAD",
        "outputId": "8c51a142-d201-4467-d06e-079b38a444c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-6909fe0ff698>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  tets = torch.tensor(([np.load('/content/drive/MyDrive/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading from ShapeNet"
      ],
      "metadata": {
        "id": "4LTFQbA5awlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "SYNSETS_IDS = ['02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02843684', '02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ],
      "metadata": {
        "id": "fxK5Qw4xay7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model = shapenet_train[1500] # change the index here for different models\n",
        "sample_verts = sample_model['mesh'][0]\n",
        "sample_faces = sample_model['mesh'][1]\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[sample_verts.cpu()],\n",
        "    faces_list=[sample_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "uhzpP8kua2Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert model to watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ],
      "metadata": {
        "id": "NXJG7i2wbHC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "    vertices=sample_verts.unsqueeze(0).to(device),\n",
        "    faces=sample_faces.to(device),\n",
        "    resolution=64\n",
        ")"
      ],
      "metadata": {
        "id": "e93m-kdBHD7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "wt_verts, wt_faces = wt_verts[0], wt_faces[0]"
      ],
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wt_verts = kaolin.metrics.trianglemesh.uniform_laplacian_smoothing(wt_verts[0].unsqueeze(0), wt_faces[0])\n",
        "# sample_verts, sample_faces = wt_verts[0], wt_faces[0]"
      ],
      "metadata": {
        "id": "SeRiCeTULDEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "wt_verts = ((wt_verts - center) / max_l)* 0.9\n",
        "timelapse.add_mesh_batch(\n",
        "    category='watertight_test',\n",
        "    vertices_list=[wt_verts.cpu()],\n",
        "    faces_list=[wt_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDF model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ],
      "metadata": {
        "id": "scLBY-eAaBUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 3, # Coordinates of the grid's vertices\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "lr = 0.01\n",
        "laplacian_weight = 0.1\n",
        "iterations = 2000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ],
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/pvcnn')  \n",
        "\n",
        "# from pvcnn.modules.pvconv import PVConv"
      ],
      "metadata": {
        "id": "Zbm4KDIdJhbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "        self.multires = config['multires']\n",
        "\n",
        "        self.embed_fn = None\n",
        "        # if self.multires > 0:\n",
        "        #     embed_fn, input_ch = get_embedder(self.multires)\n",
        "        #     self.embed_fn = embed_fn\n",
        "        #     self.input_dim = input_ch\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.embed_fn is not None:\n",
        "            x = self.embed_fn(x)\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return sdf predicted + f_v feature vector\n",
        "\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 3,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim"
      ],
      "metadata": {
        "id": "cS9kStkdKQlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "print(sdf_model)\n",
        "print('\\n\\n')\n",
        "summary(sdf_model, input_size= tets_verts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLOS3kFWrd4n",
        "outputId": "dccc1f53-9267-484e-8dfb-7db4216bd91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1          [-1, 277410, 256]           1,024\n",
            "            Linear-2          [-1, 277410, 256]          65,792\n",
            "            Linear-3          [-1, 277410, 128]          32,896\n",
            "            Linear-4           [-1, 277410, 64]           8,256\n",
            "            Linear-5            [-1, 277410, 1]              65\n",
            "================================================================\n",
            "Total params: 108,033\n",
            "Trainable params: 108,033\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.17\n",
            "Forward/backward pass size (MB): 1492.11\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 1495.70\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Little Test:"
      ],
      "metadata": {
        "id": "k3RhnpiEL35m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sdfs, f_vs = sdf_model(tets_verts)\n",
        "\n",
        "print(f'Input grid shape is : {tets_verts.shape}')\n",
        "print(f'Output shape of the predicted SDFs should be {tets_verts.shape[0], 1} and it actually is {tuple(pred_sdfs.shape)}')\n",
        "print(f'Output shape of the feature vectors f_vs should be {tets_verts.shape[0], 64} and it actually is {tuple(f_vs.shape)}')\n",
        "print(pred_sdfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqcbsCj7L5eO",
        "outputId": "9e52a7b6-6b77-4f9d-b515-7d5f2b9c8ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input grid shape is : torch.Size([277410, 3])\n",
            "Output shape of the predicted SDFs should be (277410, 1) and it actually is (277410, 1)\n",
            "Output shape of the feature vectors f_vs should be (277410, 64) and it actually is (277410, 64)\n",
            "tensor([[-0.0267],\n",
            "        [-0.0269],\n",
            "        [-0.0267],\n",
            "        ...,\n",
            "        [-0.0265],\n",
            "        [-0.0266],\n",
            "        [-0.0266]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Optimizer"
      ],
      "metadata": {
        "id": "W_Dh9gJiTWEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "rENv3tMyTSdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "gf6lBBcPTcwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# takes in a module and applies the specified weight initialization\n",
        "def weights_init_normal(m):\n",
        "    '''Takes in a module and initializes all linear layers with weight\n",
        "        values taken from a normal distribution.'''\n",
        "\n",
        "    classname = m.__class__.__name__\n",
        "    # for every Linear layer in a model\n",
        "    if classname.find('Linear') != -1:\n",
        "        y = m.in_features\n",
        "    # m.weight.data shoud be taken from a normal distribution\n",
        "        m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
        "    # m.bias.data should be 0\n",
        "        m.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "cDjptlAn_Biz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_model.apply(weights_init_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qoVPBuJ_EaA",
        "outputId": "047e3e5e-b67e-48bf-8a88-1908ab22d078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hiddens): ModuleList(\n",
              "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
              "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sdf_train(iterations, model, optimizer, scheduler):\n",
        "  model.train()\n",
        "  gt_verts = wt_verts.to(device)\n",
        "  gt_faces = wt_faces.to(device)\n",
        "\n",
        "  f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "  gt_sdfs, idx, t = point_to_mesh_distance(tets_verts.unsqueeze(0), f)\n",
        "\n",
        "  sign = kaolin.ops.mesh.check_sign(gt_verts.unsqueeze(0).to(device), gt_faces.to(device), tets_verts.unsqueeze(0))\n",
        "  gt_sdfs[sign==False] *= -1\n",
        "\n",
        "  for it in range(iterations):\n",
        "      pred_sdfs, f_vs = model(tets_verts)\n",
        "      \n",
        "      loss = F.mse_loss(pred_sdfs, gt_sdfs.squeeze(0).unsqueeze(1), reduction='sum')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (it) % save_every == 0 or it == (iterations - 1): \n",
        "          print ('Iteration {} - loss: {}'.format(it, loss))\n"
      ],
      "metadata": {
        "id": "oSbqopQVh3yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~12 min. Speed up?\n",
        "sdf_train(iterations, sdf_model, sdf_optimizer, sdf_scheduler)"
      ],
      "metadata": {
        "id": "MOLR1SY1IoFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f50ddfd-c685-443d-e867-4efbcde9738b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 - loss: 5914.7744140625\n",
            "Iteration 100 - loss: 58.16108703613281\n",
            "Iteration 200 - loss: 19.72701072692871\n",
            "Iteration 300 - loss: 6.619785785675049\n",
            "Iteration 400 - loss: 4.406362533569336\n",
            "Iteration 500 - loss: 3.4375720024108887\n",
            "Iteration 600 - loss: 3.3445141315460205\n",
            "Iteration 700 - loss: 2.316502094268799\n",
            "Iteration 800 - loss: 2.0546364784240723\n",
            "Iteration 900 - loss: 1.7777180671691895\n",
            "Iteration 1000 - loss: 1.7362644672393799\n",
            "Iteration 1100 - loss: 1.5234479904174805\n",
            "Iteration 1200 - loss: 1.4100139141082764\n",
            "Iteration 1300 - loss: 1.37628972530365\n",
            "Iteration 1400 - loss: 1.2643296718597412\n",
            "Iteration 1500 - loss: 1.1917943954467773\n",
            "Iteration 1600 - loss: 1.3606736660003662\n",
            "Iteration 1700 - loss: 1.0887134075164795\n",
            "Iteration 1800 - loss: 1.0398125648498535\n",
            "Iteration 1900 - loss: 1.1708418130874634\n",
            "Iteration 1999 - loss: 0.9650946855545044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Surface refinement utils"
      ],
      "metadata": {
        "id": "hIZbLWiqaL5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if thresh = 0, return all surface tetrahedrons\n",
        "# if thresh > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "def extract_tet(tets, sdf, thresh, non_surf=False):\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  if thresh == 0:\n",
        "    mask = sdf[tets] > 0\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (sdf[tets] >= -thresh) & (sdf[tets] <= thresh)\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    if thresh == 0:\n",
        "      non_surf_tets = tets[~((t > 0) & (t < 4))]\n",
        "    else:\n",
        "      non_surf_tets = tets[t < 4]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n",
        "def get_pred_sdfs(model, tets_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pred_sdfs, f_vs = model(tets_verts)\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  d,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  d[s==True] *= -1\n",
        "\n",
        "  return d.squeeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check quality of sdf prediction\n",
        "Test `extract_tet` here. Most ideal if about 20k~30k surface vertices are extracted."
      ],
      "metadata": {
        "id": "cfm6rGQnb3CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = get_gt_sdfs(wt_verts.unsqueeze(0).to(device), wt_faces.to(device), tets_verts.unsqueeze(0))\n",
        "pred_sdfs, _ = get_pred_sdfs(sdf_model, tets_verts)"
      ],
      "metadata": {
        "id": "ICl3ftwOb_YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Surface refinement model"
      ],
      "metadata": {
        "id": "NrEgkw5TksFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        deform = torch.tanh(deform)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature\n"
      ],
      "metadata": {
        "id": "z9uLf6MBUn49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
        "    term = torch.zeros_like(mesh_verts)\n",
        "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
        "\n",
        "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
        "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
        "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    m = pytorch3d.structures.Meshes([mesh_verts, gt_verts], [mesh_faces, gt_faces])\n",
        "  \n",
        "    # pc = pytorch3d.ops.sample_points_from_meshes(m, num_samples=50000)\n",
        "    if mesh_verts.shape[0] > 0:\n",
        "      pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 50000)[0][0]\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 50000)[0][0]\n",
        "      # pred_points,gt_points = pc[0], pc[1]\n",
        "      chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), squared=False).mean()\n",
        "    else:\n",
        "      chamfer = 0\n",
        "\n",
        "\n",
        "    #chamfer, p_norms = pytorch3d.loss.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), point_reduction='sum')\n",
        "    # norm = torch.sum(1-torch.abs(p_norms))\n",
        "    # norm = pytorch3d.loss.mesh_normal_consistency(m)\n",
        "    if it > iterations//2:\n",
        "      lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
        "      return 500*chamfer + lap * laplacian_weight #+ 1e-6*norm\n",
        "    return 500*chamfer #+ 1e-6*norm "
      ],
      "metadata": {
        "id": "U5GGfOyM3NRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train GCN Model for Surface Refinement\n",
        "The model is structured following Curve-GCN that has two Graph Res Block with three MLPs, outputs sdf residual, deform residual, updated feature vector, respectively. \n",
        "\n",
        "Before start training, need to run the model with `gcn_pretrain` to ensure that model does not run on random surface. \n",
        "\n",
        "Pretrain on sphere is not tested and not guaranteed to be working\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zzjoso_kziVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}\n",
        "\n",
        "# Same set of Hyperparam is applied\n",
        "lr = 1e-3\n",
        "laplacian_weight = 0.1\n",
        "gcn_iterations = 5000\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128"
      ],
      "metadata": {
        "id": "6QO7CuxCzohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def gcn_pretrain(iterations, gcn_model, optimizer, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdf, thresh)\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = pred_sdf[surf_tets_verts_idx]\n",
        "  surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "  \n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "\n",
        "  timelapse.add_mesh_batch(\n",
        "          category='tet_surface',\n",
        "          vertices_list=[surf_tets_verts.cpu()],\n",
        "          faces_list=[surf_tets_faces.cpu()]\n",
        "      )\n",
        "\n",
        "  for it in tqdm(range(iterations)):\n",
        "    verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(verts_f, surf_tets_edges)\n",
        "\n",
        "    update_verts = surf_tets_verts + deform / grid_res\n",
        "    update_sdfs = surf_sdfs + sdf\n",
        "\n",
        "    gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "    sdf_loss = F.mse_loss(sdf, gt_sdfs - surf_sdfs, reduction='sum')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    sdf_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "\n",
        "    if it == iterations-1:\n",
        "      print('Iteration {} - loss: {}'.format(iterations, sdf_loss))\n"
      ],
      "metadata": {
        "id": "QJ4L--ys4rh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Identify surface Tetrahedral\n",
        "input: f = [v, s, F_vol, f_64]\n",
        "output: f = [delta v, delta s, f_64]\n",
        "\n",
        "update v = v + delta v, s = s + delta s\n",
        "generate new meshes by marching tet from v and s; calculate loss\n",
        "\n",
        "loss = chamfer + sdf_loss + deform_loss\n",
        "\"\"\"\n",
        "\n",
        "def gcn_train(iterations, gcn_model, optimizer, scheduler, pred_sdf, tets_verts, tets, tets_verts_features, gt_verts, gt_faces, thresh):\n",
        "  gcn_model.train()\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Firstly, based on predicted sdf value, extract out all surface tetrahedrons\n",
        "  i.e. 1-3 vertices of tetrahedrons are with different sdf signs\n",
        "  return value: \n",
        "  --> surf_tets_idx: origin index of vertices as in tet grid\n",
        "  --> surf_tets_faces: reindexed faces list start from 0\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdf, thresh)\n",
        "  surf_tets_edges = get_edges(surf_tets_faces).to(device)\n",
        "\n",
        "  surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "  # obtain per vertex features: \n",
        "  # sdf, position, feature vector\n",
        "\n",
        "  surf_tets_verts_features = torch.clone(tets_verts_features[surf_tets_verts_idx])\n",
        "  surf_sdfs = torch.clone(pred_sdf[surf_tets_verts_idx])\n",
        "  surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "  # calculate ground truth sdf value over all vertices in tet mesh\n",
        "\n",
        "  # gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces).to(device)\n",
        "  # gt_sdfs, _, _ = point_to_mesh_distance(tets_verts.unsqueeze(0), gt_f)\n",
        "  # gt_sdfs = gt_sdfs.squeeze(0).unsqueeze(1)\n",
        "\n",
        "  gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "  gt_f = index_vertices_by_faces(gt_verts.unsqueeze(0), gt_faces)\n",
        "  \n",
        "  gt_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, tets_verts.unsqueeze(0), gt_f)\n",
        "\n",
        "  for it in range(iterations):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Secondly, predict with a 2-layer GCN followed by 2-layer MLP\n",
        "    output:\n",
        "    --> [delta v, delta s, new f_s] \\in R^68\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = torch.clone(pred_sdf)\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "    \n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    vd = deform\n",
        "    update_tets_verts = torch.clone(tets_verts)\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    vfvs = fv.detach()\n",
        "    update_tets_f = torch.clone(tets_verts_features)\n",
        "    update_tets_f[surf_tets_verts_idx] += vfvs\n",
        "\n",
        "    #test\n",
        "    MT_sdf = surf_sdfs + sdf\n",
        "    MT_verts = surf_tets_verts + deform\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    # Calculate SDF non_surface tetrahedron in newly generated mesh\n",
        "\n",
        "    # ns_mask = torch.ones(tets_verts.shape[0])\n",
        "    # ns_mask[surf_tets_verts_idx] = 0\n",
        "    # non_surf_verts = torch.clone(tets_verts[ns_mask == 1])\n",
        "\n",
        "    # p_sdfs = get_gt_sdfs(mesh_verts.unsqueeze(0), mesh_faces, non_surf_verts.unsqueeze(0))\n",
        "\n",
        "    # # Get ground truth SDF value of non_surface tetrahedron vertices and truncate at +- 0.3 to focus on surface\n",
        "\n",
        "    # ns_g = gt_sdfs[ns_mask == 1]\n",
        "    # mask = (ns_g >= -0.1) & (ns_g <= 0.1)\n",
        "    # p = p_sdfs[mask]\n",
        "    # g = ns_g[mask]\n",
        "\n",
        "    # Also calculate surface sdf loss\n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts[surf_tets_verts_idx].unsqueeze(0), gt_f)\n",
        "\n",
        "    # sdf_loss = F.mse_loss(update_sdfs, s_sdfs, reduction='sum') #+ F.mse_loss(p.to(device), g.to(device), reduction='mean')\n",
        "\n",
        "    sdf_loss = F.mse_loss(sdf, s_sdfs-surf_sdfs, reduction='mean') #+ F.mse_loss(p.to(device), g.to(device), reduction='mean')\n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    # deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='sum')\n",
        "    deform_loss = F.mse_loss(deform, torch.zeros(deform.shape).to(device), reduction='mean')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it)\n",
        "\n",
        "    g_loss = r_loss + deform_loss + 0.4*sdf_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    # r_loss.backward(retain_graph=True)\n",
        "    # deform_loss.backward(retain_graph=True)\n",
        "    # sdf_loss.backward(retain_graph=True)\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if (it) % save_every == 0 or it == (iterations - 1): \n",
        "      print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "      \n",
        "      # save reconstructed mesh\n",
        "      timelapse.add_mesh_batch(\n",
        "          iteration=it+1,\n",
        "          category='train_res',\n",
        "          vertices_list=[mesh_verts.cpu()],\n",
        "          faces_list=[mesh_faces.cpu()]\n",
        "      )"
      ],
      "metadata": {
        "id": "5pn7Q89vgch9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)\n",
        "\n",
        "pre_vars = [p for _, p in refine_model.named_parameters()]\n",
        "pre_optimizer = torch.optim.Adam(pre_vars, lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm5aud4mz6ZJ",
        "outputId": "4ee8d6d7-b770-47c9-8e24-fa50124bd0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN_Res(\n",
            "  (gcn_res): ModuleList(\n",
            "    (0): GBottleneck(\n",
            "      (blocks): Sequential(\n",
            "        (0): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "        (1): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "      )\n",
            "      (conv1): GraphConv(68 -> 128, directed=False)\n",
            "    )\n",
            "  )\n",
            "  (sdf_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
            "  )\n",
            "  (deform_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=3, bias=False)\n",
            "  )\n",
            "  (feature_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=64, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_pretrain(500, refine_model, pre_optimizer, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0.001)"
      ],
      "metadata": {
        "id": "4Hlf1luSRwZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_vars = [p for _, p in refine_model.named_parameters()]\n",
        "refine_optimizer = torch.optim.Adam(pre_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(pre_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "i7ylyiYXI08J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gcn_train(gcn_iterations, refine_model, refine_optimizer, refine_scheduler, d, tets_verts, tets, f_vs, sample_verts, sample_faces, 0.001)"
      ],
      "metadata": {
        "id": "HqEaSvssI8it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "1H7RCV62USts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2IGctyaa9n7vRBd8qq7pzd0bNKh_2pDFmKRk5Af1QDq295xZ4\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "id": "p68GrPqkUU07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78bf2c6-a24b-444e-bfa6-5559e6731b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 296 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 317 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 327 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 337 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 348 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 368 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 389 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 399 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 409 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 419 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 440 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 460 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 471 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 481 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 491 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 501 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 512 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 522 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 532 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 542 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 552 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 563 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 573 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 583 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 593 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 604 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 614 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 624 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 634 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 645 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 655 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 665 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 675 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 686 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 696 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 706 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 716 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 727 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 737 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 747 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 757 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 761 kB 4.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ],
      "metadata": {
        "id": "rWJ2SS1EUYjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62af585-63bd-43c8-ce68-f9aa02454a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking URL: NgrokTunnel: \"http://24af-35-201-250-22.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ],
      "metadata": {
        "id": "9RZLd8x7UrUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a978ecc0-e2f8-402c-be7d-12aa057d4300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash3D server starting. Go to: http://localhost:80\n",
            "2022-12-11 22:10:10,329|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:10,335|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:28,353|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:28,359|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:31,251|    INFO| tornado.access| 200 GET / (127.0.0.1) 2911.40ms\n",
            "2022-12-11 22:10:32,088|    INFO| tornado.access| 200 GET /static/thirdparty.css (127.0.0.1) 615.87ms\n",
            "2022-12-11 22:10:32,812|    INFO| tornado.access| 200 GET /static/thirdparty.js (127.0.0.1) 722.89ms\n",
            "2022-12-11 22:10:33,457|    INFO| tornado.access| 200 GET /static/core-min.js (127.0.0.1) 1367.71ms\n",
            "2022-12-11 22:10:34,826|    INFO| tornado.access| 200 GET /static/green_plastic.frag (127.0.0.1) 652.88ms\n",
            "2022-12-11 22:10:34,827|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 0.51ms\n",
            "2022-12-11 22:10:34,840|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:34,845|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:35,450|    INFO| tornado.access| 200 GET /static/favicon.ico (127.0.0.1) 603.57ms\n",
            "2022-12-11 22:10:37,941|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 3.74ms\n",
            "2022-12-11 22:10:38,870|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.38ms\n",
            "2022-12-11 22:10:49,522|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:49,527|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:49,528|    INFO| tornado.access| 200 GET / (127.0.0.1) 18.50ms\n",
            "2022-12-11 22:10:49,741|    INFO|kaolin.experimental.dash3d.util| Socket closed.\n",
            "2022-12-11 22:10:50,396|    INFO| tornado.access| 200 GET /static/style.css (127.0.0.1) 647.10ms\n",
            "2022-12-11 22:10:50,399|    INFO| tornado.access| 304 GET /static/thirdparty.css (127.0.0.1) 2.73ms\n",
            "2022-12-11 22:10:50,401|    INFO| tornado.access| 304 GET /static/core-min.js (127.0.0.1) 4.70ms\n",
            "2022-12-11 22:10:50,404|    INFO| tornado.access| 304 GET /static/thirdparty.js (127.0.0.1) 6.64ms\n",
            "2022-12-11 22:10:50,636|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.81ms\n",
            "2022-12-11 22:10:50,770|    INFO| tornado.access| 304 GET /static/favicon.ico (127.0.0.1) 2.47ms\n",
            "2022-12-11 22:10:50,770|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 2.71ms\n",
            "2022-12-11 22:10:50,783|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:50,789|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-11 22:10:50,856|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.38ms\n",
            "2022-12-11 22:10:51,065|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.53ms\n",
            "2022-12-11 22:11:15,938|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:15,943|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:18,177|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:18,182|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:23,350|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:23,355|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:27,754|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:27,759|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:30,863|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:30,867|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:33,577|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:33,582|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:33,594|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:33,599|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:43,455|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:11:43,460|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:01,759|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:01,763|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:23,079|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:23,084|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:28,890|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:28,895|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:29,614|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:12:29,619|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:03,959|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:03,964|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:14,958|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:14,963|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:21,199|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:21,203|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:22,087|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:13:22,091|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-11 22:18:23,222|    INFO|kaolin.experimental.dash3d.util| Socket closed.\n"
          ]
        }
      ]
    }
  ]
}