{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CjeE5azrOEmS",
        "8W1zYXghPPVh",
        "LxiYFjl6PT2C",
        "R-D0gGzDS3-7",
        "scLBY-eAaBUf",
        "hIZbLWiqaL5d",
        "dJxc2UTSacjd",
        "p34jmk1eTUFf",
        "qKcm_vY-TV8S"
      ],
      "mount_file_id": "1bN5hOnyvNz2e64oTMi4mSFu15Ej25o5B",
      "authorship_tag": "ABX9TyMSYVcbEALsxOffOenk0uds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aydin-ab/CV_DMTet/blob/main/CV_DMTet_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies: Kaolin and PyTorch3D"
      ],
      "metadata": {
        "id": "70enHQEVM3HX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bx6A6pHmM017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981c6d28-79d2-43ae-80cc-11cb0bb9a56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |██████████████▌                 | 834.1 MB 1.2 MB/s eta 0:13:31tcmalloc: large alloc 1147494400 bytes == 0x38e02000 @  0x7f1128339615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |██████████████████▍             | 1055.7 MB 1.2 MB/s eta 0:10:51tcmalloc: large alloc 1434370048 bytes == 0x7d458000 @  0x7f1128339615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |███████████████████████▎        | 1336.2 MB 1.2 MB/s eta 0:06:49tcmalloc: large alloc 1792966656 bytes == 0x228a000 @  0x7f1128339615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |█████████████████████████████▌  | 1691.1 MB 1.1 MB/s eta 0:02:08tcmalloc: large alloc 2241208320 bytes == 0x6d072000 @  0x7f1128339615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 1837.7 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1837744128 bytes == 0xf29d4000 @  0x7f11283381e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n",
            "tcmalloc: large alloc 2297184256 bytes == 0x160270000 @  0x7f1128339615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n",
            "\u001b[K     |████████████████████████████████| 1837.7 MB 9.5 kB/s \n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 18.0 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1+cu113 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from pathlib import Path\n",
        "INSTALL_PATH = Path(\"/content/drive/'MyDrive'/CV_DMTet/\")\n",
        "%cd  $INSTALL_PATH"
      ],
      "metadata": {
        "id": "kv10BnuQNUjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4e554f-1e68-49cc-df87-9f9cf5543d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CV_DMTet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reinstall cython, install usd-core (for 3D rendering), and clone into kaolin repo\n",
        "!pip uninstall Cython --yes\n",
        "!pip install Cython==0.29.20  --quiet\n",
        "!pip install usd-core --quiet"
      ],
      "metadata": {
        "id": "02dA9jboNWj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaolin and check version\n",
        "%env IGNORE_TORCH_VER=1\n",
        "%env KAOLIN_INSTALL_EXPERIMENTAL=1\n",
        "KAOLIN_PATH = INSTALL_PATH / \"kaolin\"\n",
        "%cd $INSTALL_PATH\n",
        "!if [ ! -d $KAOLIN_PATH ]; then git clone --recursive https://github.com/NVIDIAGameWorks/kaolin; fi;\n",
        "%cd $KAOLIN_PATH\n",
        "SETUP_CHECK = KAOLIN_PATH / \"kaolin\" / \"version.py\"\n",
        "# !echo Checking if $SETUP_CHECK exists\n",
        "# !if [ ! -f $SETUP_CHECK ]; then python setup.py develop; fi;\n",
        "!python setup.py develop\n",
        "!python -c \"import kaolin; print(kaolin.__version__)\""
      ],
      "metadata": {
        "id": "wbKOjtJyNYGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "vC8xIFcMNaXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import kaolin\n",
        "import sys\n",
        "import os\n",
        "\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\n",
        "    import pytorch3d\n",
        "\n",
        "from kaolin.ops.conversions import (\n",
        "    trianglemeshes_to_voxelgrids,\n",
        "    marching_tetrahedra,\n",
        "    voxelgrids_to_cubic_meshes,\n",
        "    voxelgrids_to_trianglemeshes,\n",
        ")\n",
        "\n",
        "from kaolin.ops.mesh import (\n",
        "    index_vertices_by_faces\n",
        ")\n",
        "\n",
        "from kaolin.io.shapenet import (\n",
        "    ShapeNetV2\n",
        ")\n",
        "\n",
        "from kaolin.metrics.trianglemesh import (\n",
        "    point_to_mesh_distance,\n",
        "\n",
        ")\n",
        "\n",
        "from pytorch3d.datasets import (\n",
        "    ShapeNetCore,\n",
        "    collate_batched_meshes\n",
        ")\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# add path for demo utils functions \n",
        "sys.path.append(os.path.abspath(''))\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/')\n",
        "sys.path.append('/content/drive/MyDrive/CV_DMTet/pvcnn')\n",
        "\n",
        "torch.manual_seed(3407)\n",
        "torch.cuda.manual_seed(3407)"
      ],
      "metadata": {
        "id": "2uriKv2LNd9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset: Subset of ShapeNetV2"
      ],
      "metadata": {
        "id": "CjeE5azrOEmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "bDyBXwZ7OHwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb674b87-5c6e-4ea5-c6b0-52dc8d4a2a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to the output logs (readable with the training visualizer in the omniverse app)\n",
        "logs_path = '/content/drive/MyDrive/CV_DMTet/Logs'\n",
        "\n",
        "# We initialize the timelapse that will store USD for the visualization apps\n",
        "timelapse = kaolin.visualize.Timelapse(logs_path)"
      ],
      "metadata": {
        "id": "-JNY_k5EOg7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import by pytorch3d\n",
        "\n",
        "SHAPENET_PATH = \"/content/drive/MyDrive/CV_DMTet/Core\"\n",
        "#SHAPENET_PATH = \"/content/drive/MyDrive/FALL 2022/Computer Vision/Project/Core\"\n",
        "SYNSETS_IDS = ['02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02843684', '02871439', '02876657', '02880940', '02924116', '02933112']\n",
        "# shapenet_dataset = ShapeNetCore(SHAPENET_PATH, synsets=SYNSETS_IDS, version=2)\n",
        "# shapenet_loader = DataLoader(shapenet_dataset, batch_size=3, collate_fn=collate_batched_meshes)"
      ],
      "metadata": {
        "id": "FAflurFdOjih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import by kaolin\n",
        "\n",
        "shapenet_train = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True)\n",
        "shapenet_test = ShapeNetV2(SHAPENET_PATH, categories=SYNSETS_IDS, output_dict=True, train=False)"
      ],
      "metadata": {
        "id": "OwZ8rPkKOnS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model visualization"
      ],
      "metadata": {
        "id": "8W1zYXghPPVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_model = shapenet_train[560] # change the index here for different models\n",
        "sample_verts = sample_model['mesh'][0]\n",
        "sample_faces = sample_model['mesh'][1]\n",
        "\n",
        "center = (sample_verts.max(0)[0] + sample_verts.min(0)[0]) / 2\n",
        "max_l = (sample_verts.max(0)[0] - sample_verts.min(0)[0]).max()\n",
        "sample_verts = ((sample_verts - center) / max_l)\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "    category='gt',\n",
        "    vertices_list=[sample_verts.cpu()],\n",
        "    faces_list=[sample_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "lLuZr7eIPN9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert model to watertight meshes\n",
        "\n",
        "We used a voxelization with resolution of 64 to predict the sdf and extract surface. "
      ],
      "metadata": {
        "id": "LxiYFjl6PT2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "    vertices=sample_verts.unsqueeze(0).to(device),\n",
        "    faces=sample_faces.to(device),\n",
        "    resolution=64\n",
        ")"
      ],
      "metadata": {
        "id": "OtlWB0DbPXws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "wt_verts, wt_faces = wt_verts[0], wt_faces[0]"
      ],
      "metadata": {
        "id": "8qo7DnerK7k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "timelapse.add_mesh_batch(\n",
        "    category='watertight_test',\n",
        "    vertices_list=[wt_verts.cpu()],\n",
        "    faces_list=[wt_faces.cpu()]\n",
        ")"
      ],
      "metadata": {
        "id": "yO0vb_YKL5ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Tetrahedral grid\n",
        "\n",
        "DMTet starts from a uniform tetrahedral grid of predefined resolution, and uses a network to predict the SDF value as well as deviation vector at each grid vertex.\n",
        "\n",
        "Here we load the pre-generated tetrahedral grid using Quartet at resolution 128, which has roughly the same number of vertices as a voxel grid of resolution 65. We use a simple MLP + positional encoding to predict the SDF and deviation vectors in DMTet, and initialize the encoded SDF to represent a sphere."
      ],
      "metadata": {
        "id": "R-D0gGzDS3-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uniform Tetrahedral Grid\n",
        "tets_verts = torch.tensor(np.load('/content/drive/MyDrive/CV_DMTet/kaolin/examples/samples/128_verts.npz')['data'], dtype=torch.float, device=device)\n",
        "tets = torch.tensor(([np.load('/content/drive/MyDrive/CV_DMTet/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
        "print(tets_verts, tets)"
      ],
      "metadata": {
        "id": "LyIoND6-SxAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3ca911-afc6-4a64-d5e1-bdaff5a98f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5000,  0.5000,  0.4844],\n",
            "        [ 0.4844,  0.5000,  0.4922],\n",
            "        [ 0.4922,  0.4844,  0.4844],\n",
            "        ...,\n",
            "        [-0.1719, -0.5000,  0.4766],\n",
            "        [-0.1562, -0.5000,  0.4688],\n",
            "        [-0.1562, -0.4922,  0.4688]], device='cuda:0') tensor([[     0,      1,      2,      3],\n",
            "        [     2,      3,      1,      4],\n",
            "        [     5,      3,      0,      2],\n",
            "        ...,\n",
            "        [277409, 272920, 272914, 272919],\n",
            "        [272919, 277409, 272920, 274866],\n",
            "        [277409, 277400, 272920, 274866]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ca8a73dbab11>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  tets = torch.tensor(([np.load('/content/drive/MyDrive/CV_DMTet/kaolin/examples/samples/128_tets_{}.npz'.format(i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SDF Model & GCN Model\n",
        "\n",
        "We follow the paper recommandation and use a four-layer\n",
        "MLPs with hidden dimensions 256, 256, 128 and 64, respectively"
      ],
      "metadata": {
        "id": "scLBY-eAaBUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.input_dim = config['input_dim']\n",
        "        self.hidden_dims  = config['hidden_dims']\n",
        "        self.output_dim = config['output_dim']\n",
        "        self.multires = config['multires']\n",
        "\n",
        "        self.embed_fn = None\n",
        "        # if self.multires > 0:\n",
        "        #     embed_fn, input_ch = get_embedder(self.multires)\n",
        "        #     self.embed_fn = embed_fn\n",
        "        #     self.input_dim = input_ch\n",
        "\n",
        "        # Hidden layers\n",
        "        self.hiddens = nn.ModuleList()\n",
        "        in_dim = self.input_dim\n",
        "        for k in range(len(self.hidden_dims)):\n",
        "            self.hiddens.append(nn.Linear(in_dim, self.hidden_dims[k]))\n",
        "            in_dim = self.hidden_dims[k]\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = torch.nn.Linear(self.hidden_dims[-1], self.output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.embed_fn is not None:\n",
        "            x = self.embed_fn(x)\n",
        "        for hidden in self.hiddens :\n",
        "            x = F.relu(hidden(x))\n",
        "        output = self.output_layer(x) # No activation (linear) cuz we do regression\n",
        "\n",
        "        return output, x # Return sdf predicted + f_v feature vector\n",
        "\n",
        "\n",
        "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
        "class Embedder:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.kwargs = kwargs\n",
        "        self.create_embedding_fn()\n",
        "        \n",
        "    def create_embedding_fn(self):\n",
        "        embed_fns = []\n",
        "        d = self.kwargs['input_dims']\n",
        "        out_dim = 0\n",
        "        if self.kwargs['include_input']:\n",
        "            embed_fns.append(lambda x : x)\n",
        "            out_dim += d\n",
        "            \n",
        "        max_freq = self.kwargs['max_freq_log2']\n",
        "        N_freqs = self.kwargs['num_freqs']\n",
        "        \n",
        "        if self.kwargs['log_sampling']:\n",
        "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
        "        else:\n",
        "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
        "            \n",
        "        for freq in freq_bands:\n",
        "            for p_fn in self.kwargs['periodic_fns']:\n",
        "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
        "                out_dim += d\n",
        "                    \n",
        "        self.embed_fns = embed_fns\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "    def embed(self, inputs):\n",
        "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
        "\n",
        "def get_embedder(multires):\n",
        "    embed_kwargs = {\n",
        "                'include_input' : True,\n",
        "                'input_dims' : 3,\n",
        "                'max_freq_log2' : multires-1,\n",
        "                'num_freqs' : multires,\n",
        "                'log_sampling' : True,\n",
        "                'periodic_fns' : [torch.sin, torch.cos],\n",
        "    }\n",
        "    \n",
        "    embedder_obj = Embedder(**embed_kwargs)\n",
        "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
        "    return embed, embedder_obj.out_dim"
      ],
      "metadata": {
        "id": "Sukbj2BeajMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Graph-res net:\n",
        "Identify surface tetrahedral, build adj matrix, \n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "# a single res block layer with dimension 256 & 128\n",
        "class GResBlock(nn.Module): \n",
        "    def __init__(self, in_dim, hidden_dim, activation=None):\n",
        "        super(GResBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GraphConv(hidden_dim, in_dim)\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        input, adj = inputs[0], inputs[1]\n",
        "        x = self.conv1(input, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.conv2(x, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(input + x)\n",
        "        \n",
        "        return [x, adj]\n",
        "\n",
        "class GBottleneck(nn.Module):\n",
        "    def __init__(self, block_num, in_dim, hidden_dim, out_dim, activation=None):\n",
        "        super(GBottleneck, self).__init__()\n",
        "\n",
        "        resblock_layers = [GResBlock(in_dim=hidden_dim[0], hidden_dim=hidden_dim[1], activation=activation)\n",
        "                          for _ in range(block_num)]\n",
        "        self.blocks = nn.Sequential(*resblock_layers)\n",
        "        self.conv1 = GraphConv(in_dim, hidden_dim[0])\n",
        "\n",
        "        self.activation = F.relu if activation else None\n",
        "    \n",
        "    def forward(self, inputs, adj):\n",
        "        x = self.conv1(inputs, adj)\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "        x = self.blocks([x, adj])[0]\n",
        "        if self.activation:\n",
        "          x = self.activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GCN_Res(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(GCN_Res, self).__init__()\n",
        "\n",
        "        self.in_dim = config['in_dim']\n",
        "        self.hidden_dim = config['hidden_dim']\n",
        "        self.out_dim = config['out_dim']\n",
        "        self.activation = config['activation']\n",
        "        self.mlp_hdim = config['mlp_hdim']\n",
        "        self.mlp_odim = config['mlp_odim']\n",
        "\n",
        "        self.gcn_res = nn.ModuleList([GBottleneck(2, self.in_dim, self.hidden_dim, self.out_dim, self.activation)])\n",
        "\n",
        "        self.sdf_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 1, bias=False),\n",
        "        )\n",
        "\n",
        "        self.deform_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], 3, bias=False),\n",
        "        )\n",
        "\n",
        "        self.feature_mlp = nn.Sequential(\n",
        "            nn.Linear(self.out_dim, self.mlp_hdim[0], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[0], self.mlp_hdim[1], bias=False),\n",
        "            nn.Linear(self.mlp_hdim[1], self.mlp_hdim[1], bias=False),\n",
        "        )\n",
        "        \n",
        "\n",
        "\n",
        "    def forward(self, inputs, adj):\n",
        "\n",
        "        x = self.gcn_res[0](inputs, adj)\n",
        "\n",
        "        sdf = self.sdf_mlp(x)\n",
        "        deform = self.deform_mlp(x)\n",
        "        deform = torch.tanh(deform)\n",
        "        feature = self.feature_mlp(x)\n",
        "        \n",
        "        return sdf, deform, feature"
      ],
      "metadata": {
        "id": "J3MYPa9jacRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Surface refinement utils"
      ],
      "metadata": {
        "id": "hIZbLWiqaL5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get edges lists of shape [E, 2] from face list of shape [V, 4]\n",
        "\n",
        "def get_edges(input):\n",
        "  c = torch.combinations(torch.arange(input.size(1)), r=2)\n",
        "  x = input[:,None].expand(-1,len(c),-1).cpu()\n",
        "  idx = c[None].expand(len(x), -1, -1)\n",
        "  x = x.gather(dim=2, index=idx)\n",
        "\n",
        "  return x.view(-1, *x.shape[2:])\n",
        "\n",
        "# Extract tets under certain sdf restrictions:\n",
        "# if thresh = 0, return all surface tetrahedrons\n",
        "# if thresh > 0, return all tetrahedrons whose vertices' sdfs are all in the range [-thresh, thresh]\n",
        "\n",
        "def extract_tet(tets, sdf, thresh, non_surf=False):\n",
        "\n",
        "  assert thresh >= 0\n",
        "\n",
        "  if thresh == 0:\n",
        "    mask = sdf[tets] > 0\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[(t > 0) & (t < 4)]\n",
        "  else:\n",
        "    mask = (sdf[tets] >= -thresh) & (sdf[tets] <= thresh)\n",
        "    mask_int = mask.squeeze(2).long()\n",
        "    t = mask_int.sum(1)\n",
        "    surf_tets = tets[t == 4]\n",
        "\n",
        "  surf_tets_tuple = surf_tets.unique(return_inverse=True)\n",
        "  surf_tets_idx, surf_tets = surf_tets_tuple[0], surf_tets_tuple[1]\n",
        "\n",
        "  if non_surf:\n",
        "    if thresh == 0:\n",
        "      non_surf_tets = tets[~((t > 0) & (t < 4))]\n",
        "    else:\n",
        "      non_surf_tets = tets[t < 4]\n",
        "    non_surf_tets_tuple = non_surf_tets.unique(return_inverse=True)\n",
        "    non_surf_tets_idx, non_surf_tets = non_surf_tets_tuple[0], non_surf_tets_tuple[1]\n",
        "    return surf_tets_idx, surf_tets, non_surf_tets_idx, non_surf_tets\n",
        "\n",
        "  return surf_tets_idx, surf_tets\n",
        "\n",
        "#Get output from initial MLP\n",
        "\n",
        "def get_pred_sdfs(model, tets_verts, gt_verts):\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    F_vol = F.interpolate(gt_verts[None, None, None,:, :], size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "    pred_sdfs, f_vs = model(F_vol)\n",
        "\n",
        "  return pred_sdfs, f_vs\n",
        "\n",
        "# Get ground truth sdf from input verts and faces\n",
        "# input shape: [batch_size, num_vertices, 3], [num_faces, 4], [batch_size, num_points, 3]\n",
        "# output shape: [num_points, 1]\n",
        "\n",
        "def get_gt_sdfs(gt_verts, gt_faces, points, f=None):\n",
        "\n",
        "  if f == None:\n",
        "    f = index_vertices_by_faces(gt_verts, gt_faces)\n",
        "  d,_,_ = point_to_mesh_distance(points, f)\n",
        "\n",
        "  s = kaolin.ops.mesh.check_sign(gt_verts, gt_faces, points)\n",
        "  d[s==True] *= -1\n",
        "\n",
        "  return d.squeeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "bMTthXJVeon8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instanciate Models"
      ],
      "metadata": {
        "id": "dJxc2UTSacjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we skip PVCNN, input dimension is just the coordinates of each grid\n",
        "\n",
        "SDF_MLP_CONFIG = {\n",
        "    'input_dim' : 6, # Coordinates of the grid's vertices #previously 3\n",
        "    'hidden_dims' : [256, 256, 128, 64],\n",
        "    'output_dim' : 1, # SDF of the vertex input. The other \"output\" f_v comes from the prior activation layer of dimension 64\n",
        "    'multires': 2\n",
        "}\n",
        "\n",
        "lr = 1e-4\n",
        "laplacian_weight = 0.1\n",
        "save_every = 100\n",
        "multires = 2\n",
        "grid_res = 128\n",
        "epoch = 1000"
      ],
      "metadata": {
        "id": "ZnLJv65eKNGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "sdf_model = MLP(SDF_MLP_CONFIG).to(device)\n",
        "print(sdf_model)\n",
        "print('\\n\\n')\n",
        "summary(sdf_model, input_size= (tets_verts.shape[0], 6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igdsZnpiTD9P",
        "outputId": "c27917a8-b1b7-4809-b310-cb402c9292a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (hiddens): ModuleList(\n",
            "    (0): Linear(in_features=6, out_features=256, bias=True)\n",
            "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1          [-1, 277410, 256]           1,792\n",
            "            Linear-2          [-1, 277410, 256]          65,792\n",
            "            Linear-3          [-1, 277410, 128]          32,896\n",
            "            Linear-4           [-1, 277410, 64]           8,256\n",
            "            Linear-5            [-1, 277410, 1]              65\n",
            "================================================================\n",
            "Total params: 108,801\n",
            "Trainable params: 108,801\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 6.35\n",
            "Forward/backward pass size (MB): 1492.11\n",
            "Params size (MB): 0.42\n",
            "Estimated Total Size (MB): 1498.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_GCNRES = {\n",
        "    'in_dim': 68,\n",
        "    'hidden_dim': [128, 256],\n",
        "    'out_dim': 128,\n",
        "    'activation': True,\n",
        "    'mlp_hdim': [128,64],\n",
        "    'mlp_odim': 68,\n",
        "}"
      ],
      "metadata": {
        "id": "9ZYDVvaVTDUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_model = GCN_Res(CONFIG_GCNRES).to(device)\n",
        "\n",
        "print(refine_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adK5p9SETGWh",
        "outputId": "28d8506b-6b99-4266-9321-1b051193d3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN_Res(\n",
            "  (gcn_res): ModuleList(\n",
            "    (0): GBottleneck(\n",
            "      (blocks): Sequential(\n",
            "        (0): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "        (1): GResBlock(\n",
            "          (conv1): GraphConv(128 -> 256, directed=False)\n",
            "          (conv2): GraphConv(256 -> 128, directed=False)\n",
            "        )\n",
            "      )\n",
            "      (conv1): GraphConv(68 -> 128, directed=False)\n",
            "    )\n",
            "  )\n",
            "  (sdf_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
            "  )\n",
            "  (deform_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=3, bias=False)\n",
            "  )\n",
            "  (feature_mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=128, bias=False)\n",
            "    (1): Linear(in_features=128, out_features=64, bias=False)\n",
            "    (2): Linear(in_features=64, out_features=64, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Up Optimizer"
      ],
      "metadata": {
        "id": "p34jmk1eTUFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_vars = [p for _, p in sdf_model.named_parameters()]\n",
        "sdf_optimizer = torch.optim.Adam(sdf_vars, lr=lr)\n",
        "sdf_scheduler = torch.optim.lr_scheduler.LambdaLR(sdf_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
        "\n",
        "params = list(sdf_model.named_parameters()) + list(refine_model.named_parameters())\n",
        "\n",
        "refine_vars = [p for _, p in params]\n",
        "refine_optimizer = torch.optim.Adam(refine_vars, lr=lr)\n",
        "refine_scheduler = torch.optim.lr_scheduler.LambdaLR(refine_optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
      ],
      "metadata": {
        "id": "WxQnq3ZRTKTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "qKcm_vY-TV8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch3d.loss import(\n",
        "    chamfer_distance\n",
        ")\n",
        "\n",
        "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
        "    term = torch.zeros_like(mesh_verts)\n",
        "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
        "\n",
        "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
        "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
        "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
        "\n",
        "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
        "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
        "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
        "\n",
        "    two = torch.ones_like(v0) * 2.0\n",
        "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
        "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
        "\n",
        "    term = term / torch.clamp(norm, min=1.0)\n",
        "\n",
        "    return torch.mean(term**2)\n",
        "\n",
        "def gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, it):\n",
        "\n",
        "    #surface alignment loss\n",
        "    pm = pytorch3d.structures.Meshes([mesh_verts], [mesh_faces])\n",
        "    gm = pytorch3d.structures.Meshes([gt_verts], [gt_faces])\n",
        "  \n",
        "    if mesh_verts.shape[0] > 0:\n",
        "      pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 100000)[0][0]\n",
        "      gt_points = kaolin.ops.mesh.sample_points(gt_verts.unsqueeze(0), gt_faces, 100000)[0][0]\n",
        "      chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), gt_points.unsqueeze(0), squared=False).mean()\n",
        "    else:\n",
        "      chamfer = 0\n",
        "\n",
        "\n",
        "    if it > iterations//2:\n",
        "      lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
        "      return 500*chamfer + lap * laplacian_weight \n",
        "    return 500*chamfer"
      ],
      "metadata": {
        "id": "MTGuIR9PS6Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "kQNxZ88uTjtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train(iterations, sdf_model, gcn_model, optimizer, scheduler, epoch):\n",
        "  gcn_model.train()\n",
        "  sdf_model.train()\n",
        "  avg_loss = 0\n",
        "  wt_models = []\n",
        "\n",
        "  for i in range(iterations):\n",
        "\n",
        "    gt_model = shapenet_train[25] # change the index here for different models\n",
        "\n",
        "    gt_verts = gt_model['mesh'][0]\n",
        "    gt_faces = gt_model['mesh'][1]\n",
        "\n",
        "    gt_verts = ((gt_verts - ((gt_verts.max(0)[0] + gt_verts.min(0)[0]) / 2)) / ((gt_verts.max(0)[0] - gt_verts.min(0)[0]).max()))* 0.8\n",
        "\n",
        "    gt_verts, gt_faces = gt_verts.to(device), gt_faces.to(device)\n",
        "\n",
        "    wt_grid = kaolin.ops.conversions.trianglemeshes_to_voxelgrids(\n",
        "        vertices=gt_verts.unsqueeze(0),\n",
        "        faces=gt_faces,\n",
        "        resolution=64\n",
        "    )\n",
        "\n",
        "    wt_verts, wt_faces = kaolin.ops.conversions.voxelgrids_to_cubic_meshes(wt_grid)\n",
        "    wt_verts, wt_faces = wt_verts[0], wt_faces[0]\n",
        "\n",
        "    center = (wt_verts.max(0)[0] + wt_verts.min(0)[0]) / 2\n",
        "    max_l = (wt_verts.max(0)[0] - wt_verts.min(0)[0]).max()\n",
        "    wt_verts = ((wt_verts - center) / max_l)* 0.8\n",
        "\n",
        "    F_vol = F.interpolate(wt_grid.unsqueeze(0), size=(1,tets_verts.shape[0], tets_verts.shape[1]), mode='trilinear', align_corners=False)\n",
        "\n",
        "    F_vol = torch.cat((tets_verts, F_vol.squeeze(0).squeeze(0).squeeze(0).to(device)), dim=1)\n",
        "\n",
        "    pred_sdfs, f_vs = sdf_model(F_vol)\n",
        "\n",
        "    \"\"\"\n",
        "    Surface Refinement\n",
        "    \"\"\"\n",
        "\n",
        "    surf_tets_verts_idx, surf_tets_faces = extract_tet(tets, pred_sdfs, 0.008) #if not working modify the 0.008 here; this is the threshold for surface sdf value\n",
        "    surf_tets_verts = torch.clone(tets_verts[surf_tets_verts_idx])\n",
        "\n",
        "    surf_tets_verts_features = torch.clone(f_vs[surf_tets_verts_idx])\n",
        "    surf_sdfs = pred_sdfs[surf_tets_verts_idx]\n",
        "    surf_tets_edges = torch.clone(get_edges(surf_tets_faces).to(device))\n",
        "    surf_verts_f = torch.cat((surf_tets_verts, surf_sdfs, surf_tets_verts_features), dim=1)\n",
        "\n",
        "    sdf, deform, fv = gcn_model(surf_verts_f, surf_tets_edges)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    Update surface position, sdf, and f_s\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #updated sdf\n",
        "\n",
        "    update_sdfs = pred_sdfs.clone()\n",
        "    update_sdfs[surf_tets_verts_idx] += sdf\n",
        "\n",
        "    #update vertices positions\n",
        "\n",
        "    update_tets_verts = tets_verts.clone()\n",
        "    update_tets_verts[surf_tets_verts_idx] += deform / grid_res\n",
        "\n",
        "    #update vertices features\n",
        "\n",
        "    update_tets_f = f_vs.clone()\n",
        "    update_tets_f[surf_tets_verts_idx] += fv\n",
        "\n",
        "    if epoch < 500:\n",
        "      gt_sdfs = get_gt_sdfs(wt_verts.unsqueeze(0), wt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "      sdf_loss = F.mse_loss(update_sdfs, gt_sdfs, reduction='mean')\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      sdf_loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "      avg_loss += sdf_loss.item()\n",
        "\n",
        "      if epoch == 0 and i == 0:\n",
        "        print('========== Start pretraining ==========')\n",
        "      \n",
        "      if i == (iterations - 1) and epoch % 100 == 0:\n",
        "        print ('Epoch {} - loss: {}'.format(epoch, avg_loss/iterations))\n",
        "\n",
        "      continue\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Marching Tetrahedra based on new sdf value and deformed vertices in the tet grid\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(update_tets_verts.unsqueeze(0), tets, update_sdfs.squeeze(1).unsqueeze(0))\n",
        "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Compute Loss for First surface refinement: \n",
        "    Normal consistency + surface alignment + laplacian smooth + sdf L2-reg + deform L2-reg\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # L2 sdf reg: \n",
        "\n",
        "    s_sdfs = get_gt_sdfs(gt_verts.unsqueeze(0), gt_faces, update_tets_verts.unsqueeze(0))\n",
        "\n",
        "    mask = ((s_sdfs >= -0.3) & (s_sdfs <= 0.3)).squeeze(1)\n",
        "    p = update_sdfs[mask]\n",
        "    g = s_sdfs[mask]\n",
        "\n",
        "    sdf_loss = F.mse_loss(p, g, reduction='mean') \n",
        "\n",
        "    #L2 deform reg\n",
        "\n",
        "    deform_loss = F.mse_loss(update_tets_verts, tets_verts, reduction='mean')\n",
        "\n",
        "    #surface alignment loss\n",
        "\n",
        "    r_loss = gcn_loss(iterations, mesh_verts, mesh_faces, gt_verts, gt_faces, i)\n",
        "\n",
        "    g_loss = r_loss + deform_loss + 0.4*sdf_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    avg_loss += g_loss.item()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch == 500 and i == 0:\n",
        "        print('========== Start Refinement ==========')\n",
        "\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "      if (i) % 1 == 0: \n",
        "        # print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(i, g_loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
        "        \n",
        "        # save reconstructed mesh\n",
        "        timelapse.add_mesh_batch(\n",
        "            iteration=epoch+1,\n",
        "            category='final_train_res',\n",
        "            vertices_list=[mesh_verts.cpu()],\n",
        "            faces_list=[mesh_faces.cpu()]\n",
        "        )\n",
        "      \n",
        "      if i == (iterations - 1):\n",
        "        print ('Epoch {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(epoch, avg_loss/iterations, mesh_verts.shape[0], mesh_faces.shape[0]))"
      ],
      "metadata": {
        "id": "0Nju6vB7_GBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_model = shapenet_train[20] #change the index here to match training example\n",
        "v_verts = v_model['mesh'][0].to(device)\n",
        "v_faces = v_model['mesh'][1]\n",
        "\n",
        "timelapse.add_mesh_batch(\n",
        "      category='gt',\n",
        "      vertices_list=[v_verts.cpu()],\n",
        "      faces_list=[v_faces.cpu()]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TyEEfd8J3G7",
        "outputId": "67374122-1988-4033-f9a3-ba906d11b451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5700],\n",
            "        [0.5689],\n",
            "        [0.5683],\n",
            "        ...,\n",
            "        [0.5367],\n",
            "        [0.5346],\n",
            "        [0.5344]], device='cuda:0')\n",
            "torch.Size([6301, 3])\n",
            "torch.Size([20778, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3000):\n",
        "  test_train(1, sdf_model, refine_model, refine_optimizer, refine_scheduler, i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT4Tf7O_a4ws",
        "outputId": "7bec3c8b-a2a1-4491-8f76-8181720ade5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Start pretraining ==========\n",
            "Epoch 0 - loss: 0.007392390631139278\n",
            "Epoch 100 - loss: 6.907405853271484\n",
            "Epoch 200 - loss: 0.11011458933353424\n",
            "Epoch 300 - loss: 0.04961121454834938\n",
            "Epoch 400 - loss: 0.03220337629318237\n",
            "========== Start Refinement ==========\n",
            "Epoch 500 - loss: 96.9729232788086, # of mesh vertices: 257625, # of mesh faces: 511583\n",
            "Epoch 600 - loss: 58.180747985839844, # of mesh vertices: 34787, # of mesh faces: 68934\n",
            "Epoch 700 - loss: 31.18280029296875, # of mesh vertices: 40110, # of mesh faces: 79868\n",
            "Epoch 800 - loss: 34.707794189453125, # of mesh vertices: 29231, # of mesh faces: 58152\n",
            "Epoch 900 - loss: 26.965675354003906, # of mesh vertices: 21904, # of mesh faces: 43760\n",
            "Epoch 1000 - loss: 23.684951782226562, # of mesh vertices: 42318, # of mesh faces: 85150\n",
            "Epoch 1100 - loss: 7.034949779510498, # of mesh vertices: 22558, # of mesh faces: 45124\n",
            "Epoch 1200 - loss: 7.041993141174316, # of mesh vertices: 34202, # of mesh faces: 68928\n",
            "Epoch 1300 - loss: 4.535536289215088, # of mesh vertices: 35340, # of mesh faces: 71792\n",
            "Epoch 1400 - loss: 6.935964584350586, # of mesh vertices: 22454, # of mesh faces: 44964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "1KFbx_48O1SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "1H7RCV62USts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use pyngrok to access localhost:80 on Colab\n",
        "\n",
        "!pip install pyngrok --quiet \n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2IGctyaa9n7vRBd8qq7pzd0bNKh_2pDFmKRk5Af1QDq295xZ4\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "id": "p68GrPqkUU07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fade1551-25f4-4808-8e2c-7d41102fcb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 143 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 194 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 256 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 266 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 276 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 296 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 317 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 327 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 337 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 348 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 368 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 389 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 399 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 409 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 419 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 440 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 460 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 471 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 481 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 491 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 501 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 512 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 522 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 532 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 542 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 552 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 563 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 573 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 583 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 593 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 604 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 614 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 624 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 634 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 645 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 655 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 665 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 675 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 686 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 696 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 706 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 716 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 727 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 737 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 747 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 757 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 761 kB 6.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generating a public url mapped to localhost 80\n",
        "public_url = ngrok.connect(port=80, proto=\"http\", options={\"bind_tls\": True, \"local\": True})\n",
        "print(\"Tracking URL:\", public_url)"
      ],
      "metadata": {
        "id": "rWJ2SS1EUYjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb8566b-662d-4985-cfe8-814bbe5f0d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking URL: NgrokTunnel: \"http://06f4-35-247-79-87.ngrok.io\" -> \"http://localhost:80\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start Kaolin Dash3D on localhost:80 \n",
        "!kaolin-dash3d --logdir=/content/drive/MyDrive/CV_DMTet/Logs --port=80"
      ],
      "metadata": {
        "id": "9RZLd8x7UrUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc31c9a2-0d21-43ad-c5a3-56663297949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash3D server starting. Go to: http://localhost:80\n",
            "2022-12-15 05:04:46,497|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:04:46,508|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:02,553|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:02,566|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:02,589|    INFO| tornado.access| 200 GET / (127.0.0.1) 65.04ms\n",
            "2022-12-15 05:05:02,751|    INFO| tornado.access| 200 GET /static/thirdparty.css (127.0.0.1) 4.01ms\n",
            "2022-12-15 05:05:02,783|    INFO| tornado.access| 200 GET /static/core-min.js (127.0.0.1) 3.04ms\n",
            "2022-12-15 05:05:02,989|    INFO| tornado.access| 200 GET /static/favicon.ico (127.0.0.1) 3.80ms\n",
            "2022-12-15 05:05:05,089|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:05,101|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:05,104|    INFO| tornado.access| 200 GET / (127.0.0.1) 41.22ms\n",
            "2022-12-15 05:05:05,241|    INFO| tornado.access| 304 GET /static/thirdparty.css (127.0.0.1) 2.93ms\n",
            "2022-12-15 05:05:05,244|    INFO| tornado.access| 200 GET /static/style.css (127.0.0.1) 5.28ms\n",
            "2022-12-15 05:05:05,292|    INFO| tornado.access| 304 GET /static/core-min.js (127.0.0.1) 2.44ms\n",
            "2022-12-15 05:05:05,297|    INFO| tornado.access| 200 GET /static/thirdparty.js (127.0.0.1) 7.30ms\n",
            "2022-12-15 05:05:05,777|    INFO| tornado.access| 200 GET /static/green_plastic.frag (127.0.0.1) 3.68ms\n",
            "2022-12-15 05:05:05,877|    INFO| tornado.access| 304 GET /static/favicon.ico (127.0.0.1) 2.52ms\n",
            "2022-12-15 05:05:05,886|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.72ms\n",
            "2022-12-15 05:05:05,887|    INFO| tornado.access| 101 GET /websocket/ (127.0.0.1) 2.68ms\n",
            "2022-12-15 05:05:05,912|    INFO|kaolin.visualize.timelapse| No checkpoints found for type pointcloud: no files matched pattern pointcloud*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:05,924|    INFO|kaolin.visualize.timelapse| No checkpoints found for type voxelgrid: no files matched pattern voxelgrid*.usd in /content/drive/MyDrive/CV_DMTet/Logs\n",
            "2022-12-15 05:05:05,985|    INFO| tornado.access| 304 GET /static/green_plastic.frag (127.0.0.1) 2.66ms\n",
            "2022-12-15 05:05:16,103|    INFO|kaolin.experimental.dash3d.util| Snap time 10.0 too close to current_time 10.0; no geometry parsed\n",
            "2022-12-15 05:05:16,108|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:17,439|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:39,491|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:39,522|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:43,633|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:43,665|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:47,190|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "2022-12-15 05:05:47,207|    INFO|kaolin.experimental.dash3d.util| Snap time 0.0 too close to current_time 0.0; no geometry parsed\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaolin-dash3d\", line 7, in <module>\n",
            "    exec(compile(f.read(), __file__, 'exec'))\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/kaolin-dash3d\", line 6, in <module>\n",
            "  File \"/content/drive/MyDrive/CV_DMTet/kaolin/kaolin/experimental/dash3d/run.py\", line 97, in run_main\n",
            "    IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tornado-6.1-py3.8-linux-x86_64.egg/tornado/platform/asyncio.py\", line 199, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1823, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}